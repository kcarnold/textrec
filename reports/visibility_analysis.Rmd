---
title: "Suggestion Visibility Analysis"
author: "(anon)"
date: "9/18/2019"
output:
  html_document:
    self_contained: no
  pdf_document: default
---

The Transparent Statistics guide, especially the [exemplars](https://transparentstats.github.io/guidelines/effectsize.html#effectsize_exemplar_within), was very helpful.

```{r setup, include=FALSE}
# https://stackoverflow.com/questions/27992239/knitr-include-figures-in-report-and-output-figures-to-separate-files
knitr::opts_chunk$set(
  echo = TRUE,
  dev=c('png', 'pdf')
)

library(dplyr)
library(readr)
library("knitr")

# Modeling
library(lme4)
library(lmerTest)
#library(car)
#library(optimx)
#library("ARTool")
library("parallel")

# Plotting
#library("cowplot")
library("ggbeeswarm")
library("ggstance")
theme_set(theme_bw())

doAnalysisSetup <- function() {
  library("tidyverse")
  library("afex")
  library("emmeans")  
  afex::set_sum_contrasts()

  ## See vignette("afex_mixed_example") for why "asymptotic".
  emm_options(lmer.df = "asymptotic") # also possible: 'satterthwaite', 'kenward-roger'
  #emm_options(lmer.df="kenward-roger") # slower, but needed for post-hoc tests to make sense.
};
doAnalysisSetup()
```

```{r read-data, include=FALSE}
# We need to set the stimulus (image) columns to chars because they otherwise look like numbers.
allData <- read_csv(
  "../data/analyzed/combined_data.csv",
  col_types = cols(
    stimulus = col_character(),
    stimulus_order = col_character()
  ));
stop_for_problems(allData)

allData$recsVisible <- allData$condition != "norecs";
```

```{r munge-data, include=FALSE}
# Use only the "Gated" study.
allData <- allData %>% subset(experiment == "gc1");

# Exclude bad participants.
data <- subset(allData, (participant != "pr5hff") & (participant != "7q253f"))


# Set appropriate columns as nominal factors
data <- data %>% mutate_at(c('experiment', 'block', 'participant', 'stimulus', 'stimulus_order', 'condition_order'), factor);
#data$idx <- factor(data$idx)
#data$idx_in_block <- factor(data$idx_in_block)

data <- data %>% rename(
    num_predictable = corrected_bow_recs_idealuse_standard,
    chars_per_sec = characters_per_sec) %>%
  mutate(
    frac_predictable = num_predictable / num_words,
    num_unpredictable = num_words - num_predictable
  );


# Name the conditions.
data <- data %>% mutate(
  condition = factor(
    recode_factor(condition, "norecs"="Never", "gated"="OnlyConfident", "standard"="Always"),
    levels = c("Never", "OnlyConfident", "Always")))

# Compute derived data.
data <- data %>% mutate(
  chars_per_sec_log = log(chars_per_sec)
);
data$itpw <- data$corrected_tapstotype_standard / data$num_words
data$itpw_log <- log(data$itpw)
data$itpw_gated <- data$corrected_tapstotype_gated / data$num_words
data$mean_rarity <- 1 - (data$mean_log_freq / 7)
data$total_nll <- -data$logprob_unconditional * data$num_words
data$tapsPerSec <- data$num_taps / data$seconds_spent_typing
data$anyErrors <- factor(data$uncorrected_errors != 0)
data$anyADJ = factor(data$ADJ != 0)


#data$num_not_recced = data$corrected_bow_recs_offered_standard - data$corrected_bow_recs_idealuse_standard
#data$frac_not_recced = 1 - data$corrected_bow_recs_idealuse_standard / data$corrected_bow_recs_offered_standard

#data <- data %>% group_by(participant) %>% mutate(mean_relevant_use_frac=mean(relevant_use_frac, na.rm=T)) %>% ungroup()
#data$rec_use_bin <- factor(ntile(data$mean_relevant_use_frac, 2))

var_names <- list(
  "num_predictable" = "Number of Predictable Words",
  "num_unpredictable" = "Number of Unpredictable Words",
  "frac_predictable" = "Fraction of Predictable Words",
  "num_words" = "Total Number of Words",
  "TLX_sum" = "Total task load (sum of TLX items)",
  "physical" = "TLX physical load item",
  "mental" = "TLX mental load item",
  "pos_count_NOUN" = "Number of nouns",
  "pos_count_ADJ" = "Number of adjectives",
  "num_colors" = "Number of color words used"
)

# expLevel <- data %>%
#   group_by(experiment, condition_order, participant, age, chars_per_sec_norecs_mean, steppedBack, gender, use_predictive) %>%
#   summarise(
#     chars_per_sec_mean = mean(chars_per_sec),
#     rec_use_per_seen_mean=mean(rec_use_per_seen, na.rm=TRUE))
# 
# data <- left_join(data, expLevel, copy=TRUE)
# 
# longForm <- data %>%
#   select(experiment, participant, condition, block, idx, idx_in_block, steppedBack, !!!names(vars.to.summarize)) %>%
#   gather(measure, value, !!!names(vars.to.summarize)) %>%
#   mutate(measure=dplyr::recode(measure, !!!vars.to.summarize))

```

```{r helpfulRank}
# I want:
#  participant | aspect | condition | rank
#
# I do that in a few steps:
# 1. Join the separate columns into one. helpfulAccurate="norecs-gated"
# 2. Split out the 

# 1. Select only the helpfulRank columns.
expHelpful <- data %>%
  select(participant, starts_with("helpfulRank")) %>% 
  select(participant, ends_with("condition")) %>% 
  group_by(participant) %>% summarise_all(first)

# Tidy the data (participant, aspect, extreme, value)
helpfulTidy <- expHelpful %>% 
  pivot_longer(
    cols=starts_with("helpfulRank"),
    names_prefix="helpfulRank-",
    names_sep="-",
    names_to = c("aspect", "extreme", "unused"),
    values_to = "condition"
  ) %>% select(-unused)
  # concatenate the two values
#  group_by(participant, aspect) %>% summarize(val_concat=decode(extreme, value))#paste(value, sep="-", collapse=""))
#data %>% transmute(
#  helpfulAccurate=paste(`helpfulRank-accurate-least-condition`, `helpfulRank-accurate-most-condition`, sep="-"),
#  )
#helpfulTidy %>% mutate(picked=TRUE) %>% pivot_wider(id_cols = c("participant", "aspect"), names_from=c("extreme", "value"), values_from=picked, values_fill = list(picked=FALSE))
helpfulCounts <- helpfulTidy %>% subset(extreme=="most") %>% group_by(condition) %>% summarize(picked=n())
helpfulCounts
```

```{r helpfulChiSq}
#helpfulTidy %>% pivot_wider(id_cols = )
chisq.test(helpfulCounts$picked)
```
# Summaries

Overall:
```{r}
print(paste("Total", n_distinct(allData$participant), "participants,", n_distinct(data$participant), "after exclusion"))
print(paste(nrow(data), "captions"))
```

Gender:
```{r genders}
# Gender distribution
allData %>%
  group_by(gender) %>%
  summarize(count=n_distinct(participant)) %>%
  spread(gender, count)
#counts.gc1 <- filter(genderCounts, experiment=="gc1")
```

Ages:
```{r ages}
# Age range
allData %>%
  summarize(min=min(age), max=max(age))
```

# Adjustments

```{r typosByCondition}
xt <- xtabs(~ condition + anyErrors, data=data)
#typo_test <- fisher.test(xt)
xt %>% addmargins() %>% kable()
```
```{r typoDifferenceSignificant}
xt <- xtabs(~ recsVisible + anyErrors, data=data)
#xt <- xtabs(~ condition + anyErrors, data=data)
fisher.test(xt)
```

# Set Up Analysis Task

```{r "blockLevelAggregation"}
blockLevelAll <- data %>% 
  group_by(participant, condition, block) %>%
  summarise_at(c("TLX_sum", "physical", "mental"), first) %>% 
  filter(!(any(is.na(TLX_sum)))) %>% 
  ungroup()

# Subtract per-image mean, aggregate by block.
dataMinusImgMean <- data %>%
  group_by(stimulus) %>% 
  mutate(
    num_predictable = num_predictable - mean(num_predictable),
    frac_predictable = frac_predictable - mean(frac_predictable),
    num_words = num_words - mean(num_words),
    chars_per_sec = chars_per_sec - mean(chars_per_sec),
    chars_per_sec_log = chars_per_sec_log - mean(chars_per_sec_log)
   ) %>% 
  ungroup();

blockLevelMinusMean <- dataMinusImgMean %>% 
  group_by(participant, condition, block) %>% 
  summarise_at(c(
    'num_predictable', 'frac_predictable', 'num_words',
    'chars_per_sec', 'chars_per_sec_log', 'chars_per_sec_norecs_mean', 'chars_per_sec_ratio_to_norecs',
    'pos_count_NOUN', 'pos_count_ADJ', 'num_colors'
    ), mean);
blockLevelRecsOnly <- subset(blockLevelMinusMean, condition != "Never")
```


```{r bootstrapGenTask}
total_iterations <- 10000

saveRDS(
  list(
    name="Trial-Level",
    iterations=total_iterations,
    data=data,
    measures=list(
      list("num_predictable", " ~ condition + (1|participant) + (1|stimulus)"),
      list("num_unpredictable", " ~ condition + (1|participant) + (1|stimulus)"),
      list("frac_predictable", " ~ condition + (1|participant) + (1|stimulus)"),
      list("num_words", " ~ condition + (1|participant) + (1|stimulus)"),
      list("pos_count_NOUN", " ~ condition + (1|participant) + (1|stimulus)"),
      list("pos_count_ADJ", " ~ condition + (1|participant) + (1|stimulus)"),
      list("num_colors", " ~ condition + (1|participant) + (1|stimulus)")
    )
  ),
  "tasks/trial_level.rds")

saveRDS(
  list(
    name="Block-Level All",
    iterations=total_iterations,
    data=blockLevelAll,
    measures=list(
      list("physical", " ~ condition + (1|participant)"),
      list("mental", " ~ condition + (1|participant)"),
      list("TLX_sum", " ~ condition + (1|participant)")
    )
  ),
  "tasks/block_level_all.rds"
)

saveRDS(
  list(
    name="Block-Level Suggs",
    iterations=total_iterations,
    data=blockLevelRecsOnly,
    measures=list(
      list("chars_per_sec_ratio_to_norecs", " ~ condition + (1|participant)")
    )
  ),
  "tasks/block_level_suggs.rds"
)
```

```{r loadResults}
trial_level_results <- readRDS("task_results/trial_level.rds")
block_level_results <- readRDS("task_results/block_level_all.rds")

```

```{r}

confIntsFromResults <- function(boot_results) {
  # inner 95%
  PERCENTILE_LO <- 0.025
  PERCENTILE_HI <- 0.975
  
  boot_results %>% 
    group_by(type, measure, statistic) %>% 
    summarize(
      n=n(),
      mean=mean(estimate),
      conf_low = unname(quantile(estimate, probs = PERCENTILE_LO)),
      conf_high = unname(quantile(estimate, probs = PERCENTILE_HI))) %>% 
    ungroup()
}

confints <- confIntsFromResults(trial_level_results)
  
```

```{r bootstrap_lsmeans, fig.width=7, fig.height=6}
cur_measures <- list("num_predictable", "num_unpredictable", "num_words", "frac_predictable")

confints %>%
  subset(type == "means") %>% 
  subset(measure %in% cur_measures) %>% 
  mutate(measure=factor(measure, levels=cur_measures)) %>%  # reorder
  mutate(measure=dplyr::recode(measure, !!!var_names)) %>%  # rename measures
  mutate(statistic=factor(statistic, levels=c("Always", "OnlyConfident", "Never"))) %>%
  ggplot(aes(x=statistic, y=mean, ymin=conf_low, ymax=conf_high)) +
  geom_hline(yintercept = 0, linetype ='dotted') +
  geom_pointrange(size=.25) +
  geom_text(aes(label=sprintf("%1.2f", ..y..)), nudge_x=.25, hjust="middle", vjust="bottom", size=2.5) +
  geom_text(aes(label=sprintf("%1.2f", conf_low), y=conf_low), hjust="right", vjust="bottom", size=3) +
  geom_text(aes(label=sprintf("%1.2f", conf_high), y=conf_high), hjust="left", vjust="bottom", size=3) +
  geom_blank(
    aes(y=value), 
    data=data.frame(
      measure=c("num_predictable", "num_unpredictable", "frac_predictable", "num_words"),
      min=c(0, 0, 0, 0.),
      max=c(9, 9, .7, 16)
    ) %>% mutate(measure=dplyr::recode(measure, !!!var_names))
    %>% pivot_longer(-measure),#data.frame(measure="frac_predictable", lims=c(-10, 10)),
  inherit.aes = F) +
  labs(x="", y="Estimated Means") +
  coord_flip() +
  facet_wrap(vars(measure), ncol=1, scales = "free")
#ggsave("bootstrap_lsmeans_manual.pdf", device=cairo_pdf())
```

```{r bootstrap_pairwise, fig.width=7, fig.height=6}
# Helpful: https://stackoverflow.com/questions/18046051/setting-individual-axis-limits-with-facet-wrap-and-scales-free-in-ggplot2
# TODO: https://stackoverflow.com/questions/45361904/duplicating-and-modifying-discrete-axis-in-ggplot2/45362497#45362497
ranges <- data.frame(
  measure=c("num_predictable", "num_unpredictable", "frac_predictable", "num_words"),
  min=c(-2, -2, -.1, -2),
  max=c(2, 2, .1, 2)
) %>% mutate(measure=dplyr::recode(measure, !!!var_names))

cur_measures <- list("num_predictable", "num_unpredictable", "num_words", "frac_predictable")

confints %>%
  subset(type == "pairs") %>% 
  subset(measure %in% cur_measures) %>% 
  mutate(measure=factor(measure, levels=cur_measures)) %>% 
  mutate(measure=dplyr::recode(measure, !!!var_names)) %>%
  ggplot(aes(x=statistic, y=mean, ymin=conf_low, ymax=conf_high)) +
  geom_hline(yintercept = 0, linetype ='dotted') +
  geom_pointrange(size=.25) +
  geom_text(aes(label=sprintf("%1.2f", ..y..)), nudge_x=.25, hjust="middle", vjust="bottom", size=2.5) +
  geom_text(aes(label=sprintf("%1.2f", conf_low), y=conf_low), hjust="right", vjust="bottom", size=3) +
  geom_text(aes(label=sprintf("%1.2f", conf_high), y=conf_high), hjust="left", vjust="bottom", size=3) +
  geom_blank(
    aes(y=value), 
    data=ranges %>% pivot_longer(-measure),
  inherit.aes = F) +
  labs(x="", y="Estimated Pairwise Difference") +
  coord_flip() +
  facet_wrap(vars(measure), ncol=1, scales = "free")
```

```{r bootstrap_frac_predictable}
# TODO: https://stackoverflow.com/questions/45361904/duplicating-and-modifying-discrete-axis-in-ggplot2/45362497#45362497
confints %>%
  subset(type == "pairs") %>% 
  subset(measure %in% list("frac_predictable", "num_words")) %>%
  mutate(measure=dplyr::recode(measure, !!!var_names)) %>%
  ggplot(aes(x=statistic, y=mean, ymin=conf_low, ymax=conf_high)) +
  geom_hline(yintercept = 0, linetype ='dotted') +
  geom_pointrange(size=.25) +
  geom_text(aes(label=sprintf("%1.2f", ..y..)), nudge_x=.25, hjust="middle", vjust="bottom", size=2.5) +
  geom_text(aes(label=sprintf("%1.2f", conf_low), y=conf_low), hjust="right", vjust="bottom", size=3) +
  geom_text(aes(label=sprintf("%1.2f", conf_high), y=conf_high), hjust="left", vjust="bottom", size=3) +
  geom_blank(aes(y=lims), data=data.frame(measure="frac_predictable", lims=c(-10, 10)), inherit.aes = F) +
  #expand_limits(x=0) +
  labs(x="", y="Estimated Pairwise Difference") +
  coord_flip() +
  facet_wrap(vars(measure), ncol=1, scales = "free")

```


```{r}
labeledBar <- list(
  stat_summary(geom="bar", fun.y=mean, position="dodge"),
    stat_summary(geom="errorbar", fun.data=mean_se, position=position_dodge(width=.9), width=.4),
    #scale_y_continuous(expand=expand_scale(mult=c(0,.05))), # remove the extra spacing at 0
    stat_summary(geom="text", fun.y=mean,
                 aes(label=sprintf("%1.2f", ..y..)),
                 position=position_dodge(width=.9),
                 hjust="middle", vjust="bottom"))
```


```{r "examples"}
total <- data %>% group_by(stimulus) %>% count() %>% pull(n) %>% mean()
q1 <- floor(total * .25)
q3 <- floor(total * .75)

sorted <- data %>%
  group_by(stimulus) %>%
  arrange(frac_predictable)

sorted %>% 
  slice(c(q1, q3)) %>%
  select(stimulus, num_predictable, num_unpredictable, frac_predictable, corrected_text) %>% 
  mutate(frac_predictable=round(frac_predictable * 100)) %>% 
  kable(format="latex") %>% 
  cat(sep="\n");

```


```{r speed_interaction}
blockLevelRecsOnly %>%
  ggplot(aes(x=chars_per_sec_norecs_mean, y=chars_per_sec_ratio_to_norecs, color=condition, shape=condition)) +
  geom_point(alpha=.5) +
  geom_smooth(method="loess", show.legend = FALSE) +
  labs(
    x="Baseline Speed (chars/sec in trials with suggestions Never visible)",
    y="Block-level mean ratio of speed in trial to baseline speed",
    color="Suggestion Visibility",
    shape="Suggestion Visibility")
  #facet_wrap(vars(block))
```

```{r "speedInteractionSimple", cache=TRUE}
lmer(
  chars_per_sec_ratio_to_norecs ~ chars_per_sec_norecs_mean + (1|participant),
  data=blockLevelRecsOnly) %>% 
confint.merMod(
  nsim = 1000,
  parallel="multicore",
  method = "boot")
```

```{r "speedInteractionWithCondition", cache=TRUE}
lmer(
  chars_per_sec_ratio_to_norecs ~ condition *  chars_per_sec_norecs_mean + (1|participant),
  data=blockLevelRecsOnly) %>%
confint.merMod(
  nsim = 1000,
  parallel="multicore",
  method = "boot")
```

# How did subjective experience depend on suggestion visibility?

```{r TLXconfints}
TLXconfints <- confIntsFromResults(block_level_results)
```

```{r tlxPairwise}
#, fig.width=7, fig.height=1.5}
# Maybe: https://stackoverflow.com/questions/45361904/duplicating-and-modifying-discrete-axis-in-ggplot2/45362497#45362497
#tlxCIs %>% #separate(contrast, into=c("right", "left"), remove=FALSE) %>% 
TLXconfints %>% 
  subset(type == "pairs") %>% 
  mutate(measure=dplyr::recode(measure, !!!var_names)) %>% 
  ggplot(aes(x=statistic, y=mean, ymin=conf_low, ymax=conf_high)) +
  geom_hline(yintercept = 0, linetype ='dotted') +
  geom_pointrange() +
  geom_text(aes(label=sprintf("%1.2f", ..y..)), nudge_x=.3, hjust="middle", vjust="bottom", size=2) +
  geom_text(aes(label=sprintf("%1.2g", conf_low), y=conf_low), hjust="right", size=2) +
  geom_text(aes(label=sprintf("%1.2g", conf_high), y=conf_high), hjust="left", size=2) +
  #expand_limits(x=0) +
  labs(x="", y="Estimated increase in TLX load") +
  coord_flip() +
  facet_wrap(vars(measure), ncol=1, scales = "free")
#ggsave("TLXpairwise.pdf");
```

# Supplemental Analyses

## Part of Speech

```{r contentExploratory}
# TODO: https://stackoverflow.com/questions/45361904/duplicating-and-modifying-discrete-axis-in-ggplot2/45362497#45362497
confints %>%
  subset(type == "pairs") %>% 
  subset(measure %in% list("pos_count_NOUN", "pos_count_ADJ", "num_colors")) %>% 
  mutate(measure=dplyr::recode(measure, !!!var_names)) %>%
  ggplot(aes(x=statistic, y=mean, ymin=conf_low, ymax=conf_high)) +
  geom_hline(yintercept = 0, linetype ='dotted') +
  geom_pointrange(size=.25) +
  geom_text(aes(label=sprintf("%1.2f", ..y..)), nudge_x=.25, hjust="middle", vjust="bottom", size=2.5) +
  geom_text(aes(label=sprintf("%1.2f", conf_low), y=conf_low), hjust="right", vjust="bottom", size=3) +
  geom_text(aes(label=sprintf("%1.2f", conf_high), y=conf_high), hjust="left", vjust="bottom", size=3) +
  expand_limits(x=0) +
  labs(x="", y="Estimated Pairwise Difference") +
  coord_flip() +
  #facet_grid(rows=vars(measure), cols=vars(type), scales="free")
  facet_wrap(vars(measure), ncol=1)#, scales = "free")

```

## Skips

```{r subset-hidden}
data %>% subset(condition=="Never") %>% select(stimulus, participant, corrected_text) %>% rename(text=corrected_text) %>% write_csv("no_suggestions_texts.csv")
```

Manually run `replay_recs.py`, then...

```{r}
actions <- read_csv("actions.csv")
```


```{r}
GATING_THRESHOLD = -0.989417552947998

skip_suggestions <- actions %>%
  mutate(gated=max_rec_prob < GATING_THRESHOLD) %>%
  group_by(participant, stimulus, text) %>% 
  fill(word, .direction = "up") %>% 
  subset(is.na(cur_word)) %>% 
  mutate(next_word=lead(word)) %>%
  rename(action_type=type) %>% 
  select(participant, stimulus, text, word, action_type, recs_shown, gated, next_word) %>% 
  mutate(
    recs_shown=str_split(recs_shown, ":"),
    shows_next_word=mapply(function(nw, recs) { nw %in% recs }, next_word, recs_shown),
  )
  #subset(shows_next_word == T) %>% 
  #View()

skip_suggestions %>% summarise(shows_next_word=sum(shows_next_word)) %>% subset(shows_next_word > 0) %>% nrow()
```

```{r}
skip_suggestions %>% ungroup() %>% subset(shows_next_word) %>%
  subset(action_type == "key") %>%
  count(word) %>% arrange(desc(n)) %>% slice(1:10) %>% pull(word) %>% paste0(collapse = ", ")
```

```{r}
skip_suggestions %>% ungroup() %>% subset(shows_next_word) %>%
  count(gated, action_type)
```

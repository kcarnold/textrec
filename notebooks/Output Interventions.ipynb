{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/code/textrec\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/textrec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import toolz\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading COCO captions\n",
      "Loading COCO id2url\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ONMT models...\n",
      "coco_lm_adam_acc_46.00_ppl_16.32_e10_nooptim.pt\n",
      "Loading model parameters.\n",
      "coco_cap_adam_acc_48.73_ppl_12.56_e10_nooptim.pt\n",
      "Loading model parameters.\n",
      "Ready.\n",
      "Loading SpaCy...done\n",
      "Loading COCO captions\n",
      "Loading COCO id2url\n",
      "Done\n",
      "Loading SpaCy...done\n"
     ]
    }
   ],
   "source": [
    "from textrec.paths import paths\n",
    "from textrec import analysis_util, util, notebook_util, automated_analyses\n",
    "reload(analysis_util), reload(util), reload(notebook_util), reload(automated_analyses)\n",
    "from textrec.notebook_util import images, id2img, id2url, show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import onmt.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of writing experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites: Run `textrec.logs_to_csv {batch_name}` and `textrec.gruntwork {batch_name}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 'spec1'\n",
    "experiment_level_data = pd.read_csv(paths.analyzed / f'experiment_{batch}.csv')\n",
    "block_level_data = pd.read_csv(paths.analyzed / f'block_{batch}.csv')\n",
    "trial_level_data = pd.read_csv(paths.analyzed / f'trial_withmanual_{batch}.csv')\n",
    "helpful_ranks_by_condition = pd.read_csv(paths.analyzed / f'helpful_ranks_by_condition_{batch}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concept**: One reason that writing is difficult is because we have to \"simulate the reader\", imagining what's going on in their mind, so that we can construct the desired concept there. A system could help by simulating the reader for us and giving us some peek into what our writing is doing inside their minds. That peek could look like:\n",
    "\n",
    "* what image is the writing conjuring in their mind? -> *show an image*\n",
    "* what inferences are they drawing? -> *show statements that are entailed by our writing*\n",
    "* what questions do they have? -> *show questions that writing similar to ours answers in different ways*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See \"Chapter Intros\" for more fleshed out concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_captions = {img['cocoid']: util.join_captions(img) for img in notebook_util.images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vectorizer, caption_vecs = util.get_vectorized_captions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123287, 9952)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    concat_captions = {stimulus: '\\n'.join(toolz.pluck('text', trials))\n",
    "                       for stimulus, trials in toolz.groupby('stimulus', trial_data).items()}\n",
    "    concat_captions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_word = 'wheelchair'\n",
    "from collections import Counter\n",
    "follows = Counter()\n",
    "for img in notebook_util.images:\n",
    "    for sent in img['sentences']:\n",
    "        tokens = sent['tokens']\n",
    "        while query_word in tokens:\n",
    "            idx = tokens.index(query_word)\n",
    "            if idx + 1 < len(tokens):\n",
    "                follows[tokens[idx + 1]] += 1\n",
    "                tokens = tokens[idx+1:]\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 11),\n",
       " ('with', 6),\n",
       " ('on', 5),\n",
       " ('holding', 5),\n",
       " ('sitting', 5),\n",
       " ('and', 4),\n",
       " ('playing', 4),\n",
       " ('while', 3),\n",
       " ('pulling', 3),\n",
       " ('sits', 3),\n",
       " ('in', 2),\n",
       " ('walking', 2),\n",
       " ('has', 2),\n",
       " ('accessible', 1),\n",
       " ('plays', 1),\n",
       " ('waiting', 1),\n",
       " ('looks', 1),\n",
       " ('near', 1),\n",
       " ('prepares', 1),\n",
       " ('are', 1),\n",
       " ('at', 1),\n",
       " ('dragging', 1),\n",
       " ('riders', 1),\n",
       " ('sets', 1),\n",
       " ('works', 1),\n",
       " ('sign', 1),\n",
       " ('driving', 1),\n",
       " ('ramp', 1),\n",
       " ('watched', 1),\n",
       " ('as', 1),\n",
       " ('shakes', 1),\n",
       " ('get', 1),\n",
       " ('next', 1),\n",
       " ('happily', 1),\n",
       " ('bound', 1),\n",
       " ('opening', 1),\n",
       " ('poses', 1),\n",
       " ('taking', 1),\n",
       " ('having', 1),\n",
       " ('beside', 1),\n",
       " ('parked', 1),\n",
       " ('flipping', 1),\n",
       " ('down', 1),\n",
       " ('looking', 1),\n",
       " ('doesnt', 1),\n",
       " ('stops', 1),\n",
       " ('desk', 1),\n",
       " ('users', 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follows.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123287"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notebook_util.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('parking', 6),\n",
       " ('bathroom', 5),\n",
       " ('accessible', 4),\n",
       " ('man', 3),\n",
       " ('restroom', 3),\n",
       " ('toilet', 3),\n",
       " ('sign', 3),\n",
       " ('bar', 2),\n",
       " ('people', 2),\n",
       " ('area', 2),\n",
       " ('with', 2),\n",
       " ('spot', 1),\n",
       " ('bars', 1),\n",
       " ('person', 1),\n",
       " ('accessory', 1),\n",
       " ('bus', 1),\n",
       " ('equipped', 1),\n",
       " ('urinal', 1),\n",
       " ('sticker', 1),\n",
       " ('chair', 1),\n",
       " ('jockeys', 1),\n",
       " ('rails', 1),\n",
       " ('access', 1),\n",
       " ('public', 1),\n",
       " ('veteran', 1),\n",
       " ('skier', 1),\n",
       " ('athletes', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follows.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>train/71589</div><img src=\"http://images.cocodataset.org/train2017/000000071589.jpg\" style=\"max-width: 200px\"><div>A blue disabled parking sight with a parking meter attached to it.</div>\n",
       "<div>A handicap parking sign sits atop a parking meter.</div>\n",
       "<div>A parking meter reserved for the disabled outside of a boutique</div>\n",
       "<div>A parking sign and meter stand in front of a store front.</div>\n",
       "<div>A handicapped parking space is in front of a clothing store.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/530037</div><img src=\"http://images.cocodataset.org/train2017/000000530037.jpg\" style=\"max-width: 200px\"><div>A bike sitting in a room with a black piece of luggage on it.</div>\n",
       "<div>A man is sitting beside a bike carrying luggage.</div>\n",
       "<div>A piece of luggage strapped on the back of a bike.</div>\n",
       "<div>The disabled man has his suitcase on the wheelchair. </div>\n",
       "<div>People sitting next to a bicycle with a suit case on it.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/538194</div><img src=\"http://images.cocodataset.org/train2017/000000538194.jpg\" style=\"max-width: 200px\"><div>The airplane is on the runway at the airport loading up.</div>\n",
       "<div>The truck bed is on a lift to reach the airplane door. </div>\n",
       "<div>A Sky Chefs truck loads commissary items onto a passenger jet aircraft.</div>\n",
       "<div>A truck and a part of a disabled plane</div>\n",
       "<div>An airport service vehicle next to a parked airplane.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/244279</div><img src=\"http://images.cocodataset.org/train2017/000000244279.jpg\" style=\"max-width: 200px\"><div>A young girl is getting a haircut in a chair.</div>\n",
       "<div>Two people that are in a room together.</div>\n",
       "<div>A women combing the long hair of another woman in a handicapped chair.</div>\n",
       "<div>One woman is arranging the other woman's hair.</div>\n",
       "<div>A disabled girl getting her hair combed by a women.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/215913</div><img src=\"http://images.cocodataset.org/train2017/000000215913.jpg\" style=\"max-width: 200px\"><div>A disabled clock with a Christmas tree next to it</div>\n",
       "<div>A wooden clock mounted to the side of a wall near a Christmas tree.</div>\n",
       "<div>a large wooden clock with roman numerals on it</div>\n",
       "<div>A wall with an old clock with rust on it.</div>\n",
       "<div>An antique clock hanging on a cluttered wall. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>val/259690</div><img src=\"http://images.cocodataset.org/val2017/000000259690.jpg\" style=\"max-width: 200px\"><div>A handicapped man in a wheelchair is being helped to hold the bat by another man on a tee ball </div>\n",
       "<div>A man standing next to another person in a wheel chair.</div>\n",
       "<div>A man helps a disabled baseball player on the mound.</div>\n",
       "<div>A man is helping an athlete on a sport field.</div>\n",
       "<div>A man in a wheel chair who is holding a baseball bat.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/257263</div><img src=\"http://images.cocodataset.org/train2017/000000257263.jpg\" style=\"max-width: 200px\"><div>A public restroom toilet has been photographed in sepia</div>\n",
       "<div>A restroom with the toilet in the corner.</div>\n",
       "<div>A toilet is equipped with support bars for the disabled.</div>\n",
       "<div>A bathroom toilet is surrounded with silver handrails.</div>\n",
       "<div>Toilet paper on the floor below a public toilet.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/312627</div><img src=\"http://images.cocodataset.org/train2017/000000312627.jpg\" style=\"max-width: 200px\"><div>a parking lot with a refrigerator and a speaker on the floor</div>\n",
       "<div>Inside picture of warehouse handicapped parking space with pieces of furniture and boxes.</div>\n",
       "<div>A handicap zone is designated in a storage facility.</div>\n",
       "<div>Several pieces of furniture are in an empty parking area.</div>\n",
       "<div>A nearly empty warehouse with a disabled  parking sign</div></div>\n",
       "<div style=\"display: inline-block;\"><div>test/149500</div><img src=\"http://images.cocodataset.org/train2017/000000149500.jpg\" style=\"max-width: 200px\"><div>An old man is trying to use his cell phone.</div>\n",
       "<div>An elderly man looks at a cell phone.</div>\n",
       "<div>An old man holding up a cell phone to his face.</div>\n",
       "<div>An elderly disabled man looks at a cell phone.</div>\n",
       "<div>An old man looks at a cell phone screen.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/339886</div><img src=\"http://images.cocodataset.org/train2017/000000339886.jpg\" style=\"max-width: 200px\"><div>A bathroom that has two different sized toilets. </div>\n",
       "<div>Two toilets in a bathroom, one is regular and one is custom made for the disabled.</div>\n",
       "<div>a bathroom with two toilets and toilet paper</div>\n",
       "<div>Two toilets, one short and one or the handicapped with railings in a bathroom.</div>\n",
       "<div>A public handicapped restroom with green and beige tile floors and walls.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/65183</div><img src=\"http://images.cocodataset.org/train2017/000000065183.jpg\" style=\"max-width: 200px\"><div>A group of passengers stands outside a bus with a flat tire.</div>\n",
       "<div>People standing behind a disabled bus while an on looker takes a photo and another looks at a rear tire.</div>\n",
       "<div>A group of people stands by a bus which is broken down on the side of the road</div>\n",
       "<div>The bus is stopped on the side of the road with a flat tire.</div>\n",
       "<div>A big bus with a flat tire that is being changed.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/17153</div><img src=\"http://images.cocodataset.org/train2017/000000017153.jpg\" style=\"max-width: 200px\"><div>A blanket on the sand with two pizzas, vegetables and dip, and other foods on it</div>\n",
       "<div>A picnic lunch with pizzas and dumplings sits on a quilt.</div>\n",
       "<div>Two pizzas sitting next to veggies and dip with dessert.</div>\n",
       "<div>An assortment of foods including pizza and dumplings on a blanket.</div>\n",
       "<div>A box of two pizzas and some packed vegetables of some sort.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/471245</div><img src=\"http://images.cocodataset.org/train2017/000000471245.jpg\" style=\"max-width: 200px\"><div>A photo of someone's meal at a restaurant.</div>\n",
       "<div>A plate of food with a salad and a sandwich</div>\n",
       "<div>A sandwich sitting on a plate with a salad of lettuce, tomato and cucumber.</div>\n",
       "<div>A mean of a hot sub sandwich and a salad rests on a plate in a cafe. </div>\n",
       "<div>A sandwich and salad on a white plate</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/460408</div><img src=\"http://images.cocodataset.org/train2017/000000460408.jpg\" style=\"max-width: 200px\"><div>Pink lunch box with compartments for all types of food</div>\n",
       "<div>A pink tray has compartments with different foods in it.</div>\n",
       "<div>A lunch box packed with mac and cheese, vegetables and a treat. </div>\n",
       "<div>The lunchbox has a container with food and some liquid in a bottle. </div>\n",
       "<div>Pink lunchbox filled with fruit and vegetables and snacks.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/242709</div><img src=\"http://images.cocodataset.org/train2017/000000242709.jpg\" style=\"max-width: 200px\"><div>A table topped with plastic containers of rice, meat and veggies.</div>\n",
       "<div>Three dishes contain the ingredients for a stir-fry meal.</div>\n",
       "<div>A couple of dishes on a table top.</div>\n",
       "<div>An apple in the middle of three different dishes.</div>\n",
       "<div>A healthy meal with meat, rice and vegetables.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/74502</div><img src=\"http://images.cocodataset.org/train2017/000000074502.jpg\" style=\"max-width: 200px\"><div>a trey containing vegetables fruit and other food</div>\n",
       "<div>A lunch box with rice, vegetables and fruit.</div>\n",
       "<div>Rice, fruit, and vegetables are in a tray.</div>\n",
       "<div>A pink tray has many containers of food in it.</div>\n",
       "<div>A food tray with yogurt & berries, cucumber & carrots, rice, green beans, and dip.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/232123</div><img src=\"http://images.cocodataset.org/train2017/000000232123.jpg\" style=\"max-width: 200px\"><div>A plate with radishes, carrots, green snap beans, peanuts and spinach.</div>\n",
       "<div>Full plate of salad with nuts, lettuce and carrots among other things.</div>\n",
       "<div>a plate that has all kinds of vegetables in it</div>\n",
       "<div>A plate with salad and sugar snap peas on it.</div>\n",
       "<div>a green and white plate with a salad </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/267540</div><img src=\"http://images.cocodataset.org/train2017/000000267540.jpg\" style=\"max-width: 200px\"><div>four different bowls with different fruits and vegetables and cheese and crackers</div>\n",
       "<div>A set of four bowls sitting on top of a white table.</div>\n",
       "<div>Small bowls of crackers and cheese, grapes and cherries, green bean and carrots and a small salad </div>\n",
       "<div>Four bowls contianing vegetables, crackers and cheese, cherries, and grapes.</div>\n",
       "<div>Four bowls with cheese, crackers, celery, carrots, lettuce, cherries and grapes in them. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/527344</div><img src=\"http://images.cocodataset.org/train2017/000000527344.jpg\" style=\"max-width: 200px\"><div>A blue bowl filled with vegetables and meat.</div>\n",
       "<div>A bowl of steamed vegetables with a view of a body of water behind it. </div>\n",
       "<div>this is a blue plate with vegetables in it</div>\n",
       "<div>A bowl that has food inside of it.</div>\n",
       "<div>A bowl that has vegetables and meat in it.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/230892</div><img src=\"http://images.cocodataset.org/train2017/000000230892.jpg\" style=\"max-width: 200px\"><div>a small white stuffed rabbit and some fruit</div>\n",
       "<div>Someone has placed the stuff rabbit with the fruit.</div>\n",
       "<div>This is a small toy rabbit in front of some apples and grapes.</div>\n",
       "<div>a stuffed bunny sitting next to a pile of fruit.</div>\n",
       "<div>A stuffed bunny rabbit next to apples and grapes. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/158514</div><img src=\"http://images.cocodataset.org/train2017/000000158514.jpg\" style=\"max-width: 200px\"><div>A white bowl filled with potato salad and a black spoon.</div>\n",
       "<div>Some creamy apple salad is in a bowl.</div>\n",
       "<div>The fruit salad has a large black spoon in it.</div>\n",
       "<div>A full view of a white plate full of food. </div>\n",
       "<div>A plate of food on a table </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/64897</div><img src=\"http://images.cocodataset.org/train2017/000000064897.jpg\" style=\"max-width: 200px\"><div>A man riding a skateboard up the side of a ramp.</div>\n",
       "<div>a boy skate boarding in a skate board park</div>\n",
       "<div>a guy is skateboarding and jumping over a concrete hill</div>\n",
       "<div>A person jumping up into the air on a skateboard.</div>\n",
       "<div>A guy is showing off his skateboarding skills.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/68430</div><img src=\"http://images.cocodataset.org/train2017/000000068430.jpg\" style=\"max-width: 200px\"><div>A table is set with snack foods outdoors.</div>\n",
       "<div>a table of food outdoors for a gathering, it includes sandwiches and finger food</div>\n",
       "<div>a long buffet of food and people waiting to eat.</div>\n",
       "<div>A variety of snacks and sandwiches are displayed on a picnic table.</div>\n",
       "<div>A long table with various food items on the table including grapes, cheese and crackers, sandwiches, oranges and beverages.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/94885</div><img src=\"http://images.cocodataset.org/train2017/000000094885.jpg\" style=\"max-width: 200px\"><div>A tray filled with plates and dishes full of food.</div>\n",
       "<div>A complete meal including desert on a tray.</div>\n",
       "<div>A tray of food has an assortment of items.</div>\n",
       "<div>A tray containing a variety of food items representing a full course meal. </div>\n",
       "<div>Meal set out in different bowls placed on a tray.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/310714</div><img src=\"http://images.cocodataset.org/train2017/000000310714.jpg\" style=\"max-width: 200px\"><div>Three plates filled with foods on a tray.</div>\n",
       "<div>A full course meal with meat and mixed vegetables.</div>\n",
       "<div>A variety of dishes sitting on a table.</div>\n",
       "<div>A display of plates containing various stir fry.</div>\n",
       "<div>a picture of some vegetable meal and a plate of what looks like chicken and a side bowl of rice and curry.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/69081</div><img src=\"http://images.cocodataset.org/train2017/000000069081.jpg\" style=\"max-width: 200px\"><div>there is a man in a blue body suit on a skateboard</div>\n",
       "<div>A blue man rides his skateboard through the park.</div>\n",
       "<div>A person in a full blue body suit with a red helmet on a skate board. </div>\n",
       "<div>An abstract photograph of a man dressed all in blue skateboarding.</div>\n",
       "<div>A person dressed in a blue costume is standing on a skateboard in the middle of a sidewalk path.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/183336</div><img src=\"http://images.cocodataset.org/train2017/000000183336.jpg\" style=\"max-width: 200px\"><div>A chicken sandwich with onions, tomatoes and spinach on the side.</div>\n",
       "<div>A meat and vegetable sandwich with a bowl of soup.</div>\n",
       "<div>a close up of a plate of food </div>\n",
       "<div>A sandwich, vegetables and soup sit on a table.</div>\n",
       "<div>A plate full of food and a bowl full of soup.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/139285</div><img src=\"http://images.cocodataset.org/train2017/000000139285.jpg\" style=\"max-width: 200px\"><div>A person standing on a sidewalk holding a sandwich that has carrots on it. </div>\n",
       "<div>A hand holding a sandwich with meat, carrots and lettuce.</div>\n",
       "<div>A sandwich on a bun with carrots and greens on it.</div>\n",
       "<div>A deli sandwhich with shredded carrots in the sandwich.</div>\n",
       "<div>Person on the street with a hoagie sandwich in hand.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/548293</div><img src=\"http://images.cocodataset.org/train2017/000000548293.jpg\" style=\"max-width: 200px\"><div>A young boy riding a skateboard in the middle of a park.</div>\n",
       "<div>The young boy is practicing on his skateboard. </div>\n",
       "<div>A little body riding on a skateboard on a sidewalk.</div>\n",
       "<div>A boy riding a skateboard on the sidewalk.</div>\n",
       "<div>A boy doing a trick on his skateboard.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/457514</div><img src=\"http://images.cocodataset.org/train2017/000000457514.jpg\" style=\"max-width: 200px\"><div>a person riding a skate board on a brick sidewalk</div>\n",
       "<div>A skateboarder riding a skateboard on a sidewalk.</div>\n",
       "<div>There is a skateboarder riding a skateboard on the street</div>\n",
       "<div>a close up of person riding a skate board</div>\n",
       "<div>A person in jeans and black shoes riding on a skateboard.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/395030</div><img src=\"http://images.cocodataset.org/train2017/000000395030.jpg\" style=\"max-width: 200px\"><div>A couple of blue plastic containers filled with food.</div>\n",
       "<div>A meal with hello kitty in the plate behind the dish.</div>\n",
       "<div>A lunchbox with food items are shown inside.</div>\n",
       "<div>A very appealing Japanese bento lunch that's sitting on a table. </div>\n",
       "<div>Two cartons of food with some cute little characters.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/220232</div><img src=\"http://images.cocodataset.org/train2017/000000220232.jpg\" style=\"max-width: 200px\"><div>A person carrying a skateboard as they walk forward.</div>\n",
       "<div>A PERSON WITH A SKATEBOARD GOING DOWN THE STREET </div>\n",
       "<div>a person getting ready to ride a skate board </div>\n",
       "<div>Person holding upright skateboard on cement block pathway.</div>\n",
       "<div>A man is skateboarding on a brick sidewalk.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/462908</div><img src=\"http://images.cocodataset.org/train2017/000000462908.jpg\" style=\"max-width: 200px\"><div>a plate that has some food on it</div>\n",
       "<div>A plate that has a sandwich and french fries on it.</div>\n",
       "<div>A plate that has a burger and fries on it.</div>\n",
       "<div>A grilled sandwich and french fries with drinks.</div>\n",
       "<div>The lunch platter contains an appetizing sandwich with fries.  </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/46997</div><img src=\"http://images.cocodataset.org/train2017/000000046997.jpg\" style=\"max-width: 200px\"><div>a close up of a sandwich on a plate</div>\n",
       "<div>an upclose picture of a restaurant meal consisting of a sandwich and soup</div>\n",
       "<div>An assortment of foods on white and blue plates.</div>\n",
       "<div>a plate with some sandwiches and soup on it </div>\n",
       "<div>Plates of soup and sandwiches on a table.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/581662</div><img src=\"http://images.cocodataset.org/train2017/000000581662.jpg\" style=\"max-width: 200px\"><div>A plate of food that includes onions, carrots and seasoning.</div>\n",
       "<div>A variety of noodles and vegetables fill up a plate. </div>\n",
       "<div>A serving plate of finely sliced vegetables with spice on top.</div>\n",
       "<div>A large white plate filled with carrot and zucchini strips.</div>\n",
       "<div>Various sliced vegetables on a platter with sauces.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/299712</div><img src=\"http://images.cocodataset.org/train2017/000000299712.jpg\" style=\"max-width: 200px\"><div>Several plates filled with meat, rice, and vegetables.</div>\n",
       "<div>A group of three bowls filled with lots of food.</div>\n",
       "<div>A Chinese main dish with a salad and rice on the table.</div>\n",
       "<div>Some orange chicken and broccoli are in a bowl.</div>\n",
       "<div>Asian stirfry meal of chicken or pork with broccoli in brown sauce and side of rice and salad.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/373511</div><img src=\"http://images.cocodataset.org/train2017/000000373511.jpg\" style=\"max-width: 200px\"><div>A blender filled with various vegetables that haven't been blended.</div>\n",
       "<div>A blender filled with many types of vegetables.</div>\n",
       "<div>Vegetables are cut up and put into a blender.</div>\n",
       "<div>A blender full of vegetables is shown with ice.</div>\n",
       "<div>A picture of vegetables in a blender waiting to be blended.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/475546</div><img src=\"http://images.cocodataset.org/train2017/000000475546.jpg\" style=\"max-width: 200px\"><div>The patrons enjoy their beverages at the bar.</div>\n",
       "<div>People having a drink in a basement bar.</div>\n",
       "<div>A group of friends enjoys a drink while sitting at a bar.</div>\n",
       "<div>Group of people drinking wine at a public location.</div>\n",
       "<div>Three women and a man are sitting at a bar</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/80134</div><img src=\"http://images.cocodataset.org/train2017/000000080134.jpg\" style=\"max-width: 200px\"><div>A family posing for a picture in front of a wall with a painting.</div>\n",
       "<div>the family is posing for an unusual picture.</div>\n",
       "<div>Two children sit on a skateboard together, their parents are behind them.</div>\n",
       "<div>A man and a woman and two children sitting on a skateboard in front of graffiti.</div>\n",
       "<div>a fmily sit on the ground in front of a wall with graffiti on it</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/234749</div><img src=\"http://images.cocodataset.org/train2017/000000234749.jpg\" style=\"max-width: 200px\"><div>A table that has three plates of food on it</div>\n",
       "<div>A meal with soup and salad for lunch.</div>\n",
       "<div>The plate of soup has sides of meat and vegetables.</div>\n",
       "<div>A plate and two bowls filled with lots of food.</div>\n",
       "<div>very well made food and salad besides it</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/369546</div><img src=\"http://images.cocodataset.org/train2017/000000369546.jpg\" style=\"max-width: 200px\"><div>A platter displays several different kinds of fresh produce.</div>\n",
       "<div>a bunch of raw vegetables on a wooden table. </div>\n",
       "<div>This is a cutting board that is filled with veggies. </div>\n",
       "<div>Cucumbers, tomatoes, string beans, broccoli and eggplant on a table.</div>\n",
       "<div>A plate topped with fruits and vegetables next to leafy greens.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/366554</div><img src=\"http://images.cocodataset.org/train2017/000000366554.jpg\" style=\"max-width: 200px\"><div>A man riding skis on a snow covered slope.</div>\n",
       "<div>A person on skis holding poles on a snowy slope.</div>\n",
       "<div>A person in striped jacket on skis standing in snowy area.</div>\n",
       "<div>Skier in white, green, and blue jacket standing on snow.</div>\n",
       "<div>The young boy is getting ready to ski. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/556065</div><img src=\"http://images.cocodataset.org/train2017/000000556065.jpg\" style=\"max-width: 200px\"><div>Two skiers, one of which has fallen and is trying to get up.</div>\n",
       "<div>A man in ski gear on his side in the snow on his skis.</div>\n",
       "<div>a person laying in the snow next to a person standing</div>\n",
       "<div>two people riding skis on a snowy slope </div>\n",
       "<div>A woman wearing skis has fallen onto her left side.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/196663</div><img src=\"http://images.cocodataset.org/train2017/000000196663.jpg\" style=\"max-width: 200px\"><div>A counter top filled with meat, vegetables and a book.</div>\n",
       "<div>Vegetables and chicken are layed out in preparation.</div>\n",
       "<div>This items have been selected to make a meal.</div>\n",
       "<div>A tray of ingredients used to cook a fine foods recipe.</div>\n",
       "<div>Variety of meat and produce displayed for meal preparation.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/155263</div><img src=\"http://images.cocodataset.org/train2017/000000155263.jpg\" style=\"max-width: 200px\"><div>A plate with a sandwich and fresh fruit and vegetables.</div>\n",
       "<div>A large sandwich with fruit and vegetable on a plate.</div>\n",
       "<div>An egg salad sandwich, an apple and carrot sticks on a plate.</div>\n",
       "<div>A plate of chopped carrots, a whole apple and an egg salad sandwich.</div>\n",
       "<div>a sandwich with a carrot and an apple near by</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/427335</div><img src=\"http://images.cocodataset.org/train2017/000000427335.jpg\" style=\"max-width: 200px\"><div>Large and colorful display of various fruits, vegetables and canned goods</div>\n",
       "<div>A picture a lot of food on the table.</div>\n",
       "<div>A selection of fresh, frozen and canned fruits and vegetables</div>\n",
       "<div>a round plate with several types of food on it.</div>\n",
       "<div>A mix of ingredients sitting on a round table   </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/504657</div><img src=\"http://images.cocodataset.org/train2017/000000504657.jpg\" style=\"max-width: 200px\"><div>A counter top filled with lots of fresh fruits and vegetables.</div>\n",
       "<div>A table with various foods on it, vegetables, fruits and meat.</div>\n",
       "<div>Several different kinds of vegetables on a counter.</div>\n",
       "<div>An arrangement of fruits and vegetables are laid out on a counter.</div>\n",
       "<div>A mass of assorted fruits and vegetables sitting on a kitchen counter.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/537532</div><img src=\"http://images.cocodataset.org/train2017/000000537532.jpg\" style=\"max-width: 200px\"><div>Plate full of chinese food with broccoli and meat.</div>\n",
       "<div>Various dishes of oriental food resting on a counter top. </div>\n",
       "<div>A white plate topped with broccoli beef next to a bow of fried rice.</div>\n",
       "<div>A large bowl of broccoli and meet on a table with other bowls of food.</div>\n",
       "<div>A table full of food including a large dish of broccoli.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/106666</div><img src=\"http://images.cocodataset.org/train2017/000000106666.jpg\" style=\"max-width: 200px\"><div>A man laying down in the snow with skies on</div>\n",
       "<div>A man lays in the snow with his skis propped up</div>\n",
       "<div>a person laying on a snowy surface wearing skis </div>\n",
       "<div>A man wearing skis lays on his back in the snow.</div>\n",
       "<div>a man on skis laying down in the snow</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/98413</div><img src=\"http://images.cocodataset.org/train2017/000000098413.jpg\" style=\"max-width: 200px\"><div>A baby sitting at a high chair in front of a table filled with food. </div>\n",
       "<div>A baby sitting at a high chair in front of some food.</div>\n",
       "<div>A baby is sitting in a highchair at a table with food on it.</div>\n",
       "<div>A baby in a high chair in front of a table with a variety of food lined out. </div>\n",
       "<div>A baby in a high chair is sitting at a dining table.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similar_images(caption, n=10):\n",
    "    query_vec = cap_vectorizer.transform([caption])\n",
    "    similarity = caption_vecs.dot(query_vec.T).A.ravel()\n",
    "    return [images[idx]['cocoid'] for idx in np.argsort(similarity)[-n:][::-1]]\n",
    "#query_caption = concat_captions[396295].replace('wine', '') #trial_data[0]['text']\n",
    "# query_caption = \"a rusty and dirty shower in the bathroom has a tan towel over its handle\"\n",
    "# query_caption = \"a sliding glass shower door with a bath mat hanging on it\"\n",
    "# query_caption = \"a closed shower door with crackled glass encases some hanging colored toiletries\"\n",
    "# query_caption = \"a brown train pulls into the tracks next to some colorful buildings\"\n",
    "# query_caption = \"a red city bus heading down the street\"\n",
    "# query_caption = \"a red double-decker bus heading down the street\"\n",
    "# query_caption = \"a red double-decker bus heading down the wide street with buildings on both sides\"\n",
    "query_caption = \"disabled\"\n",
    "# print(query_caption)\n",
    "HTML(show_images(get_similar_images(query_caption, n=50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_caption = \"a brown train pulls into the tracks next to some colorful buildings\"\n",
    "query_vec = cap_vectorizer.transform([query_caption])\n",
    "similarity = caption_vecs.dot(query_vec.T).A.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How similar should we count as similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_argsort = np.argsort(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>train/417715</div><img src=\"http://images.cocodataset.org/train2017/000000417715.jpg\" style=\"max-width: 200px\"><div>A train traveling over a bridge next to a tall building.</div>\n",
       "<div>Cars are parked outside, not far from the highway.</div>\n",
       "<div>a view from a rooftop of parked cars and train station</div>\n",
       "<div>Many cars are parked along an empty highway.</div>\n",
       "<div>some train tracks some parked cars and a building</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(show_images([images[similarity_argsort[int(.978*len(similarity_argsort))]]['cocoid']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf similarity mixes relevant (trains at stations) with irrelevant (colorful kites). I wonder if we need visual similarity as well, or if just better caption similarity (e.g., sentence vectors, Transformer LM, etc.) would do it... or maybe better data, like Visual Genome? Let's push ahead though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: just the most similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a brown train pulls into the tracks next to some colorful buildings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>train/352082</div><img src=\"http://images.cocodataset.org/train2017/000000352082.jpg\" style=\"max-width: 200px\"><div>A train traveling down railroad tracks next to a train station.</div>\n",
       "<div>People standing next to a train as it pulls down the tracks.</div>\n",
       "<div>A train sitting on some train tracks with people taking pictures</div>\n",
       "<div>A black train is stopped on the tracks.</div>\n",
       "<div>A black train engine on tracks next to buildings.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/548597</div><img src=\"http://images.cocodataset.org/train2017/000000548597.jpg\" style=\"max-width: 200px\"><div>A train in front of several colorful houses.</div>\n",
       "<div>A train driving down tracks near a building.</div>\n",
       "<div>a train sitting on the tracks next to a metal pole</div>\n",
       "<div>The train is parked on the railroad tracks.</div>\n",
       "<div>A train parked on an old track beside colorful buildings.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/150091</div><img src=\"http://images.cocodataset.org/train2017/000000150091.jpg\" style=\"max-width: 200px\"><div>there is a old train that is coming up the tracks</div>\n",
       "<div>A yellow and red train traveling down train tracks.</div>\n",
       "<div>A train sits on train tracks in front of some buildings.</div>\n",
       "<div>Train going down a track next to big buildings.</div>\n",
       "<div>A train sitting on the tracks next to a platform.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/477646</div><img src=\"http://images.cocodataset.org/train2017/000000477646.jpg\" style=\"max-width: 200px\"><div>a blue train is on a set of tracks</div>\n",
       "<div>A narrow train pulls into the station in the rain.</div>\n",
       "<div>A blue train near a platform while it is snowing.</div>\n",
       "<div>A blue train pulls into a station in the snow.</div>\n",
       "<div>a black and blue train a sign and tracks</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/322049</div><img src=\"http://images.cocodataset.org/train2017/000000322049.jpg\" style=\"max-width: 200px\"><div>a train on a train track with buildings in the background</div>\n",
       "<div>A train pulls up to a platform by the rails.</div>\n",
       "<div>A train that is riding on the tracks near the street.</div>\n",
       "<div>A train sitting next to a loading platform near tall buildings.</div>\n",
       "<div>A train on tracks near buildings and a boarding platform.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(query_caption)\n",
    "HTML(show_images([images[idx]['cocoid'] for idx in similarity_argsort[-5:][::-1]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These aren't terribly inspiring, because it's immediately obvious that for all but one, the train isn't brown... the listener \"doesn't get it\". If that's important, then we probably need better data (VG). Is there a simple way to filter those by what actually applies? How about argmaxes(p(img|caption))?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1a: Use captioning model to find images that match caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrec import onmt_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_cap = onmt_model_2.models['coco_cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(str(paths.imgdata_h5_all))\n",
    "\n",
    "def load_vecs(imgids, num_objs=36, feature_dim=2048):\n",
    "    batch_size = len(imgids)\n",
    "    vecs = np.empty((num_objs, batch_size, feature_dim))\n",
    "    for i, idx in enumerate(imgids):\n",
    "        vecs[:, i, :] = f[str(idx)][:]\n",
    "    return Variable(torch.FloatTensor(vecs), volatile=True)\n",
    "\n",
    "\n",
    "def encode_vecs(self, vecs):\n",
    "    # vecs: objs x batch_size x feature_dim\n",
    "    mean_feature = torch.mean(vecs, dim=0)  # batch_size x feature_dim\n",
    "\n",
    "    # Construct the hidden and cell states.\n",
    "    hidden_state = F.tanh(self.init_hidden(mean_feature))\n",
    "    cell_state = F.tanh(self.init_cell(mean_feature))\n",
    "    # hidden_state: batch_size x rnn_size\n",
    "\n",
    "    # To make this look like the output of a sequence RNN, states need to\n",
    "    # have an extra first dimension (per decoder layer) and be packed in a\n",
    "    # tuple.\n",
    "\n",
    "    enc_final = (\n",
    "        hidden_state.unsqueeze(0),\n",
    "        cell_state.unsqueeze(0)\n",
    "    )\n",
    "\n",
    "    return enc_final, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shower with a blue mat on the floor in front of it\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1>Captioning Model</h1><div style=\"display: inline-block;\"><div>train/356474</div><img src=\"http://images.cocodataset.org/train2017/000000356474.jpg\" style=\"max-width: 200px\"><div>A brightly lit bathroom features a green toilet and a geometric pattern.</div>\n",
       "<div>A bed spring lies in a large bathroom.</div>\n",
       "<div>An empty mattress spring and toilet in a otherwise empty room.</div>\n",
       "<div>Interior scene  of an old bathroom with a large mat on the floor.</div>\n",
       "<div>A floor mat on a bath room floor.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/308423</div><img src=\"http://images.cocodataset.org/train2017/000000308423.jpg\" style=\"max-width: 200px\"><div>white bathroom with shower in the corner and tiolet</div>\n",
       "<div>A bathroom shower stall with a toilet and weight scale.</div>\n",
       "<div>Residential bathroom in blue toned theme with corner shower stall. </div>\n",
       "<div>A walk in shower behind the door of a bathroom</div>\n",
       "<div>A nice bathroom being illuminated by the moonlight.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/466800</div><img src=\"http://images.cocodataset.org/train2017/000000466800.jpg\" style=\"max-width: 200px\"><div>A view of a fancy spa like bathroom with a blue tiled tub.</div>\n",
       "<div>Different types of tiles are on the walls, floor and tub.</div>\n",
       "<div>Large modern bathroom with jacuzzi in a house.</div>\n",
       "<div>A modern bathtub in a bathroom is displayed.</div>\n",
       "<div>A nice bathroom with a standalone shower and a shower curtain.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/368284</div><img src=\"http://images.cocodataset.org/train2017/000000368284.jpg\" style=\"max-width: 200px\"><div>a toilet next to a shower with a curtain</div>\n",
       "<div>A toilet sitting next to a shower with a white curtain.</div>\n",
       "<div>The shower is right beside of the toilet in this bathroom.</div>\n",
       "<div>a small bathroom with a little white toilet in it</div>\n",
       "<div>a bathroom with a shower, toilet and shower curtain</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/253435</div><img src=\"http://images.cocodataset.org/train2017/000000253435.jpg\" style=\"max-width: 200px\"><div>A bathroom features a door with a window, a towel rack, a stack of towls and cabinets.</div>\n",
       "<div>The bathroom has towels on the floor and on the wall</div>\n",
       "<div>The wet suit is hanging in the shower.</div>\n",
       "<div>Clean towels are sitting near a shower in a bathroom.</div>\n",
       "<div>A bathroom located near outside, with many towels</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/581863</div><img src=\"http://images.cocodataset.org/train2017/000000581863.jpg\" style=\"max-width: 200px\"><div>Bathroom with tiled floor, radiator, shower and bathtub.</div>\n",
       "<div>A bathroom has a radiator by the wall.</div>\n",
       "<div>A basic white bathroom, with shower and toilet.</div>\n",
       "<div>A bathroom showing a shower stall tub combination with a white ceramic floor.</div>\n",
       "<div>The bathroom shows a toilet, radiator, tub, and closet.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/290410</div><img src=\"http://images.cocodataset.org/train2017/000000290410.jpg\" style=\"max-width: 200px\"><div>A restroom with a black seat on the toilet next to a piles of shoes.</div>\n",
       "<div>White boots and plastic pieces on the bathroom floor.</div>\n",
       "<div>A broken item is scattered on the floor of a bathroom.</div>\n",
       "<div>The accessories are placed on the bathroom floor.</div>\n",
       "<div>A pair of white boots on the floor of a bathroom.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/177476</div><img src=\"http://images.cocodataset.org/train2017/000000177476.jpg\" style=\"max-width: 200px\"><div>a blue room with a few things in it</div>\n",
       "<div>A cat bed on the floor of a blue room.</div>\n",
       "<div>a room with some blue walls and a kitty bed on the floor </div>\n",
       "<div>A room with blue walls and a dog house.</div>\n",
       "<div>There is a pet bed in a blue room.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/358675</div><img src=\"http://images.cocodataset.org/train2017/000000358675.jpg\" style=\"max-width: 200px\"><div>a room with a floor mat that has two animal feeding bowls on it, one for food and one for water.</div>\n",
       "<div>A wall divider is made of several long ribbons.</div>\n",
       "<div>What appears to be a refrigerator covered in strange, wavy material.</div>\n",
       "<div>A curtain made of red and white ribbons covers a refrigerator </div>\n",
       "<div>a pair of pet bowls on a mat is next to a screen</div></div>\n",
       "<div style=\"display: inline-block;\"><div>val/396295</div><img src=\"http://images.cocodataset.org/train2017/000000396295.jpg\" style=\"max-width: 200px\"><div>A bathroom shower with towel hanging from the door.</div>\n",
       "<div>A bathroom scene with a shower and toilet in view</div>\n",
       "<div>A shower with a sliding glass door in a small bathroom.</div>\n",
       "<div>A small dirty bathroom with walk in shower and toilet</div>\n",
       "<div>A white toilet and a shower in a room.</div></div><h1>Text Similarity</h1><div style=\"display: inline-block;\"><div>train/71222</div><img src=\"http://images.cocodataset.org/train2017/000000071222.jpg\" style=\"max-width: 200px\"><div>A large shower head in a bathroom shower.</div>\n",
       "<div>A tiled shower with a large shower head</div>\n",
       "<div>The shower head has a blue light behind it.</div>\n",
       "<div>A shower head and a shower shelf with various toiletries.</div>\n",
       "<div>Two shower heads in a shower along with a shelf of products.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/310807</div><img src=\"http://images.cocodataset.org/train2017/000000310807.jpg\" style=\"max-width: 200px\"><div>A bathroom with a walk in shower next to a toilet and a sink.</div>\n",
       "<div>Over head photo of a glass corner shower and sink on a checkered floor.</div>\n",
       "<div>this bathroom has an all glass shower and tile floor</div>\n",
       "<div>A bathroom with black and white floor tile and a standing shower.</div>\n",
       "<div>The restroom has a checkered floor, shower, sink, and toilet.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/109561</div><img src=\"http://images.cocodataset.org/train2017/000000109561.jpg\" style=\"max-width: 200px\"><div>A modern bathroom with a round shower unit in the corner.</div>\n",
       "<div>That looks like some kind of futuristic shower with a lot of gadgets.</div>\n",
       "<div>there is a shower with a blue light in it</div>\n",
       "<div>a bathroom with a wall n shower that has glass</div>\n",
       "<div>a bathroom with a shower sitting inside of it </div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/233997</div><img src=\"http://images.cocodataset.org/train2017/000000233997.jpg\" style=\"max-width: 200px\"><div>A welcome mat placed at the foot of a closed door.</div>\n",
       "<div>A black doorway with a welcome mat in front of it.</div>\n",
       "<div>a door mat in front of a door with a vase near by</div>\n",
       "<div>A black door with a welcome mat and yellow vase next to it.</div>\n",
       "<div>A welcome mat and a yellow vase outside apartment 407.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/249356</div><img src=\"http://images.cocodataset.org/train2017/000000249356.jpg\" style=\"max-width: 200px\"><div>A bathroom with a toilet, shower stall and a mirror.</div>\n",
       "<div>A bathroom toilet next to a blue rug.</div>\n",
       "<div>The small bathroom has a shower, a toilet, and a blue shower mat.</div>\n",
       "<div>a tiled bathroom with a toilet and bath tub</div>\n",
       "<div>A bathroom has a toilet and bathtub with shower in it. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/372775</div><img src=\"http://images.cocodataset.org/train2017/000000372775.jpg\" style=\"max-width: 200px\"><div>A full view of a bathroom with the shower and mirror next to it. </div>\n",
       "<div>Glass enclosed shower with white tile walls,brown floor</div>\n",
       "<div>An industrial type bathroom with an open shower.</div>\n",
       "<div>A walk in shower sitting next to a bathroom sink.</div>\n",
       "<div>A standing shower with a see through glass door.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/262284</div><img src=\"http://images.cocodataset.org/train2017/000000262284.jpg\" style=\"max-width: 200px\"><div>A full view of a shower with glass.</div>\n",
       "<div>A walk in shower with a hand held shower head.</div>\n",
       "<div>A bathroom shower stall with a shower head.</div>\n",
       "<div>a glass walled shower in a home bathroom</div>\n",
       "<div>a see through glass shower in a bathroom </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/184866</div><img src=\"http://images.cocodataset.org/train2017/000000184866.jpg\" style=\"max-width: 200px\"><div>a female in a black shirt a toilet and a shower head</div>\n",
       "<div>A woman sitting on the floor next to a toilet. </div>\n",
       "<div>A woman holds a shower head while sitting on the floor of a bathroom in her clothes.</div>\n",
       "<div>Woman sitting on floor with feet on wall next to bathroom commode.</div>\n",
       "<div>A disoriented woman sits on a bathroom floor holding a shower sprayer.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/243386</div><img src=\"http://images.cocodataset.org/train2017/000000243386.jpg\" style=\"max-width: 200px\"><div>A shower equipped for a physically challenged person with a shower chair</div>\n",
       "<div>A stool is inside of a walk in shower.</div>\n",
       "<div>A nicely kept shower with a seat inside.</div>\n",
       "<div>A bathroom with a tiled shower is shown.</div>\n",
       "<div>A walk in shower in a bathroom next to a mirror.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/233737</div><img src=\"http://images.cocodataset.org/train2017/000000233737.jpg\" style=\"max-width: 200px\"><div>A white sink and a shower in a small room.</div>\n",
       "<div>A white shower that has open glass doors.</div>\n",
       "<div>A shower with a glass door in the bathroom beside the sink and toilet. </div>\n",
       "<div>A view of a bathroom with black tile floor and a stand up shower with a glass door. </div>\n",
       "<div>A bathroom with a shower with see through floors . </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query_caption = \"a brown train pulls into the tracks next to some colorful buildings\"\n",
    "# query_caption = \"a train on the tracks in front of blue buildings\"\n",
    "query_caption = \"a shower with a blue mat on the floor in front of it\"\n",
    "query_vec = cap_vectorizer.transform([query_caption])\n",
    "similarity = caption_vecs.dot(query_vec.T).A.ravel()\n",
    "\n",
    "n_similar = 500\n",
    "image_set = [images[idx]['cocoid'] for idx in np.argsort(similarity)[-n_similar:][::-1]]\n",
    "vecs = load_vecs(image_set)\n",
    "encoder_final, memory_bank = encode_vecs(coco_cap.model.encoder, vecs)\n",
    "\n",
    "def eval_logprobs_varying_image(model, imgids, tgt_field, tgt_text):\n",
    "    batch_size = len(imgids)\n",
    "\n",
    "    vecs = load_vecs(image_set)\n",
    "    encoder_final, memory_bank = encode_vecs(coco_cap.model.encoder, vecs)\n",
    "\n",
    "    decoder_state = model.decoder.init_decoder_state(vecs, memory_bank=memory_bank, encoder_final=encoder_final)\n",
    "#    decoder_state.repeat_beam_size_times(batch_size)\n",
    "#    memory_bank = memory_bank.repeat(1, batch_size, 1)\n",
    "\n",
    "    # \"process\" handles padding and numericalization\n",
    "    tgt = tgt_field.process([tgt_text] * batch_size, device=-1, train=False)\n",
    "    pad_idx = tgt_field.vocab.stoi[tgt_field.pad_token]\n",
    "    \n",
    "    # Decoder wants an extra dim for extra features.\n",
    "    dec_out, dec_states, attn = model.decoder(tgt[:-1].unsqueeze(2), memory_bank, decoder_state)\n",
    "    logits = model.generator(dec_out).contiguous()\n",
    "    seq_len, batch_size_2, num_vocab = logits.shape\n",
    "    assert batch_size == batch_size_2\n",
    "    losses = F.nll_loss(\n",
    "        logits.view(seq_len * batch_size, num_vocab), tgt[1:].view(seq_len * batch_size), reduce=False\n",
    "    ).view(seq_len, batch_size)\n",
    "    return losses.data.sum(0)\n",
    "#     mask = tgt[1:].eq(pad_idx)\n",
    "#     losses = losses.masked_fill(mask, 0).data.sum(0)\n",
    "#     length = (~mask.data).long().sum(0)\n",
    "#     return losses# / length.float()\n",
    "\n",
    "losses_by_img = eval_logprobs_varying_image(\n",
    "    coco_cap.model,\n",
    "    image_set,\n",
    "    coco_cap.fields['tgt'],\n",
    "    coco_cap.fields['tgt'].preprocess(query_caption)\n",
    ").numpy()\n",
    "# losses_by_img\n",
    "\n",
    "print(query_caption)\n",
    "HTML(\n",
    "    \"<h1>Captioning Model</h1>\"\n",
    "    + show_images(np.array(image_set)[np.argsort(losses_by_img)[:10]])\n",
    "    + \"<h1>Text Similarity</h1>\"\n",
    "    + show_images(image_set[:10])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>restval/241948</div><img src=\"http://images.cocodataset.org/train2017/000000241948.jpg\" style=\"max-width: 200px\"><div>A train sitting on train tracks next to a  small rural road.</div>\n",
       "<div>There is a train sitting on some train tracks.</div>\n",
       "<div> A rusty old train on top of train tracks.</div>\n",
       "<div>a steam train travels through a park area </div>\n",
       "<div>an old ttrain sitting on some tracks behind a train </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/375248</div><img src=\"http://images.cocodataset.org/train2017/000000375248.jpg\" style=\"max-width: 200px\"><div>A large long train on a steel track.</div>\n",
       "<div>A red and green train traveling down tracks.</div>\n",
       "<div>The train is stopping on the railroad tracks.</div>\n",
       "<div>A train that is traveling down some railroad tracks. </div>\n",
       "<div>A train sitting on train tracks next to a platform.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/52983</div><img src=\"http://images.cocodataset.org/train2017/000000052983.jpg\" style=\"max-width: 200px\"><div>A train that has people standing by the railing on the front.</div>\n",
       "<div>A bunch of people that are on the front of a train.</div>\n",
       "<div>Some people stand on and near a blue train near trees.</div>\n",
       "<div>A blue train with a few people on the front of it.</div>\n",
       "<div>Group of men standing on the front of a blue train together. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/470840</div><img src=\"http://images.cocodataset.org/train2017/000000470840.jpg\" style=\"max-width: 200px\"><div>A train traveling down train tracks through a lush green forest.</div>\n",
       "<div>Wooded area with small railroad approaching on the track</div>\n",
       "<div>THERE IS A TRAIN ON THE TRAVCKS IN THE GRASS</div>\n",
       "<div>A small train advancing on the tracks thru a park.</div>\n",
       "<div>A train is approaching a bend in the train tracks.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/39276</div><img src=\"http://images.cocodataset.org/train2017/000000039276.jpg\" style=\"max-width: 200px\"><div>An old rusted train engine on train tracks.</div>\n",
       "<div>A photo of an old, rusty train sitting on tracks.</div>\n",
       "<div>an old rusty train sitting on the tracks </div>\n",
       "<div>A vintage train sits on wooden tracks in a field.</div>\n",
       "<div>a close up of a train on a train track</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/106973</div><img src=\"http://images.cocodataset.org/train2017/000000106973.jpg\" style=\"max-width: 200px\"><div>A train approaching on the tracks during the day.</div>\n",
       "<div>A TRAIN IS ON THE TRAIN TRACKS </div>\n",
       "<div>A train is coming down the tracks next to a heavily wooded area.</div>\n",
       "<div>A green and yellow train going down a track. </div>\n",
       "<div>A trolley train is on the split tracks.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/373373</div><img src=\"http://images.cocodataset.org/train2017/000000373373.jpg\" style=\"max-width: 200px\"><div>a large train that is on train track with people around</div>\n",
       "<div>A group of people sitting on the ground next to a train.</div>\n",
       "<div>a woman is sitting near a red train</div>\n",
       "<div>Several people gathered near a train and the tracks on the ground and on the train. </div>\n",
       "<div>The train is driving through the tracks of a small village</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/458970</div><img src=\"http://images.cocodataset.org/train2017/000000458970.jpg\" style=\"max-width: 200px\"><div>A train on the tracks with people standing and walking by it </div>\n",
       "<div>A crowd of people are walking in front of a train.</div>\n",
       "<div>A stopped train at a train crossing with people crossing the tracks.</div>\n",
       "<div>A black train parked at a train station as people walk across the train tracks.</div>\n",
       "<div>People at a train station, gathering around a black locomotive. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/362351</div><img src=\"http://images.cocodataset.org/train2017/000000362351.jpg\" style=\"max-width: 200px\"><div>The control center of a train engine traveling down train tracks.</div>\n",
       "<div>the control room of a train on a train track</div>\n",
       "<div>The control room for a train that is still on the tracks. </div>\n",
       "<div>a train sitting on the tracks with a good view of the instrument panel</div>\n",
       "<div>A train sits on the tracks, surrounded by the woods.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/7666</div><img src=\"http://images.cocodataset.org/train2017/000000007666.jpg\" style=\"max-width: 200px\"><div>The blue train is passing through a wooded area. </div>\n",
       "<div>a blue train in the middle of a forest</div>\n",
       "<div>green valley with a creek and blue train</div>\n",
       "<div>A train that is driving by on a hill side.</div>\n",
       "<div>a blue train is coming down some tracks</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(show_images(np.array(image_set)[np.argsort(losses_by_img)[-10:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1c: Visual Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: relatively similar images that are most different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foil_set(*, stimulus, caption, rs):\n",
    "    similar_images = get_similar_images(caption, n=10)\n",
    "    if stimulus not in similar_images:\n",
    "        print(\"Inserting\", stimulus, 'into foil set')\n",
    "        similar_images[-1] = stimulus\n",
    "    rs.shuffle(similar_images)\n",
    "    return similar_images\n",
    "stimulus = trial_data[1]['stimulus']\n",
    "get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=np.random.RandomState(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(1234)\n",
    "foil_sets = {\n",
    "    stimulus: get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=rs)\n",
    "    for stimulus in sorted(concat_captions.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group tasks so that (1) each annotator never gets the same target image twice and (2) each annotator never sees two captions from the same person. The latter criterion cannot always be met, though, since the number of annotators may not evenly divide the number of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffled(lst):\n",
    "    lst = lst[:]\n",
    "    random.shuffle(lst)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    trials_by_img = toolz.groupby('stimulus', shuffled(trial_data))\n",
    "    annotators = []\n",
    "    while not any(len(trials) == 0 for trials in trials_by_img.values()):\n",
    "        trials_for_annotator = []\n",
    "        participants_seen_by_annotator = set()\n",
    "        for stimulus, trials in trials_by_img.items():\n",
    "            for i in range(len(trials)):\n",
    "                participant = trials[i]['participant']\n",
    "                if participant not in participants_seen_by_annotator:\n",
    "                    trials_for_annotator.append(trials.pop(i))\n",
    "                    participants_seen_by_annotator.add(participant)\n",
    "                    break\n",
    "            else:\n",
    "#                 print(\"Have to use the same participant again\")\n",
    "                trials_for_annotator.append(trials.pop(0))\n",
    "\n",
    "        annotators.append(shuffled(trials_for_annotator))\n",
    "    if all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators):\n",
    "        break\n",
    "    assert all(len(trials) == 0 for trials in trials_by_img.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = annotators[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_by_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never gets the same target image twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('stimulus', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never sees two captions from the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(trials) for trials in annotators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_task(stimulus, text):\n",
    "    foil_set = foil_sets[stimulus]\n",
    "    return dict(\n",
    "        description=text,\n",
    "        correct_idx=foil_set.index(stimulus),\n",
    "        images=[id2url[idx] for idx in foil_set]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = annotators[0][0]\n",
    "make_task(trial['stimulus'], trial['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_task = pd.DataFrame([\n",
    "    json.dumps([make_task(trial['stimulus'], trial['text']) for trial in annotator_trials])\n",
    "    for annotator_trials in annotators], columns=['task'])\n",
    "guesses_task.iloc[:1].to_csv(str(paths.data / 'anno-tasks' / 'guesses_test.csv'), index=False)\n",
    "guesses_task.iloc[1:].to_csv(str(paths.data / 'anno-tasks' / 'guesses_remain.csv'), index=False)\n",
    "guesses_task.to_csv(str(paths.data / 'anno-tasks' / 'guesses.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MTurk results so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = list((paths.data / 'mturk').glob('*-guesses.csv'))\n",
    "batched_guesses_results = (\n",
    "    pd.concat([pd.read_csv(str(f)) for f in result_files], axis=0, ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(batched_guesses_results['WorkTimeInSeconds']/60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_dur(results):\n",
    "    pages = json.loads(results)\n",
    "    try:\n",
    "        first_guess = pages[0]['guesses'][0]['timestamp']\n",
    "        last_guess = pages[-1]['guesses'][-1]['timestamp']\n",
    "        return (last_guess - first_guess) / 1000 / 60\n",
    "    except IndexError:\n",
    "        # Something failed in the UI probably...\n",
    "        return None\n",
    "batched_guesses_results['Answer.results'].apply(get_active_dur).hist()\n",
    "batched_guesses_results['Answer.results'].apply(get_active_dur).describe()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_guesses_results[batched_guesses_results['Answer.results'].apply(lambda x: '\"guesses\":[]' in x)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_results = []\n",
    "for i, row in batched_guesses_results.iterrows():\n",
    "    for page in json.loads(row['Answer.results']):\n",
    "#         print(page)\n",
    "        guess_indices = [guess['idx'] for guess in page['guesses']]\n",
    "        if len(guess_indices) == 0:\n",
    "            print(\"UI fail\", row['WorkerId'])\n",
    "            continue\n",
    "#         guessed_right_sometime = [row.correctIdx in row.guess_indices for row in mturk_nafc_results.itertuples()]\n",
    "        stimulus_url = [img for img in page['images'] if img['isCorrect']][0]['url']\n",
    "        guesses_results.append(dict(\n",
    "            guesser=row['WorkerId'],\n",
    "            description=page['description'],\n",
    "            num_guesses=len(guess_indices),\n",
    "            stimulus_url=stimulus_url))\n",
    "pd.DataFrame(guesses_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_responses_by_caption = mturk_nafc_results.groupby('Answer.description').size().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tasks remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials_todo = [trial for trial in trial_data if num_responses_by_caption.get(trial['text'], 0) < 3]\n",
    "# len(trial_data), len(trials_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# while True:\n",
    "#     out_fn = paths.data / 'anno-tasks' / f'{datetime.date.today().isoformat()}-{i}-nAFC.csv'\n",
    "#     if not out_fn.exists():\n",
    "#         break\n",
    "#     i += 1\n",
    "# out_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = np.random.RandomState(1234)\n",
    "# pd.DataFrame([make_task(trial, rs) for trial in trials_todo]).to_csv(out_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the actual HIT text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "html = Template(open(paths.top_level / 'HITs' / '2018-05-04-image-description-match.jinja.html').read()).render(dict(\n",
    "    description='${description}',\n",
    "    images=['${image_%d_url}' % i for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html2 = html\n",
    "trial = trial_data[18+7*9]\n",
    "for k, v in make_task(trial['stimulus'], trial['text']).items():\n",
    "    html2 = html2.replace('${' + k + '}', str(v))\n",
    "HTML('<div style=\"height: 1000px; position: relative;\">'+html2+'</div>')\n",
    "# print(html2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.Popen('pbcopy', stdin=subprocess.PIPE).communicate(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MTurk results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results.groupby('Answer.description').num_guesses.mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mturk_nafc_results['WorkTimeInSeconds'][mturk_nafc_results['WorkTimeInSeconds'] < 5*60] / 60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(mturk_nafc_results['WorkTimeInSeconds'] / 60) * 9/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    15 # participants\n",
    "    * 3 # conditions per participant\n",
    "    * 3 # captions per condition\n",
    "    - 1 # image not shown\n",
    ") * 3 # annotators per description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    * .24 # reward per annotator\n",
    ") * 1.2 # MTurk 20% fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the same worker see the same target image multiple times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data.iterrows())[1]['Input.image_0_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['target_image_url'] = [row['Input.image_'+str(row['correctIdx'])+\"_url\"] for _, row in mturk_nafc_results.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_worker_image_pairs = set()\n",
    "for worker_id, data in mturk_nafc_results.groupby('WorkerId'):\n",
    "    target_images = [row['target_image_url'] for _, row in data.iterrows()]\n",
    "    if len(target_images) != len(set(target_images)):\n",
    "#         print(worker_id)\n",
    "        value_counts = pd.Series(target_images).value_counts()\n",
    "        value_counts = value_counts[value_counts > 1]\n",
    "#         print(value_counts)\n",
    "        for img in value_counts.index:\n",
    "            bad_worker_image_pairs.add((worker_id, img))\n",
    "bad_worker_image_pairs\n",
    "\n",
    "annotation_row_is_bad = [\n",
    "    (row['WorkerId'], row['target_image_url']) in bad_worker_image_pairs\n",
    "    for _, row in mturk_nafc_results.iterrows()\n",
    "]\n",
    "mturk_nafc_results['row_is_bad'] = annotation_row_is_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['row_is_bad'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_results = mturk_nafc_results[~mturk_nafc_results['row_is_bad']].rename(columns={'Answer.description': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mturk_nafc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(guess_results), len(trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    guess_results.rename(columns={'WorkerId': 'guesser'}).drop(['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'RequesterAnnotation', 'guesses'], axis=1),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    pd.DataFrame(guesses_results).rename(columns={'description': 'text'}),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data.to_csv('annotator_level_data_2018-05-22v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(annotator_level_data['num_guesses'] == 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(model = lmer(num_guesses ~ condition + (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(null_model = lmer(num_guesses ~ (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(pbkrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "(kr <- KRmodcomp(model, null_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(glm.full = glmer(num_guesses ~ condition + (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data, family=poisson()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "(glm.null = glmer(num_guesses ~ (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data, family=poisson()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#confint(glm.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "anova(glm.full, glm.null, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(nb_model = glmer.nb(num_guesses ~ condition + (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(nb_model.null = glmer.nb(num_guesses ~ (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "anova(nb_model, nb_model.null, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([dict(trial, specificity=specificity_lookup[trial['text'].strip()]) for trial in trial_data])\n",
    "for col in ['condition', 'participant']:\n",
    "    results[col] = results[col].astype('category')\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('condition').specificity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trial_data).sample(frac=1.0).sort_values('stimulus').to_csv('trial_data_by_stimulus.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

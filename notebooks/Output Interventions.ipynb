{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/code/textrec\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/textrec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import toolz\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading COCO captions\n",
      "Loading COCO id2url\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ONMT models...\n",
      "coco_lm_adam_acc_46.00_ppl_16.32_e10_nooptim.pt\n",
      "Loading model parameters.\n",
      "coco_cap_adam_acc_48.73_ppl_12.56_e10_nooptim.pt\n",
      "Loading model parameters.\n",
      "Ready.\n",
      "Loading SpaCy...done\n",
      "Loading COCO captions\n",
      "Loading COCO id2url\n",
      "Done\n",
      "Loading SpaCy...done\n"
     ]
    }
   ],
   "source": [
    "from textrec.paths import paths\n",
    "from textrec import analysis_util, util, notebook_util, automated_analyses\n",
    "reload(analysis_util), reload(util), reload(notebook_util), reload(automated_analyses)\n",
    "from textrec.notebook_util import images, id2img, id2url, show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import onmt.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of writing experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites: Run `textrec.logs_to_csv {batch_name}` and `textrec.gruntwork {batch_name}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 'spec1'\n",
    "experiment_level_data = pd.read_csv(paths.analyzed / f'experiment_{batch}.csv')\n",
    "block_level_data = pd.read_csv(paths.analyzed / f'block_{batch}.csv')\n",
    "trial_level_data = pd.read_csv(paths.analyzed / f'trial_withmanual_{batch}.csv')\n",
    "helpful_ranks_by_condition = pd.read_csv(paths.analyzed / f'helpful_ranks_by_condition_{batch}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concept**: One reason that writing is difficult is because we have to \"simulate the reader\", imagining what's going on in their mind, so that we can construct the desired concept there. A system could help by simulating the reader for us and giving us some peek into what our writing is doing inside their minds. That peek could look like:\n",
    "\n",
    "* what image is the writing conjuring in their mind? -> *show an image*\n",
    "* what inferences are they drawing? -> *show statements that are entailed by our writing*\n",
    "* what questions do they have? -> *show questions that writing similar to ours answers in different ways*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See \"Chapter Intros\" for more fleshed out concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_captions = {img['cocoid']: util.join_captions(img) for img in notebook_util.images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vectorizer, caption_vecs = util.get_vectorized_captions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123287, 9952)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_captions = {stimulus: '\\n'.join(toolz.pluck('text', trials))\n",
    "                   for stimulus, trials in toolz.groupby('stimulus', trial_data).items()}\n",
    "concat_captions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>train/352082</div><img src=\"http://images.cocodataset.org/train2017/000000352082.jpg\" style=\"max-width: 200px\"><div>A train traveling down railroad tracks next to a train station.</div>\n",
       "<div>People standing next to a train as it pulls down the tracks.</div>\n",
       "<div>A train sitting on some train tracks with people taking pictures</div>\n",
       "<div>A black train is stopped on the tracks.</div>\n",
       "<div>A black train engine on tracks next to buildings.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/548597</div><img src=\"http://images.cocodataset.org/train2017/000000548597.jpg\" style=\"max-width: 200px\"><div>A train in front of several colorful houses.</div>\n",
       "<div>A train driving down tracks near a building.</div>\n",
       "<div>a train sitting on the tracks next to a metal pole</div>\n",
       "<div>The train is parked on the railroad tracks.</div>\n",
       "<div>A train parked on an old track beside colorful buildings.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/150091</div><img src=\"http://images.cocodataset.org/train2017/000000150091.jpg\" style=\"max-width: 200px\"><div>there is a old train that is coming up the tracks</div>\n",
       "<div>A yellow and red train traveling down train tracks.</div>\n",
       "<div>A train sits on train tracks in front of some buildings.</div>\n",
       "<div>Train going down a track next to big buildings.</div>\n",
       "<div>A train sitting on the tracks next to a platform.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/477646</div><img src=\"http://images.cocodataset.org/train2017/000000477646.jpg\" style=\"max-width: 200px\"><div>a blue train is on a set of tracks</div>\n",
       "<div>A narrow train pulls into the station in the rain.</div>\n",
       "<div>A blue train near a platform while it is snowing.</div>\n",
       "<div>A blue train pulls into a station in the snow.</div>\n",
       "<div>a black and blue train a sign and tracks</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/322049</div><img src=\"http://images.cocodataset.org/train2017/000000322049.jpg\" style=\"max-width: 200px\"><div>a train on a train track with buildings in the background</div>\n",
       "<div>A train pulls up to a platform by the rails.</div>\n",
       "<div>A train that is riding on the tracks near the street.</div>\n",
       "<div>A train sitting next to a loading platform near tall buildings.</div>\n",
       "<div>A train on tracks near buildings and a boarding platform.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>val/338986</div><img src=\"http://images.cocodataset.org/val2017/000000338986.jpg\" style=\"max-width: 200px\"><div>A train pulls up along some buildings. </div>\n",
       "<div>A blue train is coming down the tracks</div>\n",
       "<div>A photo of a train station with the train pulling in.</div>\n",
       "<div>a blue and yellow train a building and some cars</div>\n",
       "<div>a group of cars next to a train</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/132878</div><img src=\"http://images.cocodataset.org/train2017/000000132878.jpg\" style=\"max-width: 200px\"><div>A blue and yellow train traveling down train tracks.</div>\n",
       "<div>A blue, red and yellow train traveling through a wide set of tracks.</div>\n",
       "<div>Red yellow and blue train rides along train tracks</div>\n",
       "<div>A colorful train pulls into a multi track station.</div>\n",
       "<div>A train getting ready to go down the train tracks. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>val/138196</div><img src=\"http://images.cocodataset.org/train2017/000000138196.jpg\" style=\"max-width: 200px\"><div>A train is driving down the tracks in front of a building.</div>\n",
       "<div>a train that is parked on some train tracks</div>\n",
       "<div>A train that is pulling into a train station. </div>\n",
       "<div>A yellow and red train engine pulling into a station.</div>\n",
       "<div>a train pulls up to a platform for people to board.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/537139</div><img src=\"http://images.cocodataset.org/train2017/000000537139.jpg\" style=\"max-width: 200px\"><div>There is a train, buildings, and cars in the mountains.</div>\n",
       "<div>A train pulling into a train station surrounded by buildings.</div>\n",
       "<div>A train on the tracks by a building outside.</div>\n",
       "<div>A cargo train is moving traveling through the city.</div>\n",
       "<div>A train runs on tracks behind some buildings and a parking lot.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/372234</div><img src=\"http://images.cocodataset.org/train2017/000000372234.jpg\" style=\"max-width: 200px\"><div>A train pulls into the train station in a metropolis.</div>\n",
       "<div>The commuter train is traveling below the tunnel.</div>\n",
       "<div>A train on the railroad tracks has a yellow door on the front.</div>\n",
       "<div>There is a train that is on the tracks</div>\n",
       "<div>A commuter train is seen with city buildings in the background.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similar_images(caption, n=10):\n",
    "    query_vec = cap_vectorizer.transform([caption])\n",
    "    similarity = caption_vecs.dot(query_vec.T).A.ravel()\n",
    "    return [images[idx]['cocoid'] for idx in np.argsort(similarity)[-n:][::-1]]\n",
    "#query_caption = concat_captions[396295].replace('wine', '') #trial_data[0]['text']\n",
    "# query_caption = \"a rusty and dirty shower in the bathroom has a tan towel over its handle\"\n",
    "# query_caption = \"a sliding glass shower door with a bath mat hanging on it\"\n",
    "# query_caption = \"a closed shower door with crackled glass encases some hanging colored toiletries\"\n",
    "query_caption = \"a brown train pulls into the tracks next to some colorful buildings\"\n",
    "# print(query_caption)\n",
    "HTML(show_images(get_similar_images(query_caption)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_caption = \"a brown train pulls into the tracks next to some colorful buildings\"\n",
    "query_vec = cap_vectorizer.transform([query_caption])\n",
    "similarity = caption_vecs.dot(query_vec.T).A.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How similar should we count as similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_argsort = np.argsort(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>train/417715</div><img src=\"http://images.cocodataset.org/train2017/000000417715.jpg\" style=\"max-width: 200px\"><div>A train traveling over a bridge next to a tall building.</div>\n",
       "<div>Cars are parked outside, not far from the highway.</div>\n",
       "<div>a view from a rooftop of parked cars and train station</div>\n",
       "<div>Many cars are parked along an empty highway.</div>\n",
       "<div>some train tracks some parked cars and a building</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(show_images([images[similarity_argsort[int(.978*len(similarity_argsort))]]['cocoid']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf similarity mixes relevant (trains at stations) with irrelevant (colorful kites). I wonder if we need visual similarity as well, or if just better caption similarity (e.g., sentence vectors, Transformer LM, etc.) would do it... or maybe better data, like Visual Genome? Let's push ahead though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: just the most similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a brown train pulls into the tracks next to some colorful buildings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>train/352082</div><img src=\"http://images.cocodataset.org/train2017/000000352082.jpg\" style=\"max-width: 200px\"><div>A train traveling down railroad tracks next to a train station.</div>\n",
       "<div>People standing next to a train as it pulls down the tracks.</div>\n",
       "<div>A train sitting on some train tracks with people taking pictures</div>\n",
       "<div>A black train is stopped on the tracks.</div>\n",
       "<div>A black train engine on tracks next to buildings.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/548597</div><img src=\"http://images.cocodataset.org/train2017/000000548597.jpg\" style=\"max-width: 200px\"><div>A train in front of several colorful houses.</div>\n",
       "<div>A train driving down tracks near a building.</div>\n",
       "<div>a train sitting on the tracks next to a metal pole</div>\n",
       "<div>The train is parked on the railroad tracks.</div>\n",
       "<div>A train parked on an old track beside colorful buildings.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/150091</div><img src=\"http://images.cocodataset.org/train2017/000000150091.jpg\" style=\"max-width: 200px\"><div>there is a old train that is coming up the tracks</div>\n",
       "<div>A yellow and red train traveling down train tracks.</div>\n",
       "<div>A train sits on train tracks in front of some buildings.</div>\n",
       "<div>Train going down a track next to big buildings.</div>\n",
       "<div>A train sitting on the tracks next to a platform.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/477646</div><img src=\"http://images.cocodataset.org/train2017/000000477646.jpg\" style=\"max-width: 200px\"><div>a blue train is on a set of tracks</div>\n",
       "<div>A narrow train pulls into the station in the rain.</div>\n",
       "<div>A blue train near a platform while it is snowing.</div>\n",
       "<div>A blue train pulls into a station in the snow.</div>\n",
       "<div>a black and blue train a sign and tracks</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/322049</div><img src=\"http://images.cocodataset.org/train2017/000000322049.jpg\" style=\"max-width: 200px\"><div>a train on a train track with buildings in the background</div>\n",
       "<div>A train pulls up to a platform by the rails.</div>\n",
       "<div>A train that is riding on the tracks near the street.</div>\n",
       "<div>A train sitting next to a loading platform near tall buildings.</div>\n",
       "<div>A train on tracks near buildings and a boarding platform.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(query_caption)\n",
    "HTML(show_images([images[idx]['cocoid'] for idx in similarity_argsort[-5:][::-1]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These aren't terribly inspiring, because it's immediately obvious that for all but one, the train isn't brown... the listener \"doesn't get it\". If that's important, then we probably need better data (VG). Is there a simple way to filter those by what actually applies? How about argmaxes(p(img|caption))?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1a: Use captioning model to find images that match caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrec import onmt_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_cap = onmt_model_2.models['coco_cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(str(paths.imgdata_h5_all))\n",
    "\n",
    "def load_vecs(imgids, num_objs=36, feature_dim=2048):\n",
    "    batch_size = len(imgids)\n",
    "    vecs = np.empty((num_objs, batch_size, feature_dim))\n",
    "    for i, idx in enumerate(imgids):\n",
    "        vecs[:, i, :] = f[str(idx)][:]\n",
    "    return Variable(torch.FloatTensor(vecs), volatile=True)\n",
    "\n",
    "\n",
    "def encode_vecs(self, vecs):\n",
    "    # vecs: objs x batch_size x feature_dim\n",
    "    mean_feature = torch.mean(vecs, dim=0)  # batch_size x feature_dim\n",
    "\n",
    "    # Construct the hidden and cell states.\n",
    "    hidden_state = F.tanh(self.init_hidden(mean_feature))\n",
    "    cell_state = F.tanh(self.init_cell(mean_feature))\n",
    "    # hidden_state: batch_size x rnn_size\n",
    "\n",
    "    # To make this look like the output of a sequence RNN, states need to\n",
    "    # have an extra first dimension (per decoder layer) and be packed in a\n",
    "    # tuple.\n",
    "\n",
    "    enc_final = (\n",
    "        hidden_state.unsqueeze(0),\n",
    "        cell_state.unsqueeze(0)\n",
    "    )\n",
    "\n",
    "    return enc_final, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shower with a blue mat on the floor in front of it\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1>Captioning Model</h1><div style=\"display: inline-block;\"><div>train/356474</div><img src=\"http://images.cocodataset.org/train2017/000000356474.jpg\" style=\"max-width: 200px\"><div>A brightly lit bathroom features a green toilet and a geometric pattern.</div>\n",
       "<div>A bed spring lies in a large bathroom.</div>\n",
       "<div>An empty mattress spring and toilet in a otherwise empty room.</div>\n",
       "<div>Interior scene  of an old bathroom with a large mat on the floor.</div>\n",
       "<div>A floor mat on a bath room floor.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/308423</div><img src=\"http://images.cocodataset.org/train2017/000000308423.jpg\" style=\"max-width: 200px\"><div>white bathroom with shower in the corner and tiolet</div>\n",
       "<div>A bathroom shower stall with a toilet and weight scale.</div>\n",
       "<div>Residential bathroom in blue toned theme with corner shower stall. </div>\n",
       "<div>A walk in shower behind the door of a bathroom</div>\n",
       "<div>A nice bathroom being illuminated by the moonlight.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/466800</div><img src=\"http://images.cocodataset.org/train2017/000000466800.jpg\" style=\"max-width: 200px\"><div>A view of a fancy spa like bathroom with a blue tiled tub.</div>\n",
       "<div>Different types of tiles are on the walls, floor and tub.</div>\n",
       "<div>Large modern bathroom with jacuzzi in a house.</div>\n",
       "<div>A modern bathtub in a bathroom is displayed.</div>\n",
       "<div>A nice bathroom with a standalone shower and a shower curtain.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/368284</div><img src=\"http://images.cocodataset.org/train2017/000000368284.jpg\" style=\"max-width: 200px\"><div>a toilet next to a shower with a curtain</div>\n",
       "<div>A toilet sitting next to a shower with a white curtain.</div>\n",
       "<div>The shower is right beside of the toilet in this bathroom.</div>\n",
       "<div>a small bathroom with a little white toilet in it</div>\n",
       "<div>a bathroom with a shower, toilet and shower curtain</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/253435</div><img src=\"http://images.cocodataset.org/train2017/000000253435.jpg\" style=\"max-width: 200px\"><div>A bathroom features a door with a window, a towel rack, a stack of towls and cabinets.</div>\n",
       "<div>The bathroom has towels on the floor and on the wall</div>\n",
       "<div>The wet suit is hanging in the shower.</div>\n",
       "<div>Clean towels are sitting near a shower in a bathroom.</div>\n",
       "<div>A bathroom located near outside, with many towels</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/581863</div><img src=\"http://images.cocodataset.org/train2017/000000581863.jpg\" style=\"max-width: 200px\"><div>Bathroom with tiled floor, radiator, shower and bathtub.</div>\n",
       "<div>A bathroom has a radiator by the wall.</div>\n",
       "<div>A basic white bathroom, with shower and toilet.</div>\n",
       "<div>A bathroom showing a shower stall tub combination with a white ceramic floor.</div>\n",
       "<div>The bathroom shows a toilet, radiator, tub, and closet.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/290410</div><img src=\"http://images.cocodataset.org/train2017/000000290410.jpg\" style=\"max-width: 200px\"><div>A restroom with a black seat on the toilet next to a piles of shoes.</div>\n",
       "<div>White boots and plastic pieces on the bathroom floor.</div>\n",
       "<div>A broken item is scattered on the floor of a bathroom.</div>\n",
       "<div>The accessories are placed on the bathroom floor.</div>\n",
       "<div>A pair of white boots on the floor of a bathroom.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/177476</div><img src=\"http://images.cocodataset.org/train2017/000000177476.jpg\" style=\"max-width: 200px\"><div>a blue room with a few things in it</div>\n",
       "<div>A cat bed on the floor of a blue room.</div>\n",
       "<div>a room with some blue walls and a kitty bed on the floor </div>\n",
       "<div>A room with blue walls and a dog house.</div>\n",
       "<div>There is a pet bed in a blue room.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/358675</div><img src=\"http://images.cocodataset.org/train2017/000000358675.jpg\" style=\"max-width: 200px\"><div>a room with a floor mat that has two animal feeding bowls on it, one for food and one for water.</div>\n",
       "<div>A wall divider is made of several long ribbons.</div>\n",
       "<div>What appears to be a refrigerator covered in strange, wavy material.</div>\n",
       "<div>A curtain made of red and white ribbons covers a refrigerator </div>\n",
       "<div>a pair of pet bowls on a mat is next to a screen</div></div>\n",
       "<div style=\"display: inline-block;\"><div>val/396295</div><img src=\"http://images.cocodataset.org/train2017/000000396295.jpg\" style=\"max-width: 200px\"><div>A bathroom shower with towel hanging from the door.</div>\n",
       "<div>A bathroom scene with a shower and toilet in view</div>\n",
       "<div>A shower with a sliding glass door in a small bathroom.</div>\n",
       "<div>A small dirty bathroom with walk in shower and toilet</div>\n",
       "<div>A white toilet and a shower in a room.</div></div><h1>Text Similarity</h1><div style=\"display: inline-block;\"><div>train/71222</div><img src=\"http://images.cocodataset.org/train2017/000000071222.jpg\" style=\"max-width: 200px\"><div>A large shower head in a bathroom shower.</div>\n",
       "<div>A tiled shower with a large shower head</div>\n",
       "<div>The shower head has a blue light behind it.</div>\n",
       "<div>A shower head and a shower shelf with various toiletries.</div>\n",
       "<div>Two shower heads in a shower along with a shelf of products.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/310807</div><img src=\"http://images.cocodataset.org/train2017/000000310807.jpg\" style=\"max-width: 200px\"><div>A bathroom with a walk in shower next to a toilet and a sink.</div>\n",
       "<div>Over head photo of a glass corner shower and sink on a checkered floor.</div>\n",
       "<div>this bathroom has an all glass shower and tile floor</div>\n",
       "<div>A bathroom with black and white floor tile and a standing shower.</div>\n",
       "<div>The restroom has a checkered floor, shower, sink, and toilet.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/109561</div><img src=\"http://images.cocodataset.org/train2017/000000109561.jpg\" style=\"max-width: 200px\"><div>A modern bathroom with a round shower unit in the corner.</div>\n",
       "<div>That looks like some kind of futuristic shower with a lot of gadgets.</div>\n",
       "<div>there is a shower with a blue light in it</div>\n",
       "<div>a bathroom with a wall n shower that has glass</div>\n",
       "<div>a bathroom with a shower sitting inside of it </div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/233997</div><img src=\"http://images.cocodataset.org/train2017/000000233997.jpg\" style=\"max-width: 200px\"><div>A welcome mat placed at the foot of a closed door.</div>\n",
       "<div>A black doorway with a welcome mat in front of it.</div>\n",
       "<div>a door mat in front of a door with a vase near by</div>\n",
       "<div>A black door with a welcome mat and yellow vase next to it.</div>\n",
       "<div>A welcome mat and a yellow vase outside apartment 407.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/249356</div><img src=\"http://images.cocodataset.org/train2017/000000249356.jpg\" style=\"max-width: 200px\"><div>A bathroom with a toilet, shower stall and a mirror.</div>\n",
       "<div>A bathroom toilet next to a blue rug.</div>\n",
       "<div>The small bathroom has a shower, a toilet, and a blue shower mat.</div>\n",
       "<div>a tiled bathroom with a toilet and bath tub</div>\n",
       "<div>A bathroom has a toilet and bathtub with shower in it. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/372775</div><img src=\"http://images.cocodataset.org/train2017/000000372775.jpg\" style=\"max-width: 200px\"><div>A full view of a bathroom with the shower and mirror next to it. </div>\n",
       "<div>Glass enclosed shower with white tile walls,brown floor</div>\n",
       "<div>An industrial type bathroom with an open shower.</div>\n",
       "<div>A walk in shower sitting next to a bathroom sink.</div>\n",
       "<div>A standing shower with a see through glass door.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/262284</div><img src=\"http://images.cocodataset.org/train2017/000000262284.jpg\" style=\"max-width: 200px\"><div>A full view of a shower with glass.</div>\n",
       "<div>A walk in shower with a hand held shower head.</div>\n",
       "<div>A bathroom shower stall with a shower head.</div>\n",
       "<div>a glass walled shower in a home bathroom</div>\n",
       "<div>a see through glass shower in a bathroom </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/184866</div><img src=\"http://images.cocodataset.org/train2017/000000184866.jpg\" style=\"max-width: 200px\"><div>a female in a black shirt a toilet and a shower head</div>\n",
       "<div>A woman sitting on the floor next to a toilet. </div>\n",
       "<div>A woman holds a shower head while sitting on the floor of a bathroom in her clothes.</div>\n",
       "<div>Woman sitting on floor with feet on wall next to bathroom commode.</div>\n",
       "<div>A disoriented woman sits on a bathroom floor holding a shower sprayer.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/243386</div><img src=\"http://images.cocodataset.org/train2017/000000243386.jpg\" style=\"max-width: 200px\"><div>A shower equipped for a physically challenged person with a shower chair</div>\n",
       "<div>A stool is inside of a walk in shower.</div>\n",
       "<div>A nicely kept shower with a seat inside.</div>\n",
       "<div>A bathroom with a tiled shower is shown.</div>\n",
       "<div>A walk in shower in a bathroom next to a mirror.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/233737</div><img src=\"http://images.cocodataset.org/train2017/000000233737.jpg\" style=\"max-width: 200px\"><div>A white sink and a shower in a small room.</div>\n",
       "<div>A white shower that has open glass doors.</div>\n",
       "<div>A shower with a glass door in the bathroom beside the sink and toilet. </div>\n",
       "<div>A view of a bathroom with black tile floor and a stand up shower with a glass door. </div>\n",
       "<div>A bathroom with a shower with see through floors . </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query_caption = \"a brown train pulls into the tracks next to some colorful buildings\"\n",
    "# query_caption = \"a train on the tracks in front of blue buildings\"\n",
    "query_caption = \"a shower with a blue mat on the floor in front of it\"\n",
    "query_vec = cap_vectorizer.transform([query_caption])\n",
    "similarity = caption_vecs.dot(query_vec.T).A.ravel()\n",
    "\n",
    "n_similar = 500\n",
    "image_set = [images[idx]['cocoid'] for idx in np.argsort(similarity)[-n_similar:][::-1]]\n",
    "vecs = load_vecs(image_set)\n",
    "encoder_final, memory_bank = encode_vecs(coco_cap.model.encoder, vecs)\n",
    "\n",
    "def eval_logprobs_varying_image(model, imgids, tgt_field, tgt_text):\n",
    "    batch_size = len(imgids)\n",
    "\n",
    "    vecs = load_vecs(image_set)\n",
    "    encoder_final, memory_bank = encode_vecs(coco_cap.model.encoder, vecs)\n",
    "\n",
    "    decoder_state = model.decoder.init_decoder_state(vecs, memory_bank=memory_bank, encoder_final=encoder_final)\n",
    "#    decoder_state.repeat_beam_size_times(batch_size)\n",
    "#    memory_bank = memory_bank.repeat(1, batch_size, 1)\n",
    "\n",
    "    # \"process\" handles padding and numericalization\n",
    "    tgt = tgt_field.process([tgt_text] * batch_size, device=-1, train=False)\n",
    "    pad_idx = tgt_field.vocab.stoi[tgt_field.pad_token]\n",
    "    \n",
    "    # Decoder wants an extra dim for extra features.\n",
    "    dec_out, dec_states, attn = model.decoder(tgt[:-1].unsqueeze(2), memory_bank, decoder_state)\n",
    "    logits = model.generator(dec_out).contiguous()\n",
    "    seq_len, batch_size_2, num_vocab = logits.shape\n",
    "    assert batch_size == batch_size_2\n",
    "    losses = F.nll_loss(\n",
    "        logits.view(seq_len * batch_size, num_vocab), tgt[1:].view(seq_len * batch_size), reduce=False\n",
    "    ).view(seq_len, batch_size)\n",
    "    return losses.data.sum(0)\n",
    "#     mask = tgt[1:].eq(pad_idx)\n",
    "#     losses = losses.masked_fill(mask, 0).data.sum(0)\n",
    "#     length = (~mask.data).long().sum(0)\n",
    "#     return losses# / length.float()\n",
    "\n",
    "losses_by_img = eval_logprobs_varying_image(\n",
    "    coco_cap.model,\n",
    "    image_set,\n",
    "    coco_cap.fields['tgt'],\n",
    "    coco_cap.fields['tgt'].preprocess(query_caption)\n",
    ").numpy()\n",
    "# losses_by_img\n",
    "\n",
    "print(query_caption)\n",
    "HTML(\n",
    "    \"<h1>Captioning Model</h1>\"\n",
    "    + show_images(np.array(image_set)[np.argsort(losses_by_img)[:10]])\n",
    "    + \"<h1>Text Similarity</h1>\"\n",
    "    + show_images(image_set[:10])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>restval/241948</div><img src=\"http://images.cocodataset.org/train2017/000000241948.jpg\" style=\"max-width: 200px\"><div>A train sitting on train tracks next to a  small rural road.</div>\n",
       "<div>There is a train sitting on some train tracks.</div>\n",
       "<div> A rusty old train on top of train tracks.</div>\n",
       "<div>a steam train travels through a park area </div>\n",
       "<div>an old ttrain sitting on some tracks behind a train </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/375248</div><img src=\"http://images.cocodataset.org/train2017/000000375248.jpg\" style=\"max-width: 200px\"><div>A large long train on a steel track.</div>\n",
       "<div>A red and green train traveling down tracks.</div>\n",
       "<div>The train is stopping on the railroad tracks.</div>\n",
       "<div>A train that is traveling down some railroad tracks. </div>\n",
       "<div>A train sitting on train tracks next to a platform.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/52983</div><img src=\"http://images.cocodataset.org/train2017/000000052983.jpg\" style=\"max-width: 200px\"><div>A train that has people standing by the railing on the front.</div>\n",
       "<div>A bunch of people that are on the front of a train.</div>\n",
       "<div>Some people stand on and near a blue train near trees.</div>\n",
       "<div>A blue train with a few people on the front of it.</div>\n",
       "<div>Group of men standing on the front of a blue train together. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/470840</div><img src=\"http://images.cocodataset.org/train2017/000000470840.jpg\" style=\"max-width: 200px\"><div>A train traveling down train tracks through a lush green forest.</div>\n",
       "<div>Wooded area with small railroad approaching on the track</div>\n",
       "<div>THERE IS A TRAIN ON THE TRAVCKS IN THE GRASS</div>\n",
       "<div>A small train advancing on the tracks thru a park.</div>\n",
       "<div>A train is approaching a bend in the train tracks.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/39276</div><img src=\"http://images.cocodataset.org/train2017/000000039276.jpg\" style=\"max-width: 200px\"><div>An old rusted train engine on train tracks.</div>\n",
       "<div>A photo of an old, rusty train sitting on tracks.</div>\n",
       "<div>an old rusty train sitting on the tracks </div>\n",
       "<div>A vintage train sits on wooden tracks in a field.</div>\n",
       "<div>a close up of a train on a train track</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/106973</div><img src=\"http://images.cocodataset.org/train2017/000000106973.jpg\" style=\"max-width: 200px\"><div>A train approaching on the tracks during the day.</div>\n",
       "<div>A TRAIN IS ON THE TRAIN TRACKS </div>\n",
       "<div>A train is coming down the tracks next to a heavily wooded area.</div>\n",
       "<div>A green and yellow train going down a track. </div>\n",
       "<div>A trolley train is on the split tracks.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/373373</div><img src=\"http://images.cocodataset.org/train2017/000000373373.jpg\" style=\"max-width: 200px\"><div>a large train that is on train track with people around</div>\n",
       "<div>A group of people sitting on the ground next to a train.</div>\n",
       "<div>a woman is sitting near a red train</div>\n",
       "<div>Several people gathered near a train and the tracks on the ground and on the train. </div>\n",
       "<div>The train is driving through the tracks of a small village</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/458970</div><img src=\"http://images.cocodataset.org/train2017/000000458970.jpg\" style=\"max-width: 200px\"><div>A train on the tracks with people standing and walking by it </div>\n",
       "<div>A crowd of people are walking in front of a train.</div>\n",
       "<div>A stopped train at a train crossing with people crossing the tracks.</div>\n",
       "<div>A black train parked at a train station as people walk across the train tracks.</div>\n",
       "<div>People at a train station, gathering around a black locomotive. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/362351</div><img src=\"http://images.cocodataset.org/train2017/000000362351.jpg\" style=\"max-width: 200px\"><div>The control center of a train engine traveling down train tracks.</div>\n",
       "<div>the control room of a train on a train track</div>\n",
       "<div>The control room for a train that is still on the tracks. </div>\n",
       "<div>a train sitting on the tracks with a good view of the instrument panel</div>\n",
       "<div>A train sits on the tracks, surrounded by the woods.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/7666</div><img src=\"http://images.cocodataset.org/train2017/000000007666.jpg\" style=\"max-width: 200px\"><div>The blue train is passing through a wooded area. </div>\n",
       "<div>a blue train in the middle of a forest</div>\n",
       "<div>green valley with a creek and blue train</div>\n",
       "<div>A train that is driving by on a hill side.</div>\n",
       "<div>a blue train is coming down some tracks</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(show_images(np.array(image_set)[np.argsort(losses_by_img)[-10:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1c: Visual Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: relatively similar images that are most different from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foil_set(*, stimulus, caption, rs):\n",
    "    similar_images = get_similar_images(caption, n=10)\n",
    "    if stimulus not in similar_images:\n",
    "        print(\"Inserting\", stimulus, 'into foil set')\n",
    "        similar_images[-1] = stimulus\n",
    "    rs.shuffle(similar_images)\n",
    "    return similar_images\n",
    "stimulus = trial_data[1]['stimulus']\n",
    "get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=np.random.RandomState(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(1234)\n",
    "foil_sets = {\n",
    "    stimulus: get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=rs)\n",
    "    for stimulus in sorted(concat_captions.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group tasks so that (1) each annotator never gets the same target image twice and (2) each annotator never sees two captions from the same person. The latter criterion cannot always be met, though, since the number of annotators may not evenly divide the number of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffled(lst):\n",
    "    lst = lst[:]\n",
    "    random.shuffle(lst)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    trials_by_img = toolz.groupby('stimulus', shuffled(trial_data))\n",
    "    annotators = []\n",
    "    while not any(len(trials) == 0 for trials in trials_by_img.values()):\n",
    "        trials_for_annotator = []\n",
    "        participants_seen_by_annotator = set()\n",
    "        for stimulus, trials in trials_by_img.items():\n",
    "            for i in range(len(trials)):\n",
    "                participant = trials[i]['participant']\n",
    "                if participant not in participants_seen_by_annotator:\n",
    "                    trials_for_annotator.append(trials.pop(i))\n",
    "                    participants_seen_by_annotator.add(participant)\n",
    "                    break\n",
    "            else:\n",
    "#                 print(\"Have to use the same participant again\")\n",
    "                trials_for_annotator.append(trials.pop(0))\n",
    "\n",
    "        annotators.append(shuffled(trials_for_annotator))\n",
    "    if all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators):\n",
    "        break\n",
    "    assert all(len(trials) == 0 for trials in trials_by_img.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = annotators[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_by_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never gets the same target image twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('stimulus', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never sees two captions from the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(trials) for trials in annotators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_task(stimulus, text):\n",
    "    foil_set = foil_sets[stimulus]\n",
    "    return dict(\n",
    "        description=text,\n",
    "        correct_idx=foil_set.index(stimulus),\n",
    "        images=[id2url[idx] for idx in foil_set]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = annotators[0][0]\n",
    "make_task(trial['stimulus'], trial['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_task = pd.DataFrame([\n",
    "    json.dumps([make_task(trial['stimulus'], trial['text']) for trial in annotator_trials])\n",
    "    for annotator_trials in annotators], columns=['task'])\n",
    "guesses_task.iloc[:1].to_csv(str(paths.data / 'anno-tasks' / 'guesses_test.csv'), index=False)\n",
    "guesses_task.iloc[1:].to_csv(str(paths.data / 'anno-tasks' / 'guesses_remain.csv'), index=False)\n",
    "guesses_task.to_csv(str(paths.data / 'anno-tasks' / 'guesses.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MTurk results so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = list((paths.data / 'mturk').glob('*-guesses.csv'))\n",
    "batched_guesses_results = (\n",
    "    pd.concat([pd.read_csv(str(f)) for f in result_files], axis=0, ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(batched_guesses_results['WorkTimeInSeconds']/60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_dur(results):\n",
    "    pages = json.loads(results)\n",
    "    try:\n",
    "        first_guess = pages[0]['guesses'][0]['timestamp']\n",
    "        last_guess = pages[-1]['guesses'][-1]['timestamp']\n",
    "        return (last_guess - first_guess) / 1000 / 60\n",
    "    except IndexError:\n",
    "        # Something failed in the UI probably...\n",
    "        return None\n",
    "batched_guesses_results['Answer.results'].apply(get_active_dur).hist()\n",
    "batched_guesses_results['Answer.results'].apply(get_active_dur).describe()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_guesses_results[batched_guesses_results['Answer.results'].apply(lambda x: '\"guesses\":[]' in x)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_results = []\n",
    "for i, row in batched_guesses_results.iterrows():\n",
    "    for page in json.loads(row['Answer.results']):\n",
    "#         print(page)\n",
    "        guess_indices = [guess['idx'] for guess in page['guesses']]\n",
    "        if len(guess_indices) == 0:\n",
    "            print(\"UI fail\", row['WorkerId'])\n",
    "            continue\n",
    "#         guessed_right_sometime = [row.correctIdx in row.guess_indices for row in mturk_nafc_results.itertuples()]\n",
    "        stimulus_url = [img for img in page['images'] if img['isCorrect']][0]['url']\n",
    "        guesses_results.append(dict(\n",
    "            guesser=row['WorkerId'],\n",
    "            description=page['description'],\n",
    "            num_guesses=len(guess_indices),\n",
    "            stimulus_url=stimulus_url))\n",
    "pd.DataFrame(guesses_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_responses_by_caption = mturk_nafc_results.groupby('Answer.description').size().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tasks remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials_todo = [trial for trial in trial_data if num_responses_by_caption.get(trial['text'], 0) < 3]\n",
    "# len(trial_data), len(trials_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# while True:\n",
    "#     out_fn = paths.data / 'anno-tasks' / f'{datetime.date.today().isoformat()}-{i}-nAFC.csv'\n",
    "#     if not out_fn.exists():\n",
    "#         break\n",
    "#     i += 1\n",
    "# out_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = np.random.RandomState(1234)\n",
    "# pd.DataFrame([make_task(trial, rs) for trial in trials_todo]).to_csv(out_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the actual HIT text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "html = Template(open(paths.top_level / 'HITs' / '2018-05-04-image-description-match.jinja.html').read()).render(dict(\n",
    "    description='${description}',\n",
    "    images=['${image_%d_url}' % i for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html2 = html\n",
    "trial = trial_data[18+7*9]\n",
    "for k, v in make_task(trial['stimulus'], trial['text']).items():\n",
    "    html2 = html2.replace('${' + k + '}', str(v))\n",
    "HTML('<div style=\"height: 1000px; position: relative;\">'+html2+'</div>')\n",
    "# print(html2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.Popen('pbcopy', stdin=subprocess.PIPE).communicate(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MTurk results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results.groupby('Answer.description').num_guesses.mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mturk_nafc_results['WorkTimeInSeconds'][mturk_nafc_results['WorkTimeInSeconds'] < 5*60] / 60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(mturk_nafc_results['WorkTimeInSeconds'] / 60) * 9/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    15 # participants\n",
    "    * 3 # conditions per participant\n",
    "    * 3 # captions per condition\n",
    "    - 1 # image not shown\n",
    ") * 3 # annotators per description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    * .24 # reward per annotator\n",
    ") * 1.2 # MTurk 20% fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the same worker see the same target image multiple times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data.iterrows())[1]['Input.image_0_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['target_image_url'] = [row['Input.image_'+str(row['correctIdx'])+\"_url\"] for _, row in mturk_nafc_results.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_worker_image_pairs = set()\n",
    "for worker_id, data in mturk_nafc_results.groupby('WorkerId'):\n",
    "    target_images = [row['target_image_url'] for _, row in data.iterrows()]\n",
    "    if len(target_images) != len(set(target_images)):\n",
    "#         print(worker_id)\n",
    "        value_counts = pd.Series(target_images).value_counts()\n",
    "        value_counts = value_counts[value_counts > 1]\n",
    "#         print(value_counts)\n",
    "        for img in value_counts.index:\n",
    "            bad_worker_image_pairs.add((worker_id, img))\n",
    "bad_worker_image_pairs\n",
    "\n",
    "annotation_row_is_bad = [\n",
    "    (row['WorkerId'], row['target_image_url']) in bad_worker_image_pairs\n",
    "    for _, row in mturk_nafc_results.iterrows()\n",
    "]\n",
    "mturk_nafc_results['row_is_bad'] = annotation_row_is_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['row_is_bad'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_results = mturk_nafc_results[~mturk_nafc_results['row_is_bad']].rename(columns={'Answer.description': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mturk_nafc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(guess_results), len(trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    guess_results.rename(columns={'WorkerId': 'guesser'}).drop(['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'RequesterAnnotation', 'guesses'], axis=1),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    pd.DataFrame(guesses_results).rename(columns={'description': 'text'}),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data.to_csv('annotator_level_data_2018-05-22v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(annotator_level_data['num_guesses'] == 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(model = lmer(num_guesses ~ condition + (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(null_model = lmer(num_guesses ~ (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(pbkrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "(kr <- KRmodcomp(model, null_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(glm.full = glmer(num_guesses ~ condition + (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data, family=poisson()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "(glm.null = glmer(num_guesses ~ (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data, family=poisson()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#confint(glm.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "anova(glm.full, glm.null, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(nb_model = glmer.nb(num_guesses ~ condition + (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(nb_model.null = glmer.nb(num_guesses ~ (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "anova(nb_model, nb_model.null, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([dict(trial, specificity=specificity_lookup[trial['text'].strip()]) for trial in trial_data])\n",
    "for col in ['condition', 'participant']:\n",
    "    results[col] = results[col].astype('category')\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('condition').specificity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trial_data).sample(frac=1.0).sort_values('stimulus').to_csv('trial_data_by_stimulus.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

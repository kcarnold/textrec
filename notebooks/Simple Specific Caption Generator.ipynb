{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import toolz\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = json.load(open('/Users/kcarnold/src/ImageCaptioning.pytorch/data/dataset_coco.json'))['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'restval': 30504, 'test': 5000, 'train': 82783, 'val': 5000})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(img['split'] for img in images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_by_split = toolz.groupby('split', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_images = images_by_split['val']#[img for img in images if img['split'] == 'val']\n",
    "len(valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.RandomState(0).permutation(len(valid_images))\n",
    "examples = [valid_images[idx] for idx in perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_url(cocoid):\n",
    "    return f'http://images.cocodataset.org/train2017/{cocoid:012d}.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://images.cocodataset.org/train2017/000000133707.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_url(examples[0]['cocoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([dict(\n",
    "    coco_id=img['cocoid'],\n",
    "    url=coco_url(img['cocoid']),\n",
    "    cap0=img['sentences'][0]['raw'],\n",
    "    cap1=img['sentences'][1]['raw'],\n",
    "    cap2=img['sentences'][2]['raw'],\n",
    "    cap3=img['sentences'][3]['raw'],\n",
    "    cap4=img['sentences'][4]['raw'],\n",
    ") for img in examples[:50]])\n",
    "df.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrec import lang_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'textrec.lang_model' from '/Users/kcarnold/code/textrec/src/textrec/lang_model.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(lang_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running /Users/kcarnold/code/kenlm/build/bin/lmplz -o 5 --prune 2 --verbose_header < /Users/kcarnold/code/textrec/models/coco_train.txt > /Users/kcarnold/code/textrec/models/coco_train.arpa\n",
      "Running /Users/kcarnold/code/kenlm/build/bin/build_binary /Users/kcarnold/code/textrec/models/coco_train.arpa /Users/kcarnold/code/textrec/models/coco_train.kenlm\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "lang_model.dump_kenlm(\n",
    "    'coco_train',\n",
    "    [' '.join(sentence['tokens']) for img in images_by_split['train'] for sentence in img['sentences']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model coco_train ... reading raw ARPA data ...  Encoding bigrams to indices... Loaded.\n"
     ]
    }
   ],
   "source": [
    "model = lang_model.Model.get_or_load_model('coco_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-398.472120447575, State([], []))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score_seq(model.bos_state, 'a person standing inside of a phone booth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-174.28278306181613, State([], []))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score_seq(model.bos_state, 'a group of people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "car\n",
      ": a blue car parked, a blue car with, a blue surfboard, a blue car driving, a blue car and\n",
      "a: blue car parked, blue surfboard, blue car driving, blue car with a, blue car and a\n",
      "a blue: car parked in, car driving down, train car sitting, car driving on, car with a cat\n",
      "a blue car: parked in an antique, parked in front of, driving down a street, driving down a road, parked in an airport\n",
      "a blue car parked: in an antique, in front of a, in an airport, in front of the, in front of an\n",
      "a blue car parked in: an antique style, an antique store, an antique truck, an antique motorcycle, front of a building\n",
      "a blue car parked in an: antique motorcycle, antique style pizza, antique store with, antique style kitchen, antique style bathroom\n",
      "a blue car parked in an antique: style kitchen with, style pizza with, style bathroom with, style on a table, store with a large\n",
      "a blue car parked in an antique style: building with a clock, pizza with cheese, kitchen with a large, bathroom with a toilet, kitchen with a sink\n",
      "a blue car parked in an antique style building: with a white surfboard, with a clock on, with a clock tower, with a clock and, with a clock at\n",
      "a blue car parked in an antique style building with: a clock tower, a clock on the, a clock on it, a clock on top, surfboard under a wave\n",
      "a blue car parked in an antique style building with a: surfboard on a wave, surfboard in the water, surfboard in the ocean, surfboard on top of, surfboard under his\n",
      "a blue car parked in an antique style building with a surfboard: in the water, in the ocean, on a wave in, on top of a table, under his arm and\n",
      "a blue car parked in an antique style building with a surfboard in: the middle of, the water with, the ocean waves, the ocean with, front of a building\n",
      "\n",
      "kitchen\n",
      ": white kitchen sink, white kitchen stove, white stove sink, white sink refrigerator, white sink stove\n",
      "white: kitchen stove sink, refrigerator stove sink, kitchen sink refrigerator, kitchen sink stove, kitchen stove refrigerator\n",
      "white kitchen: stove sink refrigerator, sink stove refrigerator, refrigerator stove sink, sink refrigerator, stove sink and a\n",
      "white kitchen stove: sink refrigerator, refrigerator and sink in, and sink refrigerator, refrigerator and sink and, refrigerator and sink with\n",
      "white kitchen stove sink: refrigerator and wooden, refrigerator and other, refrigerator and a table, refrigerator and a black, refrigerator and a window\n",
      "white kitchen stove sink refrigerator: and wooden cabinets, and a table with, and a table in, and a table and, and a black and\n",
      "white kitchen stove sink refrigerator and: doorway of a building, doorway of a train, pantry in a large, pantry in a small, pantry in a city\n",
      "white kitchen stove sink refrigerator and doorway: of a building, of a train station, of a train on, of a train car, of a train with\n",
      "white kitchen stove sink refrigerator and doorway of: a train station, a building with, a train car, a train on a, a train with\n",
      "white kitchen stove sink refrigerator and doorway of a: narrow dirt road, narrow alley way, narrow road with, narrow room with, narrow road in the\n",
      "white kitchen stove sink refrigerator and doorway of a narrow: dirt road with, alley way with a, dirt road in the, dirt road in front, dirt road in a\n",
      "white kitchen stove sink refrigerator and doorway of a narrow dirt: road next to a, road in front of, road in the middle, road in a city, road in the city\n",
      "white kitchen stove sink refrigerator and doorway of a narrow dirt road: in front of a, in the middle, next to a building, next to a fence, next to a car in\n",
      "white kitchen stove sink refrigerator and doorway of a narrow dirt road in: the middle of, front of a building, front of a large, front of a window, front of a mirror\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    dict(\n",
    "        name=\"car\",\n",
    "        bonuses='blue retro antique car surfboard'.split(),\n",
    "        avoids='two parking lot hand train'.split(),\n",
    "        good_recs=[\n",
    "            \"a: blue\",\n",
    "            \"a: retro\",\n",
    "            \"a blue: antique\"\n",
    "        ],\n",
    "        bad_recs = [\n",
    "            \"a: car\",\n",
    "        ]\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"kitchen\",\n",
    "        bonuses=\"white narrow galley kitchen sink stove refrigerator pantry doorway\".split(),\n",
    "        avoids=\"street bathroom\".split(),\n",
    "        good_recs=[\n",
    "            'a: white',\n",
    "            'a: narrow',\n",
    "            'a narrow: white'\n",
    "        ],\n",
    "        bad_recs=[\n",
    "            'a: street',\n",
    "            'a: bathroom'\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "def get_bonuses(context, to_bonus, to_avoid, amt):\n",
    "    bonus_words = {}\n",
    "    for word in to_bonus:\n",
    "        bonus_words[word] = amt if word not in context else -amt\n",
    "    for word in to_avoid:\n",
    "        bonus_words[word] = -amt\n",
    "    return bonus_words\n",
    "\n",
    "def eval_bonus_amt(amt):\n",
    "    num_good_recs = 0\n",
    "    num_bad_recs = 0\n",
    "    for example in examples:\n",
    "        for ref_rec in example['good_recs']:\n",
    "            context, rest = ref_rec.split(':')\n",
    "            context = context.split()\n",
    "            rest = rest.strip()\n",
    "            bonus_words = get_bonuses(context, example['bonuses'], example['avoids'], amt)\n",
    "            ents = lang_model.beam_search_phrases(model, context, length_after_first=10, beam_width=3, bonus_words=bonus_words)\n",
    "            generated_recs = [' '.join(ent.words) for ent in ents]\n",
    "            print(' '.join(context), '::', ','.join(generated_recs))\n",
    "#eval_bonus_amt(5.)\n",
    "\n",
    "for example in examples:\n",
    "    print(f'\\n{example[\"name\"]}')\n",
    "    context = ['<s>']\n",
    "    while len(context) < 15:\n",
    "        bonus_words = get_bonuses(context, example['bonuses'], example['avoids'], 10.)\n",
    "        ents = lang_model.beam_search_phrases(model, context, length_after_first=10, beam_width=5, bonus_words=bonus_words)\n",
    "        generated_recs = [' '.join(ent.words) for ent in ents]\n",
    "        print('{}: {}'.format(' '.join(context[1:]), ', '.join(generated_recs)))\n",
    "        context.append(ents[0].words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['white',\n",
       " 'yellow',\n",
       " 'red',\n",
       " 'silver',\n",
       " 'black',\n",
       " 'green',\n",
       " 'gray',\n",
       " 'orange',\n",
       " 'grey',\n",
       " 'gold',\n",
       " 'pink',\n",
       " 'a',\n",
       " 'purple',\n",
       " 'brown',\n",
       " 'car',\n",
       " 'the',\n",
       " 'is',\n",
       " 'surfboard',\n",
       " 'antique',\n",
       " 'some',\n",
       " 'one',\n",
       " 'two',\n",
       " 'other',\n",
       " 'an',\n",
       " 'holding',\n",
       " 'people',\n",
       " 'another',\n",
       " 'on',\n",
       " 'in',\n",
       " 'looking',\n",
       " 'several',\n",
       " 'has',\n",
       " 'three',\n",
       " 'various',\n",
       " 'trees',\n",
       " 'sitting',\n",
       " 'small',\n",
       " 'many',\n",
       " 'and',\n",
       " 'with',\n",
       " 'eating',\n",
       " 'standing',\n",
       " 'large',\n",
       " 'water',\n",
       " 'wearing',\n",
       " 'his',\n",
       " 'smiling',\n",
       " 'vegetables',\n",
       " 'lots',\n",
       " 'broccoli']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bonuses(context):\n",
    "    amt = 5.\n",
    "    return {word: (amt if word not in context else -amt) for word in bonus_words}\n",
    "context = 'a blue and'.split()\n",
    "ents = lang_model.beam_search_phrases(model, context, length_after_first=1, beam_width=50, bonus_words=get_bonuses(context))\n",
    "[' '.join(ent.words) for ent in ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'front slices syrup . bacon and blackberries of a maple bananas plate with banana in mug blueberries , topped pancakes'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_captions = [\n",
    "    'plate with pancakes topped with banana slices , bacon , and blackberries , in front of a mug and maple syrup .',\n",
    "    'a plate with blueberries , bacon , and pancakes topped with bananas .',\n",
    "]\n",
    "' '.join(set(tok for cap in example_captions for tok in cap.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(caption):\n",
    "    # FIXME: Karpathy seems to have killed commas and periods.\n",
    "    return [\"<s>\"] + nltk.word_tokenize(caption.replace(',', ' ').replace('.', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'<s>': {'a': 1.0, 'plate': 1.0},\n",
       "             '<s> a': {'plate': 1.0},\n",
       "             '<s> a plate': {'with': 1.0},\n",
       "             '<s> a plate with': {'blueberries': 1.0},\n",
       "             '<s> a plate with blueberries': {'bacon': 1.0},\n",
       "             '<s> a plate with blueberries bacon': {'and': 1.0},\n",
       "             '<s> a plate with blueberries bacon and': {'pancakes': 1.0},\n",
       "             '<s> a plate with blueberries bacon and pancakes': {'topped': 1.0},\n",
       "             '<s> a plate with blueberries bacon and pancakes topped': {'with': 1.0},\n",
       "             '<s> a plate with blueberries bacon and pancakes topped with': {'bananas': 1.0},\n",
       "             '<s> plate': {'with': 1.0},\n",
       "             '<s> plate with': {'pancakes': 1.0},\n",
       "             '<s> plate with pancakes': {'topped': 1.0},\n",
       "             '<s> plate with pancakes topped': {'with': 1.0},\n",
       "             '<s> plate with pancakes topped with': {'banana': 1.0},\n",
       "             '<s> plate with pancakes topped with banana': {'slices': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices': {'bacon': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon': {'and': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and': {'blackberries': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries': {'in': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in': {'front': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front': {'of': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of': {'a': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of a': {'mug': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of a mug': {'and': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of a mug and': {'maple': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of a mug and maple': {'syrup': 1.0}})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = defaultdict(dict)\n",
    "for cap in example_captions:\n",
    "    toks = tokenize(cap)\n",
    "    for idx in range(1, len(toks)):\n",
    "        context = ' '.join(toks[:idx])\n",
    "        tok = toks[idx]\n",
    "        dataset[context][tok] = 1.\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pop a context\n",
    "2. Generate 10 possible suggestions\n",
    "3. Have annotator pick all the ones that are good suggestions.\n",
    "4. Record the raw results (for later playing with ranking learning)\n",
    "5. Record all good suggestions as 1, bad suggestions as 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake the first step\n",
    "context = '<s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 possible suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.id2str[:3] == ['<unk>', '<s>', '</s>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_word_distribution_ngram(model, toks):\n",
    "    state = model.get_state(toks, bos=True)[0]\n",
    "    logprobs = model.eval_logprobs_for_words(state, range(len(model.id2str)))\n",
    "    logprobs[:3] = -1e99\n",
    "    logprobs -= logsumexp(logprobs)\n",
    "    return logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = next_word_distribution_ngram(model, context.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsumexp(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dist # for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'some',\n",
       " 'several',\n",
       " 'people',\n",
       " 'three',\n",
       " 'there',\n",
       " 'an',\n",
       " 'the',\n",
       " 'two',\n",
       " 'a']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = [model.id2str[idx] for idx in np.argsort(scores)[-10:]]\n",
    "recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Which of these is a good suggestion?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'an': 0,\n",
       " 'people': 0,\n",
       " 'several': 0,\n",
       " 'some': 1,\n",
       " 'the': 0,\n",
       " 'there': 1,\n",
       " 'this': 0,\n",
       " 'three': 0,\n",
       " 'two': 0}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_good = [0, 1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
    "assert len(is_good) == len(recs)\n",
    "{word: label for word, label in zip(recs, is_good)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, label in zip(recs, is_good):\n",
    "    dataset[context][word] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now learn us a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_for_unigram_feats = sorted(word for words in dataset.values() for word in words.keys())\n",
    "word2unigram_feat_idx = {word: idx for idx, word in enumerate(words_for_unigram_feats)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_words = np.diag(np.ones(len(words_for_unigram_feats)))\n",
    "one_hot_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_hot = np.zeros(len(words_for_unigram_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(ngram_dist, word):\n",
    "    word_idx = model.model.vocab_index(word)\n",
    "    assert word_idx != 0, word\n",
    "    if word in word2unigram_feat_idx:\n",
    "        unigram_feat = one_hot_words[word2unigram_feat_idx[word]]\n",
    "    else:\n",
    "        unigram_feat = no_hot\n",
    "    return np.r_[\n",
    "        ngram_dist[word_idx],\n",
    "        unigram_feat\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "examples = []\n",
    "for context, words in dataset.items():\n",
    "    ngram_dist = next_word_distribution_ngram(model, context.split())\n",
    "    for word, label in words.items():\n",
    "        examples.append((context, word, label))\n",
    "        X.append(featurize(ngram_dist, word))\n",
    "        y.append(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 58)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 42, 41, 40, 39, 45, 44, 19,  2,  4,  5, 46,  6, 29, 31, 32, 33,\n",
       "       24,  8, 47, 35,  9, 36, 37, 26, 10, 48, 38, 17, 50, 20, 51, 15, 53,\n",
       "        0,  3, 30,  7, 12, 34, 21, 22, 23, 13, 56, 28, 54,  1, 18, 52, 25,\n",
       "       27, 16, 11, 49, 14, 55])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(clf.predict_log_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'plate', 1.0),\n",
       " ('<s>', 'a', 1),\n",
       " ('<s>', 'this', 0),\n",
       " ('<s>', 'some', 1),\n",
       " ('<s>', 'several', 0),\n",
       " ('<s>', 'people', 0),\n",
       " ('<s>', 'three', 0),\n",
       " ('<s>', 'there', 1),\n",
       " ('<s>', 'an', 0),\n",
       " ('<s>', 'the', 0),\n",
       " ('<s>', 'two', 0),\n",
       " ('<s> plate', 'with', 1.0),\n",
       " ('<s> plate with', 'pancakes', 1.0),\n",
       " ('<s> plate with pancakes', 'topped', 1.0),\n",
       " ('<s> plate with pancakes topped', 'with', 1.0),\n",
       " ('<s> plate with pancakes topped with', 'banana', 1.0),\n",
       " ('<s> plate with pancakes topped with banana', 'slices', 1.0),\n",
       " ('<s> plate with pancakes topped with banana slices', 'bacon', 1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon', 'and', 1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon and',\n",
       "  'blackberries',\n",
       "  1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon and blackberries',\n",
       "  'in',\n",
       "  1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon and blackberries in',\n",
       "  'front',\n",
       "  1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon and blackberries in front',\n",
       "  'of',\n",
       "  1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon and blackberries in front of',\n",
       "  'a',\n",
       "  1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon and blackberries in front of a',\n",
       "  'mug',\n",
       "  1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon and blackberries in front of a mug',\n",
       "  'and',\n",
       "  1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon and blackberries in front of a mug and',\n",
       "  'maple',\n",
       "  1.0),\n",
       " ('<s> plate with pancakes topped with banana slices bacon and blackberries in front of a mug and maple',\n",
       "  'syrup',\n",
       "  1.0),\n",
       " ('<s> a', 'plate', 1.0),\n",
       " ('<s> a', 'cat', 0.0),\n",
       " ('<s> a', 'white', 1.0),\n",
       " ('<s> a', 'small', 0.0),\n",
       " ('<s> a', 'couple', 0.0),\n",
       " ('<s> a', 'young', 0.0),\n",
       " ('<s> a', 'large', 1.0),\n",
       " ('<s> a', 'group', 0.0),\n",
       " ('<s> a', 'person', 0.0),\n",
       " ('<s> a', 'woman', 0.0),\n",
       " ('<s> a', 'man', 0.0),\n",
       " ('<s> a', 'sitting', 0),\n",
       " ('<s> a', 'fence', 0),\n",
       " ('<s> a', 'on', 0),\n",
       " ('<s> a', 'wave', 0),\n",
       " ('<s> a', 'is', 0),\n",
       " ('<s> a', 'in', 0),\n",
       " ('<s> a', 'of', 0),\n",
       " ('<s> a', 'a', 0),\n",
       " ('<s> a', 'and', 0),\n",
       " ('<s> a', 'with', 0),\n",
       " ('<s> a plate', 'with', 1.0),\n",
       " ('<s> a plate with', 'blueberries', 1.0),\n",
       " ('<s> a plate with blueberries', 'bacon', 1.0),\n",
       " ('<s> a plate with blueberries bacon', 'and', 1.0),\n",
       " ('<s> a plate with blueberries bacon and', 'pancakes', 1.0),\n",
       " ('<s> a plate with blueberries bacon and pancakes', 'topped', 1.0),\n",
       " ('<s> a plate with blueberries bacon and pancakes topped', 'with', 1.0),\n",
       " ('<s> a plate with blueberries bacon and pancakes topped with',\n",
       "  'bananas',\n",
       "  1.0)]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51957722, 0.48042278]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X[38:39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2unigram_feat_idx['with']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77776883])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_[0,54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '<s> a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_dist = next_word_distribution_ngram(model, context.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [model.id2str[id] for id in model.filtered_bigrams[model.model.vocab_index('a')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sitting fence on wave is in of a and with'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = [candidates[i] for i in np.argsort(clf.predict_log_proba([featurize(ngram_dist, word) for word in candidates])[:,1])[-10:]]\n",
    "' '.join(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.889380755798495"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_dist[model.model.vocab_index('')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51957722, 0.48042278]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([featurize(ngram_dist, 'man')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_good = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "assert len(is_good) == len(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, label in zip(recs, is_good):\n",
    "    dataset[context][word] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'<s>': {'a': 1,\n",
       "              'an': 0,\n",
       "              'people': 0,\n",
       "              'plate': 1.0,\n",
       "              'several': 0,\n",
       "              'some': 1,\n",
       "              'the': 0,\n",
       "              'there': 1,\n",
       "              'this': 0,\n",
       "              'three': 0,\n",
       "              'two': 0},\n",
       "             '<s> a': {'a': 0,\n",
       "              'and': 0,\n",
       "              'cat': 0.0,\n",
       "              'couple': 0.0,\n",
       "              'fence': 0,\n",
       "              'group': 0.0,\n",
       "              'in': 0,\n",
       "              'is': 0,\n",
       "              'large': 1.0,\n",
       "              'man': 0.0,\n",
       "              'of': 0,\n",
       "              'on': 0,\n",
       "              'person': 0.0,\n",
       "              'plate': 1.0,\n",
       "              'sitting': 0,\n",
       "              'small': 0.0,\n",
       "              'wave': 0,\n",
       "              'white': 1.0,\n",
       "              'with': 0,\n",
       "              'woman': 0.0,\n",
       "              'young': 0.0},\n",
       "             '<s> a plate': {'with': 1.0},\n",
       "             '<s> a plate with': {'blueberries': 1.0},\n",
       "             '<s> a plate with blueberries': {'bacon': 1.0},\n",
       "             '<s> a plate with blueberries bacon': {'and': 1.0},\n",
       "             '<s> a plate with blueberries bacon and': {'pancakes': 1.0},\n",
       "             '<s> a plate with blueberries bacon and pancakes': {'topped': 1.0},\n",
       "             '<s> a plate with blueberries bacon and pancakes topped': {'with': 1.0},\n",
       "             '<s> a plate with blueberries bacon and pancakes topped with': {'bananas': 1.0},\n",
       "             '<s> plate': {'with': 1.0},\n",
       "             '<s> plate with': {'pancakes': 1.0},\n",
       "             '<s> plate with pancakes': {'topped': 1.0},\n",
       "             '<s> plate with pancakes topped': {'with': 1.0},\n",
       "             '<s> plate with pancakes topped with': {'banana': 1.0},\n",
       "             '<s> plate with pancakes topped with banana': {'slices': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices': {'bacon': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon': {'and': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and': {'blackberries': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries': {'in': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in': {'front': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front': {'of': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of': {'a': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of a': {'mug': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of a mug': {'and': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of a mug and': {'maple': 1.0},\n",
       "             '<s> plate with pancakes topped with banana slices bacon and blackberries in front of a mug and maple': {'syrup': 1.0}})"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

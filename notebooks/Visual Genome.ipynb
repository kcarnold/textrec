{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ujson\n",
    "import toolz\n",
    "import pathlib\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_base = pathlib.Path('/Data/VisualGenome')\n",
    "image_objects = ujson.load(open(vg_base / 'objects.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_by_id = {img['image_id']: img for img in image_objects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def show_images(imgids):\n",
    "        return HTML('\\n'.join('<img src=\"{}\">'.format(img_by_id[imgid]['image_url']) for imgid in imgids))\n",
    "\n",
    "    obj_synsets = json.load(open(vg_base / 'object_synsets.json'))\n",
    "    obj_attributes = json.load(open(vg_base / 'attributes.json'))\n",
    "\n",
    "    attributes_by_img = {att['image_id']: att['attributes'] for att in obj_attributes}\n",
    "\n",
    "    def has_object(imgid, obj_name):\n",
    "        return any(obj_name in '\\n'.join(obj['names']) for obj in attributes_by_img[imgid])\n",
    "\n",
    "    def has_synset(imgid, obj_synset):\n",
    "        return any(obj_synset in obj['synsets'] for obj in attributes_by_img[imgid])\n",
    "\n",
    "    def has_attr(imgid, attr):\n",
    "        return any(attr in obj['attributes'] for obj in attributes_by_img[imgid])\n",
    "\n",
    "    def has_obj_with_attr(imgid, obj_name, attr):\n",
    "        return any(\n",
    "            (obj_name in '\\n'.join(obj['names'])) and (attr in obj.get('attributes', []))\n",
    "            for obj in attributes_by_img[imgid])\n",
    "\n",
    "    def has_synset_with_attr(imgid, obj_synset, attr):\n",
    "        return any(\n",
    "            (obj_synset in obj['synsets']) and (attr in obj.get('attributes', []))\n",
    "            for obj in attributes_by_img[imgid])\n",
    "\n",
    "    def has_obj_without_attr(imgid, obj_name, attr):\n",
    "        return any(\n",
    "            (obj_name in '\\n'.join(obj['names'])) and (attr not in obj.get('attributes', []))\n",
    "            for obj in attributes_by_img[imgid])\n",
    "\n",
    "    def has_synset_without_attr(imgid, obj_synset, attr):\n",
    "        return any(\n",
    "            (obj_synset in obj['synsets']) and (attr not in obj.get('attributes', []))\n",
    "            for obj in attributes_by_img[imgid])\n",
    "\n",
    "    candidates = {\n",
    "        imgid for imgid in attributes_by_img.keys()\n",
    "        if (\n",
    "            (\n",
    "                has_object(imgid, 'pedestrian sign') or\n",
    "                has_object(imgid, 'pedestrian crossing sign') or\n",
    "                has_object(imgid, 'crossing sign') or\n",
    "                has_obj_with_attr(imgid, 'sign', 'yellow')\n",
    "            ) and (\n",
    "                has_obj_without_attr(imgid, 'traffic light', 'red') or\n",
    "                has_synset_without_attr(imgid, 'traffic_light.n.01', 'red')\n",
    "            ))}\n",
    "    len(candidates)\n",
    "\n",
    "\n",
    "    show_images(list(candidates)[:10])\n",
    "    show_images(candidates)\n",
    "\n",
    "    candidates = {\n",
    "        imgid for imgid in attributes_by_img.keys()\n",
    "        if has_obj_with_attr(imgid, \"train\", \"brown\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_descs = ujson.load(open(vg_base / 'region_descriptions.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['regions', 'id'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_descs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_by_img = {r['id']: r['regions'] for r in region_descs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_by_img = {id: {region['phrase'].strip() for region in regions} for id, regions in regions_by_img.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7760 on back of train',\n",
       " 'MARC  on back of train',\n",
       " 'a blue metal pipe',\n",
       " 'a bright green light',\n",
       " 'a bunch of wires and plugs',\n",
       " 'a few telephone posts',\n",
       " 'a red traffic light',\n",
       " 'a small grey outbuilding',\n",
       " 'a small grey shack',\n",
       " 'a small puddle of water',\n",
       " 'a straigh train track',\n",
       " 'a tall electrical pole with powerlines',\n",
       " 'a train in motion',\n",
       " 'a white train with blue and orange stripes',\n",
       " 'a yellow and blue logo sticker',\n",
       " 'blue and orange stripes',\n",
       " 'bright red lights on the back of a train',\n",
       " 'brown train tracks',\n",
       " 'green and red stoplights',\n",
       " 'green dense trees',\n",
       " 'green traffic light on right',\n",
       " 'orange and blue stripes on back',\n",
       " 'red light on the left',\n",
       " 'red light on the right',\n",
       " 'red traffic light on right',\n",
       " 'rough rocky ground',\n",
       " 'some piles of gravel',\n",
       " 'the door is white',\n",
       " 'the light is red',\n",
       " 'the lights are red',\n",
       " 'the nummber 7760 is on the train',\n",
       " 'the photo was taken during the day',\n",
       " 'the pole is white',\n",
       " 'the portable is standing',\n",
       " 'the rail road is brown',\n",
       " 'the sky is clear',\n",
       " 'the sky is dim',\n",
       " 'the stoplight is red',\n",
       " 'the tracks are rusted',\n",
       " 'the train has two windows',\n",
       " 'the train is stopped',\n",
       " 'the tree is green',\n",
       " 'there  are trees on the side',\n",
       " 'there are two bulbs below the train',\n",
       " 'there is gravel between the tracks',\n",
       " 'there is gravel on th eground',\n",
       " 'track on the left',\n",
       " 'track the train is on',\n",
       " 'train car on a track'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_by_img[2408456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answers = ujson.load(open(vg_base / 'question_answers.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(imgids, max_width=200):\n",
    "    def img(idx):\n",
    "        img = img_by_id[idx]\n",
    "#         attrs = {\n",
    "#             '<b>{}</b>=<i>{}</i>'.format(', '.join(obj['names']), ', '.join(obj.get('attributes', [])))\n",
    "#             for obj in attributes_by_img[idx]}\n",
    "        attrs = sorted(phrases_by_img[idx])\n",
    "        return '<div style=\"display: inline-block;\">{}<img src=\"{}\" style=\"max-width: {}px\">{}</div>'.format(\n",
    "            idx, img['image_url'], max_width, '; '.join(sorted(attrs)))\n",
    "    return '\\n'.join(img(idx) for idx in imgids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108077"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_answers[0]['qas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a_objects', 'question', 'image_id', 'qa_id', 'answer', 'q_objects'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answers[0]['qas'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answers = {qa['id']: qa['qas'] for qa in question_answers if len(qa['qas'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Where was the picture taken?', 'At a motorcycle convention.'),\n",
       " ('Who is sitting on the motorcycle?', 'A man.'),\n",
       " ('Where is the motorcycle?', 'A store.'),\n",
       " ('What has two wheels?', 'The motorcycle.'),\n",
       " ('What is the man holding onto?', 'Handles.'),\n",
       " ('What year is on the sign?', '2011.'),\n",
       " ('What is the motorcycle parked for?', 'Display.'),\n",
       " ('What is the man looking at?', 'The camera.'),\n",
       " ('Why is a plate on the bottom?', 'To hold the bike.'),\n",
       " ('What is advertised behind the man?', 'Posters.'),\n",
       " ('What is the poster of?', 'Bike 2011.'),\n",
       " ('What are the two people standing doing?', 'Hugging.'),\n",
       " ('What is the person carrying?', 'Bags.'),\n",
       " ('What is the man sitting on?', 'Motorcycles.'),\n",
       " ('What is the man sitting on?', 'Showroom bike.'),\n",
       " ('What is the man wearing?', 'White hoodie and gray design.'),\n",
       " ('What number is on the motorcycle?', 'Number 54 is on it.'),\n",
       " ('What type of carpet?', 'A red carpet.'),\n",
       " ('Who is sitting on the bike?', 'A man is sitting.'),\n",
       " ('What is black on the bike?', 'The wheel is black.'),\n",
       " (\"What is on the man's face?\", 'A moustache.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "img_qa = random.choice(list(question_answers.values()))\n",
    "list(toolz.pluck(['question', 'answer'], img_qa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a_objects': [],\n",
       "  'question': 'Why are the lights on?',\n",
       "  'image_id': 12,\n",
       "  'qa_id': 988489,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Who us named on the clock face?',\n",
       "  'image_id': 2411253,\n",
       "  'qa_id': 166360,\n",
       "  'answer': 'J. C. Leadbetter.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are these scissors in light?',\n",
       "  'image_id': 2408221,\n",
       "  'qa_id': 190623,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why do the players wear cleats?',\n",
       "  'image_id': 2407189,\n",
       "  'qa_id': 1201108,\n",
       "  'answer': 'Better footing.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is there a light around the mirror?',\n",
       "  'image_id': 2407180,\n",
       "  'qa_id': 198948,\n",
       "  'answer': 'For better visibility.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the dog sleeping in the bed curled up in a ball?',\n",
       "  'image_id': 2405369,\n",
       "  'qa_id': 1158833,\n",
       "  'answer': 'To sleep better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why does the giraffe need to spread the legs?',\n",
       "  'image_id': 2404233,\n",
       "  'qa_id': 1299656,\n",
       "  'answer': 'To reach grass better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the frosting on the cake?',\n",
       "  'image_id': 2400662,\n",
       "  'qa_id': 1226887,\n",
       "  'answer': 'To make it taste better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'What does the hanging sign say?',\n",
       "  'image_id': 2400449,\n",
       "  'qa_id': 1222023,\n",
       "  'answer': \"You'll feel better.\",\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man wearing glasses?',\n",
       "  'image_id': 2399713,\n",
       "  'qa_id': 1531540,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why does the judge sit so high?',\n",
       "  'image_id': 2398919,\n",
       "  'qa_id': 348492,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are the hot dogs cut?',\n",
       "  'image_id': 2397868,\n",
       "  'qa_id': 1522232,\n",
       "  'answer': 'Better cooking.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man wearing gloves?',\n",
       "  'image_id': 2396865,\n",
       "  'qa_id': 1517648,\n",
       "  'answer': 'To have better grasp of the baseball bat.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is she wearing glasses?',\n",
       "  'image_id': 2396845,\n",
       "  'qa_id': 797940,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the motorcycle front wheel smaller?',\n",
       "  'image_id': 2396120,\n",
       "  'qa_id': 1514409,\n",
       "  'answer': 'To better handle the motorcycle while operating it.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the boy looking down?',\n",
       "  'image_id': 2393625,\n",
       "  'qa_id': 1501170,\n",
       "  'answer': 'To better control the skateboard.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is there a mirror?',\n",
       "  'image_id': 2392285,\n",
       "  'qa_id': 801587,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'What is the raised diamond-shaped pattern on the gloves used for?',\n",
       "  'image_id': 2392233,\n",
       "  'qa_id': 1367170,\n",
       "  'answer': 'To have a better grip.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': \"Why is the man's finger in his ear?\",\n",
       "  'image_id': 2392131,\n",
       "  'qa_id': 673733,\n",
       "  'answer': 'To hear better on phone.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why does the girl wear glasses?',\n",
       "  'image_id': 2389862,\n",
       "  'qa_id': 227763,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the boy wearing glasses?',\n",
       "  'image_id': 2389388,\n",
       "  'qa_id': 1542818,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is this photo a close-up?',\n",
       "  'image_id': 2388234,\n",
       "  'qa_id': 484991,\n",
       "  'answer': 'Better detail.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is there an antenna?',\n",
       "  'image_id': 2387016,\n",
       "  'qa_id': 421927,\n",
       "  'answer': 'Better reception.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are his ears up?',\n",
       "  'image_id': 2384601,\n",
       "  'qa_id': 294155,\n",
       "  'answer': 'To hear better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the wood so dark?',\n",
       "  'image_id': 2377344,\n",
       "  'qa_id': 1983558,\n",
       "  'answer': 'Better for sleep.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man wearing glasses?',\n",
       "  'image_id': 2376387,\n",
       "  'qa_id': 1965652,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are two men wearing glasses?',\n",
       "  'image_id': 2376271,\n",
       "  'qa_id': 1963104,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why does the batter wear gloves?',\n",
       "  'image_id': 2374752,\n",
       "  'qa_id': 1933010,\n",
       "  'answer': 'Better grip on the bat.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why does the woman wear eyeglasses?',\n",
       "  'image_id': 2374172,\n",
       "  'qa_id': 1920987,\n",
       "  'answer': 'To better her vision.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are the smallest children in the front?',\n",
       "  'image_id': 2374171,\n",
       "  'qa_id': 688100,\n",
       "  'answer': 'So they can be seen better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the catcher crouched over on the field?',\n",
       "  'image_id': 2373871,\n",
       "  'qa_id': 1915052,\n",
       "  'answer': 'See the ball better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man in the suit wearing glasses?',\n",
       "  'image_id': 2372932,\n",
       "  'qa_id': 1895700,\n",
       "  'answer': 'So he can see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the person holding the hair?',\n",
       "  'image_id': 2372904,\n",
       "  'qa_id': 1895059,\n",
       "  'answer': 'To better cut it.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the woman looking at the man?',\n",
       "  'image_id': 2372894,\n",
       "  'qa_id': 497268,\n",
       "  'answer': 'To help him look better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the woman wearing glasses?',\n",
       "  'image_id': 2372786,\n",
       "  'qa_id': 1892421,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is ther a point at the front of the plane?',\n",
       "  'image_id': 2372486,\n",
       "  'qa_id': 1885861,\n",
       "  'answer': 'To get better wind resistence when in the air.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the wall behind devoid of decoration?',\n",
       "  'image_id': 2372410,\n",
       "  'qa_id': 1884088,\n",
       "  'answer': 'To better focus on the glassware.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man wearing glasses?',\n",
       "  'image_id': 2371267,\n",
       "  'qa_id': 1859950,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the woman holding up the child?',\n",
       "  'image_id': 2371132,\n",
       "  'qa_id': 562643,\n",
       "  'answer': 'For a better view.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man wearing glasses?',\n",
       "  'image_id': 2371070,\n",
       "  'qa_id': 1855811,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the boy practicing tricks on the skateboard?',\n",
       "  'image_id': 2369775,\n",
       "  'qa_id': 1830056,\n",
       "  'answer': 'In order to better his foot placement on the skateboard.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are there two wheels under the head of the aircraft?',\n",
       "  'image_id': 2369512,\n",
       "  'qa_id': 1824790,\n",
       "  'answer': 'To better control landings on runways.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'What kind of condition is the teddy bear in?',\n",
       "  'image_id': 2369340,\n",
       "  'qa_id': 1821275,\n",
       "  'answer': 'Like it has seen better days.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the chair tall?',\n",
       "  'image_id': 2369086,\n",
       "  'qa_id': 1816055,\n",
       "  'answer': 'See better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the umpire bending down?',\n",
       "  'image_id': 2368156,\n",
       "  'qa_id': 1796333,\n",
       "  'answer': 'To get a better view.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the cat on the table?',\n",
       "  'image_id': 2367774,\n",
       "  'qa_id': 501361,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why does the player have bent knees?',\n",
       "  'image_id': 2366891,\n",
       "  'qa_id': 1770657,\n",
       "  'answer': 'To better strike the ball.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why did the players wear shoes with cleats?',\n",
       "  'image_id': 2364622,\n",
       "  'qa_id': 247957,\n",
       "  'answer': 'So they could get better traction.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are the pipes painted yellow?',\n",
       "  'image_id': 2364284,\n",
       "  'qa_id': 1718821,\n",
       "  'answer': 'To be noticed better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man wearing headphones?',\n",
       "  'image_id': 2364016,\n",
       "  'qa_id': 440180,\n",
       "  'answer': 'To hear the music better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': \"Why is the woman's arm up?\",\n",
       "  'image_id': 2363962,\n",
       "  'qa_id': 1712160,\n",
       "  'answer': 'Get a better view.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the players holding a big racket?',\n",
       "  'image_id': 2362793,\n",
       "  'qa_id': 1688605,\n",
       "  'answer': 'Hit the ball better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'How would you describe these bananas?',\n",
       "  'image_id': 2362468,\n",
       "  'qa_id': 1681857,\n",
       "  'answer': 'Like they have seen better days.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is man wearing glasses?',\n",
       "  'image_id': 2362466,\n",
       "  'qa_id': 1681815,\n",
       "  'answer': 'Better vision.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'What are the words at the bottom of the picture?',\n",
       "  'image_id': 2362366,\n",
       "  'qa_id': 1679818,\n",
       "  'answer': '...because of a better bench.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': \"Why is the woman's hand on the customer forehead?\",\n",
       "  'image_id': 2361219,\n",
       "  'qa_id': 1657785,\n",
       "  'answer': 'Better grip to do eyebrows.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the player gripping a tennis racket with both hands in the photo?',\n",
       "  'image_id': 2361007,\n",
       "  'qa_id': 1653636,\n",
       "  'answer': 'Better hit the ball.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are the boys with legs crossed in first row in the photo?',\n",
       "  'image_id': 2360966,\n",
       "  'qa_id': 1652699,\n",
       "  'answer': 'Better sitting position.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why did the woman jump?',\n",
       "  'image_id': 2359646,\n",
       "  'qa_id': 763711,\n",
       "  'answer': 'To hit the ball better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the player wearing a glove?',\n",
       "  'image_id': 2358907,\n",
       "  'qa_id': 1611159,\n",
       "  'answer': 'For better grip on bat.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man wearing glasses?',\n",
       "  'image_id': 2343715,\n",
       "  'qa_id': 520599,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is he crouching on the skateboard?',\n",
       "  'image_id': 2341782,\n",
       "  'qa_id': 266163,\n",
       "  'answer': 'For better balance.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man wearing glasses?',\n",
       "  'image_id': 2339144,\n",
       "  'qa_id': 844109,\n",
       "  'answer': 'To be able to see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is he wearing glasses?',\n",
       "  'image_id': 2323760,\n",
       "  'qa_id': 866271,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the woman pressing her hand to her ear?',\n",
       "  'image_id': 2318816,\n",
       "  'qa_id': 905822,\n",
       "  'answer': 'To hear better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is she wearing eyeglasses?',\n",
       "  'image_id': 2317421,\n",
       "  'qa_id': 916982,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the man on the left covering the meter?',\n",
       "  'image_id': 2414114,\n",
       "  'qa_id': 1023618,\n",
       "  'answer': 'To see better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is she looking at the ball?',\n",
       "  'image_id': 2413109,\n",
       "  'qa_id': 151519,\n",
       "  'answer': 'To hit it better.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are the lights on?',\n",
       "  'image_id': 2412488,\n",
       "  'qa_id': 156484,\n",
       "  'answer': 'For better visibility.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are the people wearing cleats?',\n",
       "  'image_id': 2411631,\n",
       "  'qa_id': 1333685,\n",
       "  'answer': 'To better grip the ground when running.',\n",
       "  'q_objects': []}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[qa for qa in toolz.concat(question_answers.values()) if 'better' in qa['answer'].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38672"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whys = [qa for qa in toolz.concat(question_answers.values()) if qa['question'].lower().startswith('why ')]\n",
    "len(whys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a_objects': [],\n",
       "  'question': 'Why is the hand on the street light?',\n",
       "  'image_id': 2413300,\n",
       "  'qa_id': 149990,\n",
       "  'answer': \"Don't walk.\",\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are his arms out?',\n",
       "  'image_id': 2323698,\n",
       "  'qa_id': 866769,\n",
       "  'answer': 'For balance.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the car there?',\n",
       "  'image_id': 2370224,\n",
       "  'qa_id': 819243,\n",
       "  'answer': \"It's the cat's toy.\",\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the airplane sitting?',\n",
       "  'image_id': 2401632,\n",
       "  'qa_id': 1247966,\n",
       "  'answer': 'Loading.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is shirt so large?',\n",
       "  'image_id': 2399643,\n",
       "  'qa_id': 1469960,\n",
       "  'answer': 'Wrong size.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is this man surfing?',\n",
       "  'image_id': 2347722,\n",
       "  'qa_id': 261441,\n",
       "  'answer': 'For fun.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are the boats stationary?',\n",
       "  'image_id': 2380028,\n",
       "  'qa_id': 619438,\n",
       "  'answer': 'They are anchored.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are there so many ingredients in this photo?',\n",
       "  'image_id': 2347511,\n",
       "  'qa_id': 709431,\n",
       "  'answer': 'Photo for food preparation.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why is the player holding a bat?',\n",
       "  'image_id': 2378053,\n",
       "  'qa_id': 557107,\n",
       "  'answer': 'To hit the ball.',\n",
       "  'q_objects': []},\n",
       " {'a_objects': [],\n",
       "  'question': 'Why are the tree leaves red?',\n",
       "  'image_id': 2403169,\n",
       "  'qa_id': 1276791,\n",
       "  'answer': 'The season is autumn.',\n",
       "  'q_objects': []}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(whys, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\">2370308<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2370308.jpg\" style=\"max-width: 200px\">A dark small handbag; A spotted open umbrella; The black man on the right; The building with two white windows; The gray background  building; The man wearing a leather jacket; The old lady wearing pants; The partially hidden person on the left; The senior old woman; The woman carrying an umbrella; a black backpack on a man's back; a man wearing a leather jacket; a woman wearing a black jacket; a woman wearing white pants; a woman's black leather bag; an animal print umbrella held in the air; buttons on the jacket; cloudy grey skies over the city; edge of a coat; edge of a trouser; edge of an umbrella; grey concrete on the ground; man has short hair; man is carrying a bag; man is wearing a jacket; man wears dark pants; man wears leather jacket; part of a floor; part of a trouser; purse around woman's arm; sidewalk behind people is wet; sidewalk is wet; the sun shining off of the wet ground; umbrella has a leopard print; woman carrying her purse on her arm; woman has dark coat; woman has dark purse; woman has light hair; woman has light slacks; woman holds spotted umbrella; woman is holding the umbrella; woman is wearing earrings; woman is wearing glasses; woman is wearing rings; wooden doors of a building</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(show_images([2370308]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6c9611479f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_qa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_images' is not defined"
     ]
    }
   ],
   "source": [
    "HTML(show_images([img_qa[0]['image_id']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the region descriptions contain more information than the objects/attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-Object Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names = [[name for obj in img['objects'] for name in obj['names']] for img in image_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['couch',\n",
       " 'floor',\n",
       " 'curtains',\n",
       " 'curtains',\n",
       " 'lamp',\n",
       " 'cushion',\n",
       " 'shade',\n",
       " 'cord',\n",
       " 'foot',\n",
       " 'foot']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_names[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_vectorizer = TfidfVectorizer(analyzer=lambda x: x)\n",
    "object_vec_matrix = object_vectorizer.fit_transform(object_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<108077x82827 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1929060 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_vec_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62957"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_vectorizer.vocabulary_['shower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2objname = object_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances_argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairwise_distances_argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['floor',\n",
       " 'mirror',\n",
       " 'faucet',\n",
       " 'sink',\n",
       " 'towel',\n",
       " 'toilet',\n",
       " 'wall',\n",
       " 'bathroom',\n",
       " 'tile',\n",
       " 'shower']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = object_vec_matrix.T.dot(object_vec_matrix[:,object_vectorizer.vocabulary_['shower']]).A.ravel()\n",
    "[id2objname[x] for x in np.argsort(sims)[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['string',\n",
       " 'shirt',\n",
       " 'clouds',\n",
       " 'kites',\n",
       " 'people',\n",
       " 'beach',\n",
       " 'man',\n",
       " 'person',\n",
       " 'sky',\n",
       " 'kite']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = object_vec_matrix.T.dot(object_vec_matrix[:,object_vectorizer.vocabulary_['kite']]).A.ravel()\n",
    "[id2objname[x] for x in np.argsort(sims)[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['window',\n",
       " 'laptop',\n",
       " 'wall',\n",
       " 'mouse',\n",
       " 'keyboard',\n",
       " 'chair',\n",
       " 'computer',\n",
       " 'monitor',\n",
       " 'desk',\n",
       " 'office']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = object_vec_matrix.T.dot(object_vec_matrix[:,object_vectorizer.vocabulary_['office']]).A.ravel()\n",
    "[id2objname[x] for x in np.argsort(sims)[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tree',\n",
       " 'tire',\n",
       " 'street',\n",
       " 'light',\n",
       " 'road',\n",
       " 'car',\n",
       " 'building',\n",
       " 'sign',\n",
       " 'window',\n",
       " 'bus']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = object_vec_matrix.T.dot(object_vec_matrix[:,object_vectorizer.vocabulary_['bus']]).A.ravel()\n",
    "[id2objname[x] for x in np.argsort(sims)[-10:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great, I can generate \"is there a \\_\" questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about more general questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Where is the kite?', 397),\n",
       " ('What color is the kite?', 265),\n",
       " ('Where are the kites?', 223),\n",
       " ('How many kites are there?', 182),\n",
       " ('Who is flying the kite?', 164),\n",
       " ('Who is holding the kite?', 80),\n",
       " ('Who is flying a kite?', 63),\n",
       " ('How many kites are in the sky?', 59),\n",
       " ('How many kites?', 52),\n",
       " ('What is attached to the kite?', 41),\n",
       " ('How many kites are shown?', 37),\n",
       " ('What shape is the kite?', 37),\n",
       " ('What color are the kites?', 30),\n",
       " ('Who is flying the kites?', 30),\n",
       " ('How many kites are in the air?', 29),\n",
       " ('Where are the kites flying?', 27),\n",
       " ('How many kites are flying?', 25),\n",
       " ('What is on the kite?', 23),\n",
       " ('How many kites are in the photo?', 21),\n",
       " ('Where is the kite flying?', 21)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = [qa for qa in toolz.concat(question_answers.values()) if 'kite' in qa['question'].lower()]\n",
    "Counter(toolz.pluck('question', qs)).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What color is the bus?', 1102),\n",
       " ('Where is the bus?', 823),\n",
       " ('How many buses are there?', 381),\n",
       " ('What is behind the bus?', 202),\n",
       " ('Where are the bushes?', 177),\n",
       " ('What color are the bushes?', 157),\n",
       " ('Where is the bus parked?', 143),\n",
       " ('What color are the buses?', 126),\n",
       " ('Who is driving the bus?', 123),\n",
       " ('Where is the bus going?', 115),\n",
       " ('What is the bus doing?', 113),\n",
       " ('What is on the bus?', 111),\n",
       " ('What kind of bus is this?', 104),\n",
       " ('What is on the side of the bus?', 100),\n",
       " ('How many buses?', 98),\n",
       " ('Where are the buses?', 89),\n",
       " ('What number is on the bus?', 89),\n",
       " ('How many buses are in the picture?', 85),\n",
       " ('How many buses are shown?', 83),\n",
       " ('What type of bus is this?', 79)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = [qa for qa in toolz.concat(question_answers.values()) if 'bus' in qa['question'].lower()]\n",
    "Counter(toolz.pluck('question', qs)).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is on the street?', 395),\n",
       " ('What color is the street?', 371),\n",
       " ('What is the street made of?', 196),\n",
       " ('What color is the street sign?', 161),\n",
       " ('What color are the street signs?', 113),\n",
       " ('Where is the street sign?', 98),\n",
       " ('What is the name of the street?', 93),\n",
       " ('What is in the street?', 92),\n",
       " ('What is parked on the street?', 87),\n",
       " ('What is across the street?', 85),\n",
       " ('What does the street sign say?', 76),\n",
       " ('Where is the street light?', 73),\n",
       " ('How many street signs are there?', 71),\n",
       " ('What color are the lines on the street?', 70),\n",
       " ('What is painted on the street?', 67),\n",
       " ('Where are the street signs?', 65),\n",
       " ('Where are the street lights?', 55),\n",
       " ('What color is the street light?', 53),\n",
       " ('What street is this?', 51),\n",
       " ('Who is crossing the street?', 50)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = [qa for qa in toolz.concat(question_answers.values()) if 'street' in qa['question'].lower()]\n",
    "Counter(toolz.pluck('question', qs)).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So thereare some questions that don't make sense, but surprisingly many seem like they will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1, 2)\n",
    "min_df = 20\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, min_df=min_df, max_df=.7)\n",
    "joined_captions = ['\\n'.join(phrases) for phrases in phrases_by_img.values()]\n",
    "caption_vecs = vectorizer.fit_transform(joined_captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgids = list(phrases_by_img.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_caption = \"a shower with a blue mat on the floor in front of it\"\n",
    "query_vec = vectorizer.transform([query_caption])\n",
    "similarity = caption_vecs.dot(query_vec.T).A.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(query_vec[0,x], voc[x]) for x in query_vec.tocoo().col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CosMul similarity. https://tedboy.github.io/nlps/_modules/gensim/models/word2vec.html#Word2Vec.most_similar_cosmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = caption_vecs.dot(vectorizer.transform(['shower', 'towel', 'hanging', 'handle']).T.A).T\n",
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.prod(1 + similarities / 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(show_images([imgids[x] for x in np.argsort(similarity)[-10:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textrec.paths import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import dateutil.parser\n",
    "import datetime\n",
    "import toolz\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invalid():\n",
    "    invalid = set()\n",
    "    with open(paths.data / 'invalid.txt') as f:\n",
    "        for line in f:\n",
    "            line = re.sub(r'#.+', '', line)\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            invalid.add(line)\n",
    "    return invalid\n",
    "INVALID = get_invalid()\n",
    "INVALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_log_data(log_file, earliest):\n",
    "    size = os.path.getsize(log_file)\n",
    "    meta = None\n",
    "    num_nexts = 0\n",
    "    with open(log_file) as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            if 'next' not in line and 'login' not in line and 'finalData' not in line:\n",
    "                continue\n",
    "            line = json.loads(line)\n",
    "            if line.get('type') == 'next':\n",
    "                num_nexts += 1\n",
    "            elif line.get('type') == 'login':\n",
    "                if 'jsTimestamp' in line:\n",
    "                    timestamp = datetime.datetime.fromtimestamp(line['jsTimestamp'] / 1000)\n",
    "                else:\n",
    "                    timestamp = dateutil.parser.parse(line['timestamp'])\n",
    "                if timestamp < earliest:\n",
    "                    return\n",
    "                platform_id = line['platform_id']\n",
    "                meta = dict(\n",
    "                    timestamp=timestamp,\n",
    "                    batch=line.get('batch'),\n",
    "                    config=line['config'],\n",
    "                    platform_id=platform_id,\n",
    "                    participant_id=line['participant_id'],\n",
    "                    size=size,\n",
    "                    complete=False) # will override\n",
    "            elif line.get('type') == 'finalData':\n",
    "#                 meta['finalData'] = line['finalData']\n",
    "                meta['complete'] = True\n",
    "    if meta:\n",
    "        return dict(meta, num_nexts=num_nexts)\n",
    "\n",
    "\n",
    "def get_logs(log_path, earliest):\n",
    "    log_files = []\n",
    "    for log_file in log_path.glob('*.jsonl'):\n",
    "        data = get_log_data(log_file, earliest)\n",
    "        if data is not None:\n",
    "#             print(data)\n",
    "            log_files.append(data)\n",
    "    return log_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_files = get_logs(paths.top_level / 'logs-gcp1', earliest = datetime.datetime(2018, 5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_invalid = [entry for entry in log_files if entry['participant_id'] not in INVALID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete = [entry for entry in not_invalid if entry['complete']]\n",
    "complete.sort(key=lambda x: x['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_by_group = {\n",
    "    config: [participant['participant_id'] for participant in sorted(group, key=lambda x: x['timestamp'])]\n",
    "    for config, group in toolz.groupby('batch', complete).items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dump a list of participant_ids\n",
    "for config, group in complete_by_group.items():\n",
    "    print()\n",
    "    print(f'{len(group)} completed in {config}')\n",
    "    print(f'{config}:',  ' '.join(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrec.quick_summary import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(sys.modules[summarize.__module__])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(complete_by_group['xs1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "did_some_work = [entry for entry in not_invalid if entry['num_nexts'] > 4] # arbitrary cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "incomplete = [entry for entry in did_some_work if not entry['complete']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -m textrec.quick_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize([x['participant_id'] for x in incomplete], incomplete_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "' '.join(entry['participant_id'] for entry in complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrec.counterbalancing import get_completion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = pd.DataFrame(get_completion_data('gc1'))\n",
    "completions['login_timestamp'] = pd.to_datetime(completions.login_timestamp, unit='s')\n",
    "completions = completions.sort_values('login_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions.login_timestamp.iloc[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions[\n",
    "    completions.completed\n",
    "   & (completions.login_timestamp < pd.Timestamp(year=2018, month=6, day=29))].assignment.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

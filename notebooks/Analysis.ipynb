{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis pipeline for Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/code/textrec\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/textrec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import toolz\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<module 'textrec.analysis_util' from '/Users/kcarnold/code/textrec/src/textrec/analysis_util.py'>,\n",
       " <module 'textrec.util' from '/Users/kcarnold/code/textrec/src/textrec/util.py'>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textrec.paths import paths\n",
    "from textrec import analysis_util, util\n",
    "reload(analysis_util), reload(util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Karpathy's version of the COCO captions dataset. This has the train-test split that is more commonly used in the literature, as well as pre-tokenized captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = util.get_coco_captions()\n",
    "images_by_split = toolz.groupby('split', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2img = {img['cocoid']: img for img in images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2url = util.get_coco_id2url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(indices):\n",
    "    def img(idx):\n",
    "        img = id2img[idx]\n",
    "        captions = '\\n'.join(\n",
    "            '<div>{}</div>'.format(sent)\n",
    "            for sent in toolz.pluck('raw', img['sentences'])\n",
    "        )\n",
    "        return '<div style=\"display: inline-block;\"><div>{}/{}</div><img src=\"{}\">{}</div>'.format(\n",
    "            img['split'], img['cocoid'], id2url[img['cocoid']], captions)\n",
    "\n",
    "    return '\\n'.join(img(idx) for idx in indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>val/184613</div><img src=\"http://images.cocodataset.org/train2017/000000184613.jpg\"><div>A child holding a flowered umbrella and petting a yak.</div>\n",
       "<div>A young man holding an umbrella next to a herd of cattle.</div>\n",
       "<div>a young boy barefoot holding an umbrella touching the horn of a cow</div>\n",
       "<div>A young boy with an umbrella who is touching the horn of a cow.</div>\n",
       "<div>A boy holding an umbrella while standing next to livestock.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(show_images([images_by_split['val'][0]['cocoid']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of writing experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -m textrec.batch_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = get_participants_by_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2018-04-09', '2018-04-24', '2018-04-27', '2018-05-02'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "h52x67\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:specific:a cat sitting next to a glass bowl, looking up to the camera\n",
      "final-0-1:specific:a shower with dirty glass doors has a beige towel hanging on the outside\n",
      "final-0-2:specific:there is no image here \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a bride and groom cutting their wedding cake, while a photographer guides them\n",
      "final-1-1:norecs:a man helping his children fly a multicolor butterfly kite on a clear day\n",
      "final-1-2:norecs:a passenger train approaching a small quaint station with a blue and white building on the background\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a busy street in a historic town with a red bus driving on the street. \n",
      "final-2-1:general:a tennis player hits a ball during a game \n",
      "final-2-2:general:a surfer riding a wave on a sunny day \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: There was no image in he third task.\n",
      "postTask-0-other: The keyboard seemed to have the words I wanted already there, on many of them all I had to do was touch the word.\n",
      "postTask-1-techDiff: None.\n",
      "postTask-1-other: It was a little more challenging this time, because there were no predicted words. Also I had to be extra careful with spelling!\n",
      "postTask-2-techDiff: No.\n",
      "postTask-2-other: This also had predicted words, but somehow I had a harder time coming up with good descriptions. The photos seemed too generic for some reason.\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 41\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: Just the fact that the third photo in keyboard 1 never loaded.\n",
      "postExp-other: It was fun! Just feel a little unsure that I will be penalized for not writing a caption for the third photo on keyboard 1. I hope that was OK. Thank you!\n",
      "\n",
      "Total time: 47.0m\n",
      "ExperimentScreen: 2094.0\n",
      "PostTaskSurvey: 276.4\n",
      "PostExpSurvey: 156.4\n",
      "Instructions: 127.3\n",
      "TaskDescription: 72.3\n",
      "Welcome: 34.8\n",
      "StudyDesc: 31.9\n",
      "IntroSurvey: 15.5\n",
      "PostPractice: 9.9\n",
      "\n",
      "jvccx2\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a yellow cat with strips is setting on a place mat  on a table behind a half of glass of red wine\n",
      "final-0-1:general:a small bath with a shower with a blue mat on the floor\n",
      "final-0-2:general:a bath room with a white toilet and a white washbasin \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a newly wedded couple cutting there wedding cake with a lady helping the bride cut the cake\n",
      "final-1-1:norecs:a group of people flying kites on a beach and its a beautiful day\n",
      "final-1-2:norecs:a train station with three building to the left it is a nice sunny day\n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a busy city street with cars and people along the streets with high-rise buildings on both sides\n",
      "final-2-1:specific:a tennis player is trying hard to return the ball oronto is written in the grass\n",
      "final-2-2:specific:a surfer is riding a wave the water looks so refreshing its a beautiful day \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None\n",
      "postTask-0-other: Fun study\n",
      "postTask-1-techDiff: None\n",
      "postTask-1-other: The key board was difficult\n",
      "postTask-2-techDiff: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 36\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: None\n",
      "postExp-other: Use  my data\n",
      "\n",
      "Total time: 34.9m\n",
      "ExperimentScreen: 1478.8\n",
      "PostTaskSurvey: 274.4\n",
      "PostExpSurvey: 125.0\n",
      "TaskDescription: 70.6\n",
      "PostPractice: 38.5\n",
      "Welcome: 36.4\n",
      "IntroSurvey: 27.0\n",
      "StudyDesc: 25.1\n",
      "Instructions: 16.6\n",
      "\n",
      "36x2r3\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a tricolor cat is sitting in front of a partially full wine glass\n",
      "final-0-1:norecs:someome is using a shower but it's hard to see due to the opaque glass\n",
      "final-0-2:norecs:a clean bathroom with a white sink near a white toilet\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:specific:a black and white photo or a large man and a woman cutting thwir wedding cake\n",
      "final-1-1:specific:colorful kites are flown above a sandy beach by two children and an adult\n",
      "final-1-2:specific:a brown trai  pulls into the tracka next to some colorful buildings\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red trolley drives through a stree surrounded by plain brick buildings. \n",
      "final-2-1:general:a tennis player is ready to hit the tennis ball across the court. \n",
      "final-2-2:general:a surfer leans forward to ride a wave\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-0-other: None\n",
      "postTask-1-techDiff: None\n",
      "postTask-1-other: None\n",
      "postTask-2-techDiff: None\n",
      "postTask-2-other: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 24\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: Mone\n",
      "postExp-other: None\n",
      "\n",
      "Total time: 10.2m\n",
      "ExperimentScreen: 332.4\n",
      "PostTaskSurvey: 92.8\n",
      "TaskDescription: 75.7\n",
      "PostExpSurvey: 46.4\n",
      "Welcome: 26.7\n",
      "StudyDesc: 16.6\n",
      "IntroSurvey: 11.9\n",
      "Instructions: 6.1\n",
      "PostPractice: 3.6\n",
      "\n",
      "qmwvwv\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:brown cat is crouching in the background of a glass of wine\n",
      "final-0-1:specific:brown towel is hanging on a sliding shower door\n",
      "final-0-2:specific:toilet paper roll is on top of the toilet in a mellow yellow painted bathroom \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:wedding photographer is guiding a bride and groom as to how they should cut their cake\n",
      "final-1-1:norecs:man and two girls are flying butterfly kites on a very windy and cloudy day\n",
      "final-1-2:norecs:a train passes by a series of brightly blue and white station buildings\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red two story city bus is driving in a european city with pedestrians all around \n",
      "final-2-1:general:a tennis player is about to hit the tennis ball \n",
      "final-2-2:general:a surfer in a white and black suit is leaning forward and riding a wave \n",
      "\n",
      "intro-use_predictive: No\n",
      "postTask-0-techDiff: None\n",
      "postTask-1-techDiff: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 30\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "\n",
      "Total time: 13.6m\n",
      "ExperimentScreen: 550.7\n",
      "PostTaskSurvey: 112.8\n",
      "PostExpSurvey: 48.3\n",
      "TaskDescription: 41.2\n",
      "StudyDesc: 18.9\n",
      "IntroSurvey: 17.6\n",
      "Welcome: 12.1\n",
      "PostPractice: 10.6\n",
      "Instructions: 3.9\n",
      "\n",
      "77j4mf\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling textrec.analysis_util.get_log_analysis_raw...\n",
      "get_log_analysis_raw('/Users/kcarnold/code/textrec/logs/77j4mf.jsonl', 1660899, git_rev='c651507', analysis_files={ 'analyze.js': '76f95f2156828639ea7c756411b37a4e03cdd403',\n",
      "  'run-analysis': '11083c5f51c5c469297e930142323920f09fe548',\n",
      "  'src/Analyzer.js': 'e8d4e8df767b71fe55698cf95fd9ceddd7b6d3bb'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________get_log_analysis_raw - 3.8s, 0.1min\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a glass of red wine sitting in fronf of a brown cat with brown stripes on a brown mat\n",
      "final-0-1:norecs:a beige towel hangs over the rightmost shower door both of which are wet with water\n",
      "final-0-2:norecs:a toilet with the seat down and a roll of toilet paper on top is next to a white sink\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:specific:a husband, bride and female all stand in front of a table holding a knife cutting a cake\n",
      "final-1-1:specific:two children and one adult stand on the beach holding kites and flying them into the sky \n",
      "final-1-2:specific:a train on the tracks passes a white house with blue paint before approaching another white house\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red double-decker bus passes a group of people to its lefg while a black car looks to pass\n",
      "final-2-1:general:a man with a tennis racket, white shirt and shoes holds his racket back in order to hit the ball\n",
      "final-2-2:general:a man with a white shirt and blue pants stands on a surfboard as the wave rises\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-other: Annoying \n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 23\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-other: This was very annoying\n",
      "\n",
      "Total time: 13.2m\n",
      "ExperimentScreen: 490.0\n",
      "PostTaskSurvey: 168.1\n",
      "Welcome: 43.3\n",
      "PostExpSurvey: 41.7\n",
      "TaskDescription: 24.0\n",
      "IntroSurvey: 11.3\n",
      "StudyDesc: 9.8\n",
      "PostPractice: 3.5\n",
      "Instructions: 3.3\n",
      "\n",
      "692c8j\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a tabby cat standing behind a glass of wine stares at me\n",
      "final-0-1:norecs:a tan towel hangs in front of a glass shower\n",
      "final-0-2:norecs:a wrapped roll of toilet paper sits on top of a toilet in front if a metal bar and next to a porcelain sink. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a woman in a wedding dress cuts a cake with her husband and the photographer. \n",
      "final-1-1:general:a man flies a butterfly kite with his two daughters. \n",
      "final-1-2:general:a train is approaching the station and passing in front of blue and white buildings \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a double decker red bus drives down a crowded street with a car behind it. \n",
      "final-2-1:specific:a tennis player uses his backhand to swing at a tennis ball on a green and blue court \n",
      "final-2-2:specific:a blonde man in a wetsuit surfs a wave. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: No\n",
      "postTask-2-techDiff: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 27\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No \n",
      "\n",
      "Total time: 24.7m\n",
      "ExperimentScreen: 1063.2\n",
      "PostTaskSurvey: 185.6\n",
      "StudyDesc: 54.5\n",
      "Welcome: 51.7\n",
      "TaskDescription: 50.0\n",
      "PostExpSurvey: 47.3\n",
      "IntroSurvey: 17.5\n",
      "PostPractice: 8.2\n",
      "Instructions: 6.4\n",
      "\n",
      "gg65g6\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a car is sitting on a table behind a wine glass with red wine in it. \n",
      "final-0-1:general:i see a standing shower with two hazy sliding glass doors and a towel hanging off of one. \n",
      "final-0-2:general:its a public restroom with a white sink and toilet. \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a bride and groom are both holding onto the same knife to cut their wedding cake. \n",
      "final-1-1:norecs:kids at a beach flying colourful kites. \n",
      "final-1-2:norecs:a train is pulling into the train station. \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a busy city street with cars, a large red bus and pedestrians going about their day. \n",
      "final-2-1:specific:roger federer about to back hand a tennis ball in a tennis match. \n",
      "final-2-2:specific:a male surfer riding on his surfboard in the ocean. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None.\n",
      "postTask-1-techDiff: None.\n",
      "postTask-2-techDiff: None.\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 26\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: None.\n",
      "postExp-other: No problems, hit was fine. Really liked the third board, it was the best one by far.\n",
      "\n",
      "Total time: 17.9m\n",
      "ExperimentScreen: 623.5\n",
      "PostTaskSurvey: 179.3\n",
      "PostExpSurvey: 117.0\n",
      "TaskDescription: 63.2\n",
      "Welcome: 31.6\n",
      "StudyDesc: 25.8\n",
      "IntroSurvey: 22.0\n",
      "PostPractice: 8.2\n",
      "Instructions: 3.9\n",
      "\n",
      "3vf5fg\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a tabby cat sits on a table behind a glass of red wine\n",
      "final-0-1:norecs:a glass shower door has a towel rack on it with a beige towel. \n",
      "final-0-2:norecs:a bathroom has a white toilet and matching sink. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven. \n",
      "final-1-0:general:a newly wedded couple is seen cutting the cake in black and white. \n",
      "final-1-1:general:a family is flying kites on a beach together near a body of water. \n",
      "final-1-2:general:a train sits beside some colorful buildings on a track. \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a busy city street has sidewalks full of people and a bus and some cars. \n",
      "final-2-1:specific:a tennis player raises his arm to hit the ball with his racket. \n",
      "final-2-2:specific:a person is surfing on a wave in the ocean. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None\n",
      "postTask-0-other: None\n",
      "postTask-1-techDiff: None\n",
      "postTask-1-other: None\n",
      "postTask-2-techDiff: None\n",
      "postTask-2-other: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 33\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: None\n",
      "postExp-other: Fun. I could to these exercises all day.\n",
      "\n",
      "Total time: 15.3m\n",
      "ExperimentScreen: 531.7\n",
      "PostTaskSurvey: 139.9\n",
      "PostExpSurvey: 73.7\n",
      "Instructions: 48.9\n",
      "StudyDesc: 43.2\n",
      "Welcome: 39.1\n",
      "TaskDescription: 17.0\n",
      "IntroSurvey: 13.7\n",
      "PostPractice: 9.5\n"
     ]
    }
   ],
   "source": [
    "# summarize('2018-04-27')\n",
    "summarize('2018-05-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = get_trial_data('2018-05-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in trial_data:\n",
    "    trial['text'] = trial['text'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had the wrong URL for one image when one person ran it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = [trial for trial in trial_data if not (trial['stimulus'] == 431140 and trial['participant'] == 'h52x67')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a cat sitting next to a glass bowl, looking up to the camera',\n",
       " 'a shower with dirty glass doors has a beige towel hanging on the outside',\n",
       " 'a bride and groom cutting their wedding cake, while a photographer guides them',\n",
       " 'a man helping his children fly a multicolor butterfly kite on a clear day',\n",
       " 'a passenger train approaching a small quaint station with a blue and white building on the background',\n",
       " 'a busy street in a historic town with a red bus driving on the street.',\n",
       " 'a tennis player hits a ball during a game',\n",
       " 'a surfer riding a wave on a sunny day',\n",
       " 'a yellow cat with strips is setting on a place mat  on a table behind a half of glass of red wine',\n",
       " 'a small bath with a shower with a blue mat on the floor',\n",
       " 'a bath room with a white toilet and a white washbasin',\n",
       " 'a newly wedded couple cutting there wedding cake with a lady helping the bride cut the cake',\n",
       " 'a group of people flying kites on a beach and its a beautiful day',\n",
       " 'a train station with three building to the left it is a nice sunny day',\n",
       " 'a busy city street with cars and people along the streets with high-rise buildings on both sides',\n",
       " 'a tennis player is trying hard to return the ball oronto is written in the grass',\n",
       " 'a surfer is riding a wave the water looks so refreshing its a beautiful day',\n",
       " 'a tricolor cat is sitting in front of a partially full wine glass',\n",
       " \"someome is using a shower but it's hard to see due to the opaque glass\",\n",
       " 'a clean bathroom with a white sink near a white toilet',\n",
       " 'a black and white photo or a large man and a woman cutting thwir wedding cake',\n",
       " 'colorful kites are flown above a sandy beach by two children and an adult',\n",
       " 'a brown trai  pulls into the tracka next to some colorful buildings',\n",
       " 'a red trolley drives through a stree surrounded by plain brick buildings.',\n",
       " 'a tennis player is ready to hit the tennis ball across the court.',\n",
       " 'a surfer leans forward to ride a wave',\n",
       " 'brown cat is crouching in the background of a glass of wine',\n",
       " 'brown towel is hanging on a sliding shower door',\n",
       " 'toilet paper roll is on top of the toilet in a mellow yellow painted bathroom',\n",
       " 'wedding photographer is guiding a bride and groom as to how they should cut their cake',\n",
       " 'man and two girls are flying butterfly kites on a very windy and cloudy day',\n",
       " 'a train passes by a series of brightly blue and white station buildings',\n",
       " 'a red two story city bus is driving in a european city with pedestrians all around',\n",
       " 'a tennis player is about to hit the tennis ball',\n",
       " 'a surfer in a white and black suit is leaning forward and riding a wave',\n",
       " 'a glass of red wine sitting in fronf of a brown cat with brown stripes on a brown mat',\n",
       " 'a beige towel hangs over the rightmost shower door both of which are wet with water',\n",
       " 'a toilet with the seat down and a roll of toilet paper on top is next to a white sink',\n",
       " 'a husband, bride and female all stand in front of a table holding a knife cutting a cake',\n",
       " 'two children and one adult stand on the beach holding kites and flying them into the sky',\n",
       " 'a train on the tracks passes a white house with blue paint before approaching another white house',\n",
       " 'a red double-decker bus passes a group of people to its lefg while a black car looks to pass',\n",
       " 'a man with a tennis racket, white shirt and shoes holds his racket back in order to hit the ball',\n",
       " 'a man with a white shirt and blue pants stands on a surfboard as the wave rises',\n",
       " 'a tabby cat standing behind a glass of wine stares at me',\n",
       " 'a tan towel hangs in front of a glass shower',\n",
       " 'a wrapped roll of toilet paper sits on top of a toilet in front if a metal bar and next to a porcelain sink.',\n",
       " 'a woman in a wedding dress cuts a cake with her husband and the photographer.',\n",
       " 'a man flies a butterfly kite with his two daughters.',\n",
       " 'a train is approaching the station and passing in front of blue and white buildings',\n",
       " 'a double decker red bus drives down a crowded street with a car behind it.',\n",
       " 'a tennis player uses his backhand to swing at a tennis ball on a green and blue court',\n",
       " 'a blonde man in a wetsuit surfs a wave.',\n",
       " 'a car is sitting on a table behind a wine glass with red wine in it.',\n",
       " 'i see a standing shower with two hazy sliding glass doors and a towel hanging off of one.',\n",
       " 'its a public restroom with a white sink and toilet.',\n",
       " 'a bride and groom are both holding onto the same knife to cut their wedding cake.',\n",
       " 'kids at a beach flying colourful kites.',\n",
       " 'a train is pulling into the train station.',\n",
       " 'a busy city street with cars, a large red bus and pedestrians going about their day.',\n",
       " 'roger federer about to back hand a tennis ball in a tennis match.',\n",
       " 'a male surfer riding on his surfboard in the ocean.',\n",
       " 'a tabby cat sits on a table behind a glass of red wine',\n",
       " 'a glass shower door has a towel rack on it with a beige towel.',\n",
       " 'a bathroom has a white toilet and matching sink.',\n",
       " 'a newly wedded couple is seen cutting the cake in black and white.',\n",
       " 'a family is flying kites on a beach together near a body of water.',\n",
       " 'a train sits beside some colorful buildings on a track.',\n",
       " 'a busy city street has sidewalks full of people and a bus and some cars.',\n",
       " 'a tennis player raises his arm to hit the ball with his racket.',\n",
       " 'a person is surfing on a wave in the ocean.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(toolz.pluck('text', trial_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(trial_data).to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate nAFC task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vectorizer, caption_vecs = util.get_vectorized_captions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123287, 9952)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://images.cocodataset.org/train2017/000000570528.jpg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2url[570528]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a cat sitting next to a glass bowl, looking up to the camera\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>restval/570528</div><img src=\"http://images.cocodataset.org/train2017/000000570528.jpg\"><div>A large orange cat sitting in a white glass bowl.</div>\n",
       "<div>A cat sitting in a bowl on a table looking at the camera.</div>\n",
       "<div>a brown cat sitting inside a fancy bowl</div>\n",
       "<div>A cat looking back is sitting in a bowl.</div>\n",
       "<div>A cat is sitting in a white bowl.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>val/300732</div><img src=\"http://images.cocodataset.org/train2017/000000300732.jpg\"><div>A black cat standing over a glass bowl.</div>\n",
       "<div>A black and white cat sitting on top of a table.</div>\n",
       "<div>A cat sitting in front of his food bowl looking at the camera.</div>\n",
       "<div>A black and white defensively looking up by its bowl.</div>\n",
       "<div>A black and white cat eating from a ceramic bowl.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/400999</div><img src=\"http://images.cocodataset.org/train2017/000000400999.jpg\"><div>A cat sits on the table next to a bowl.</div>\n",
       "<div>A black cat is standing next to a bowl on a table</div>\n",
       "<div>A black cat sits on a small white table next to a fruit bowl.</div>\n",
       "<div>a cat sitting on a table next to a bowl of fruit</div>\n",
       "<div>A black cat sits on a table next to a fruit bowl.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/449770</div><img src=\"http://images.cocodataset.org/train2017/000000449770.jpg\"><div> A cat sitting on the floor near a bag.</div>\n",
       "<div>A cat is sitting next to a camera in a case.</div>\n",
       "<div>A cat sitting next to an open camera bag.</div>\n",
       "<div>a cat that is sitting next to a backpack</div>\n",
       "<div>A cat that is sitting next to a backpack.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>test/146767</div><img src=\"http://images.cocodataset.org/train2017/000000146767.jpg\"><div>A cat laying next to a stainless steel bowl.</div>\n",
       "<div>a close up of a cat near a bowl</div>\n",
       "<div>A gray cat laying on the floor next to a food dish.</div>\n",
       "<div>A grey cat is laying next to a metal bowl.</div>\n",
       "<div>Cat laying down with a bowl in front of it.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/548661</div><img src=\"http://images.cocodataset.org/train2017/000000548661.jpg\"><div>a cat sitting on a table next to a colorful bowl</div>\n",
       "<div>A ginger cat lying on a table next to a bowl</div>\n",
       "<div>A cat sitting on top of the table beside a dish. </div>\n",
       "<div>an orange and white cat laying on a brown table</div>\n",
       "<div>A golden colored cat sitting next to a bowl.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>val/279386</div><img src=\"http://images.cocodataset.org/train2017/000000279386.jpg\"><div>A small cat sitting under a wooden table.</div>\n",
       "<div>A brown and white cat sitting next to a glass.</div>\n",
       "<div>a cat underneath a wood table playing with a glass cup</div>\n",
       "<div>A cat is playing with a glass under a table.</div>\n",
       "<div>A cat leaned over looking at a glass on the floor.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/350727</div><img src=\"http://images.cocodataset.org/train2017/000000350727.jpg\"><div>A cat is sitting in a bowl which is on the floor.</div>\n",
       "<div>There is a adult cat that is sitting in a bowl</div>\n",
       "<div>A grey cat sitting in a blue bowl</div>\n",
       "<div>The cat is sitting in the bowl on the floor. </div>\n",
       "<div>The cat sits in the bowl on the floor.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>test/2295</div><img src=\"http://images.cocodataset.org/train2017/000000002295.jpg\"><div>A cat peering into a wooden bowl which is sitting on a table.</div>\n",
       "<div>A CAT ON A WOODEN SURFACE IS LOOKING AT A WOODEN BOWL</div>\n",
       "<div>A cat is looking at an empty bowl on the floor.</div>\n",
       "<div>A cat staring at the bottom of a brown bowl. </div>\n",
       "<div>A cat looking inside a wooden bowl for some food.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/537417</div><img src=\"http://images.cocodataset.org/train2017/000000537417.jpg\"><div>A black and white cat is sitting in a ceramic bowl.</div>\n",
       "<div>A cat sitting inside of a bowl on top of  a table.</div>\n",
       "<div>A black and white cat sits in a bowl on a table.</div>\n",
       "<div>A cat sitting in a bowl on a table </div>\n",
       "<div>A cat is sitting in a bowl on a table.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similar_images(caption, n=10):\n",
    "    query_vec = cap_vectorizer.transform([caption])\n",
    "    similarity = caption_vecs.dot(query_vec.T).A.ravel()\n",
    "    return [images[idx]['cocoid'] for idx in np.argsort(similarity)[-n:][::-1]]\n",
    "query_caption = trial_data[0]['text']\n",
    "print(query_caption)\n",
    "HTML(show_images(get_similar_images(query_caption)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://images.cocodataset.org/train2017/000000570528.jpg|http://images.cocodataset.org/train2017/000000300732.jpg|http://images.cocodataset.org/train2017/000000400999.jpg|http://images.cocodataset.org/train2017/000000449770.jpg|http://images.cocodataset.org/train2017/000000146767.jpg|http://images.cocodataset.org/train2017/000000548661.jpg|http://images.cocodataset.org/train2017/000000279386.jpg|http://images.cocodataset.org/train2017/000000350727.jpg|http://images.cocodataset.org/train2017/000000002295.jpg|http://images.cocodataset.org/train2017/000000537417.jpg'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'|'.join(id2url[idx] for idx in get_similar_images(query_caption))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[396295, 277466, 362711, 212082, 409842, 233737, 510852, 503200, 480798, 98257]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_foil_set(*, stimulus, caption, rs):\n",
    "    similar_images = get_similar_images(caption, n=10)\n",
    "    if stimulus not in similar_images:\n",
    "        print(\"Inserting\", stimulus, 'into foil set')\n",
    "        similar_images[-1] = stimulus\n",
    "    rs.shuffle(similar_images)\n",
    "    return similar_images\n",
    "trial = trial_data[1]\n",
    "get_foil_set(stimulus=trial['stimulus'], caption=trial['text'], rs=np.random.RandomState(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_task(trial, rs):\n",
    "    stimulus = trial['stimulus']\n",
    "    foil_set = get_foil_set(stimulus=stimulus, caption=trial['text'], rs=rs)\n",
    "    res = dict(description=trial['text'], correct_idx=foil_set.index(stimulus))\n",
    "    for i, idx in enumerate(foil_set):\n",
    "        res[f'image_{i}_url'] = id2url[idx]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 275449 into foil set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correct_idx': 8,\n",
       " 'description': 'a cat sitting next to a glass bowl, looking up to the camera',\n",
       " 'image_0_url': 'http://images.cocodataset.org/train2017/000000146767.jpg',\n",
       " 'image_1_url': 'http://images.cocodataset.org/train2017/000000570528.jpg',\n",
       " 'image_2_url': 'http://images.cocodataset.org/train2017/000000350727.jpg',\n",
       " 'image_3_url': 'http://images.cocodataset.org/train2017/000000548661.jpg',\n",
       " 'image_4_url': 'http://images.cocodataset.org/train2017/000000002295.jpg',\n",
       " 'image_5_url': 'http://images.cocodataset.org/train2017/000000449770.jpg',\n",
       " 'image_6_url': 'http://images.cocodataset.org/train2017/000000300732.jpg',\n",
       " 'image_7_url': 'http://images.cocodataset.org/train2017/000000279386.jpg',\n",
       " 'image_8_url': 'http://images.cocodataset.org/train2017/000000275449.jpg',\n",
       " 'image_9_url': 'http://images.cocodataset.org/train2017/000000400999.jpg'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_task(trial_data[0], np.random.RandomState(123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MTurk results so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_files = list((paths.data / 'mturk').glob('*-2AFC.csv'))\n",
    "# mturk_2afc_results = (\n",
    "#     pd.concat([pd.read_csv(str(f)) for f in result_files], axis=0, ignore_index=True)\n",
    "#     if len(result_files)\n",
    "#     else pd.DataFrame([], columns=['Input.caption']))\n",
    "result_files = list((paths.data / 'mturk').glob('*-nAFC.csv'))\n",
    "mturk_nafc_results = (\n",
    "    pd.concat([pd.read_csv(str(f)) for f in result_files], axis=0, ignore_index=True)\n",
    "    if len(result_files)\n",
    "    else pd.DataFrame([], columns=['Answer.description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comparisons_by_caption = mturk_nafc_results.groupby('Answer.description').size().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tasks remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 71)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_todo = [trial for trial in trial_data if num_comparisons_by_caption.get(trial['text'], 0) < 5]\n",
    "len(trial_data), len(trials_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/kcarnold/code/textrec/HITs/2018-05-11-0-nAFC.csv')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "while True:\n",
    "    out_fn = paths.top_level / 'HITs' / f'{datetime.date.today().isoformat()}-{i}-nAFC.csv'\n",
    "    if not out_fn.exists():\n",
    "        break\n",
    "    i += 1\n",
    "out_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 275449 into foil set\n",
      "Inserting 200451 into foil set\n",
      "Inserting 223777 into foil set\n"
     ]
    }
   ],
   "source": [
    "rs = np.random.RandomState(1234)\n",
    "pd.DataFrame([make_task(trial, rs) for trial in trials_todo[:5]]).to_csv(out_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the actual HIT text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "html = Template(open(paths.top_level / 'HITs' / '2018-05-04-image-description-match.jinja.html').read()).render(dict(\n",
    "    description='${description}',\n",
    "    images=['${image_%d_url}' % i for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"height: 500px; position: relative;\"><link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\">\n",
       "<style>\n",
       "\n",
       ".outer-container {\n",
       "/*  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  width: 100%;\n",
       "*/}\n",
       "\n",
       "#submitButton{\n",
       "  white-space: normal;\n",
       "}\n",
       "\n",
       ".instructions {\n",
       "  flex: 0 0 150px;\n",
       "}\n",
       "\n",
       ".image-option button:disabled {\n",
       "  cursor: not-allowed;\n",
       "  opacity: .25;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<meta content=\"width=device-width,initial-scale=1\" name=\"viewport\" />\n",
       "<section class=\"outer-container\">\n",
       "\n",
       "  <section class=\"instructions\">\n",
       "    <p>Someone wrote this description for one of the 10 images below:</p>\n",
       "\n",
       "    <blockquote><b style=\"font-size: 200%\">&ldquo;a bride and groom cutting their wedding cake, while a photographer guides them&rdquo;</b></blockquote>\n",
       "\n",
       "    <p>Try to guess which of the 10 images this description was written for. Click an image to guess it. Try to get it in as few guesses as possible.</p>\n",
       "\n",
       "    <p>If any of the images doesn't load, make a note in the feedback section and submit the HIT incomplete.</p>\n",
       "  </section>\n",
       "\n",
       "\n",
       "<div style=\"flex: 1 0 0; overflow: auto; display: flex; flex-flow: row wrap; align-items: center;\">\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"0\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000119065.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 1 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"1\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000466456.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 2 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"2\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000227326.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 3 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"3\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000185559.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 4 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"4\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000564058.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 5 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"5\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000561454.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 6 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"6\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000086147.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 7 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"7\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000352892.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 8 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"8\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000554635.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 9 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "<div style=\"flex: 0 0 300px; padding: 10px;\" class=\"image-option\" data-idx=\"9\">\n",
       "  <button class=\"guess\">\n",
       "    <img src=\"http://images.cocodataset.org/train2017/000000162332.jpg\" style=\"max-width: 100%; max-height: 400px; display: inline-block;\" alt=\"Image 10 should appear here\">\n",
       "  </button>\n",
       "</div>\n",
       "\n",
       "</div>\n",
       "</section>\n",
       "\n",
       "<p>\n",
       "  This is a new HIT, so we&#39;d appreciate your feedback: are the instructions clear? Is the payment fair? Any technical difficulties? Anything else?<br>\n",
       "  <textarea cols=\"80\" name=\"feedback\" placeholder=\"optional feedback\" rows=\"4\"></textarea>\n",
       "</p>\n",
       "\n",
       "\n",
       "<input id=\"data-description\" type=\"hidden\" name=\"description\" value=\"a bride and groom cutting their wedding cake, while a photographer guides them\">\n",
       "<input id=\"data-images\" type=\"hidden\" name=\"images\" value=\"http://images.cocodataset.org/train2017/000000119065.jpg|http://images.cocodataset.org/train2017/000000466456.jpg|http://images.cocodataset.org/train2017/000000227326.jpg|http://images.cocodataset.org/train2017/000000185559.jpg|http://images.cocodataset.org/train2017/000000564058.jpg|http://images.cocodataset.org/train2017/000000561454.jpg|http://images.cocodataset.org/train2017/000000086147.jpg|http://images.cocodataset.org/train2017/000000352892.jpg|http://images.cocodataset.org/train2017/000000554635.jpg|http://images.cocodataset.org/train2017/000000162332.jpg\">\n",
       "<input id=\"data-correct-idx\" type=\"hidden\" name=\"correctIdx\" values=\"\">\n",
       "<input id=\"data-guesses\" type=\"hidden\" name=\"guesses\" value=\"[]\">\n",
       "\n",
       "<script\n",
       "        src=\"https://code.jquery.com/jquery-3.3.1.slim.js\"\n",
       "        integrity=\"sha256-fNXJFIlca05BIO2Y5zh1xrShK3ME+/lYZ0j+ChxX2DA=\"\n",
       "        crossorigin=\"anonymous\"></script>\n",
       "<script>\n",
       "var correctIdx = 2;\n",
       "var guesses = [];\n",
       "$(function() {\n",
       "  $('.image-option').on('click', 'button.guess', function(event) {\n",
       "    var idx = +$(event.delegateTarget).attr('data-idx');\n",
       "    console.log('click', idx);\n",
       "    $(event.target).prop('disabled', true);\n",
       "    guesses.push({\n",
       "      idx: idx,\n",
       "      timestamp: +new Date()\n",
       "    });\n",
       "    $('#data-guesses').val(JSON.stringify(guesses));\n",
       "\n",
       "    if (idx === correctIdx) {\n",
       "      alert(\"Got it! You can submit the HIT now.\");\n",
       "    } else {\n",
       "      alert(\"Oops, try again!\");\n",
       "    }\n",
       "  });\n",
       "});\n",
       "</script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html2 = html\n",
    "for k, v in make_task(trial_data[2], np.random.RandomState(1234)).items():\n",
    "    html2 = html2.replace('${' + k + '}', str(v))\n",
    "HTML('<div style=\"height: 500px; position: relative;\">'+html2+'</div>')\n",
    "# print(html2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.Popen('pbcopy', stdin=subprocess.PIPE).communicate(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MTurk results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "5       True\n",
       "6       True\n",
       "7       True\n",
       "8       True\n",
       "9       True\n",
       "10      True\n",
       "11      True\n",
       "12      True\n",
       "13      True\n",
       "14      True\n",
       "15     False\n",
       "16      True\n",
       "17     False\n",
       "18      True\n",
       "19     False\n",
       "20     False\n",
       "21      True\n",
       "22      True\n",
       "23      True\n",
       "24      True\n",
       "25      True\n",
       "26     False\n",
       "27      True\n",
       "28      True\n",
       "29      True\n",
       "       ...  \n",
       "325     True\n",
       "326     True\n",
       "327     True\n",
       "328     True\n",
       "329     True\n",
       "330     True\n",
       "331     True\n",
       "332     True\n",
       "333     True\n",
       "334     True\n",
       "335     True\n",
       "336     True\n",
       "337     True\n",
       "338     True\n",
       "339     True\n",
       "340     True\n",
       "341     True\n",
       "342     True\n",
       "343     True\n",
       "344     True\n",
       "345     True\n",
       "346     True\n",
       "347     True\n",
       "348     True\n",
       "349     True\n",
       "350     True\n",
       "351     True\n",
       "352     True\n",
       "353    False\n",
       "354    False\n",
       "Name: is_correct, Length: 355, dtype: bool"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mturk_2afc_results['picked_id'] = mturk_2afc_results.apply(\n",
    "    lambda row: dict(optionA=row['Input.image_A_id'], optionB=row['Input.image_B_id'])[row['Answer.choice']], axis=1)\n",
    "mturk_2afc_results['is_correct'] = mturk_2afc_results['picked_id'] == mturk_2afc_results['Input.stimulus_id']\n",
    "mturk_2afc_results['is_correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_lookup = mturk_2afc_results.groupby('Input.caption').is_correct.mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a bath room with a white toilet and a white washbasin': 0.8,\n",
       " 'a bathroom has a white toilet and matching sink.': 1.0,\n",
       " 'a beige towel hangs over the rightmost shower door both of which are wet with water': 1.0,\n",
       " 'a black and white photo or a large man and a woman cutting thwir wedding cake': 1.0,\n",
       " 'a blonde man in a wetsuit surfs a wave.': 0.6,\n",
       " 'a bride and groom are both holding onto the same knife to cut their wedding cake.': 0.6,\n",
       " 'a bride and groom cutting their wedding cake, while a photographer guides them': 1.0,\n",
       " 'a brown trai  pulls into the tracka next to some colorful buildings': 1.0,\n",
       " 'a busy city street has sidewalks full of people and a bus and some cars.': 1.0,\n",
       " 'a busy city street with cars and people along the streets with high-rise buildings on both sides': 1.0,\n",
       " 'a busy city street with cars, a large red bus and pedestrians going about their day.': 1.0,\n",
       " 'a busy street in a historic town with a red bus driving on the street.': 1.0,\n",
       " 'a car is sitting on a table behind a wine glass with red wine in it.': 0.6,\n",
       " 'a cat sitting next to a glass bowl, looking up to the camera': 0.4,\n",
       " 'a clean bathroom with a white sink near a white toilet': 0.8,\n",
       " 'a double decker red bus drives down a crowded street with a car behind it.': 1.0,\n",
       " 'a family is flying kites on a beach together near a body of water.': 1.0,\n",
       " 'a glass of red wine sitting in fronf of a brown cat with brown stripes on a brown mat': 0.4,\n",
       " 'a glass shower door has a towel rack on it with a beige towel.': 1.0,\n",
       " 'a group of people flying kites on a beach and its a beautiful day': 0.2,\n",
       " 'a husband, bride and female all stand in front of a table holding a knife cutting a cake': 0.8,\n",
       " 'a male surfer riding on his surfboard in the ocean.': 0.2,\n",
       " 'a man flies a butterfly kite with his two daughters.': 1.0,\n",
       " 'a man helping his children fly a multicolor butterfly kite on a clear day': 0.8,\n",
       " 'a man with a tennis racket, white shirt and shoes holds his racket back in order to hit the ball': 0.8,\n",
       " 'a man with a white shirt and blue pants stands on a surfboard as the wave rises': 1.0,\n",
       " 'a newly wedded couple cutting there wedding cake with a lady helping the bride cut the cake': 0.8,\n",
       " 'a newly wedded couple is seen cutting the cake in black and white.': 1.0,\n",
       " 'a passenger train approaching a small quaint station with a blue and white building on the background': 1.0,\n",
       " 'a person is surfing on a wave in the ocean.': 0.6,\n",
       " 'a red double-decker bus passes a group of people to its lefg while a black car looks to pass': 0.8,\n",
       " 'a red trolley drives through a stree surrounded by plain brick buildings.': 1.0,\n",
       " 'a red two story city bus is driving in a european city with pedestrians all around': 0.8,\n",
       " 'a shower with dirty glass doors has a beige towel hanging on the outside': 1.0,\n",
       " 'a small bath with a shower with a blue mat on the floor': 1.0,\n",
       " 'a surfer in a white and black suit is leaning forward and riding a wave': 0.8,\n",
       " 'a surfer is riding a wave the water looks so refreshing its a beautiful day': 1.0,\n",
       " 'a surfer leans forward to ride a wave': 1.0,\n",
       " 'a surfer riding a wave on a sunny day': 0.8,\n",
       " 'a tabby cat sits on a table behind a glass of red wine': 0.6,\n",
       " 'a tabby cat standing behind a glass of wine stares at me': 0.6,\n",
       " 'a tan towel hangs in front of a glass shower': 1.0,\n",
       " 'a tennis player hits a ball during a game': 0.4,\n",
       " 'a tennis player is about to hit the tennis ball': 0.6,\n",
       " 'a tennis player is ready to hit the tennis ball across the court.': 1.0,\n",
       " 'a tennis player is trying hard to return the ball oronto is written in the grass': 0.8,\n",
       " 'a tennis player raises his arm to hit the ball with his racket.': 1.0,\n",
       " 'a tennis player uses his backhand to swing at a tennis ball on a green and blue court': 0.6,\n",
       " 'a toilet with the seat down and a roll of toilet paper on top is next to a white sink': 1.0,\n",
       " 'a train is approaching the station and passing in front of blue and white buildings': 1.0,\n",
       " 'a train is pulling into the train station.': 0.8,\n",
       " 'a train on the tracks passes a white house with blue paint before approaching another white house': 1.0,\n",
       " 'a train passes by a series of brightly blue and white station buildings': 1.0,\n",
       " 'a train sits beside some colorful buildings on a track.': 1.0,\n",
       " 'a train station with three building to the left it is a nice sunny day': 1.0,\n",
       " 'a tricolor cat is sitting in front of a partially full wine glass': 0.6,\n",
       " 'a woman in a wedding dress cuts a cake with her husband and the photographer.': 1.0,\n",
       " 'a wrapped roll of toilet paper sits on top of a toilet in front if a metal bar and next to a porcelain sink.': 0.8,\n",
       " 'a yellow cat with strips is setting on a place mat  on a table behind a half of glass of red wine': 1.0,\n",
       " 'brown cat is crouching in the background of a glass of wine': 0.2,\n",
       " 'brown towel is hanging on a sliding shower door': 1.0,\n",
       " 'colorful kites are flown above a sandy beach by two children and an adult': 1.0,\n",
       " 'i see a standing shower with two hazy sliding glass doors and a towel hanging off of one.': 1.0,\n",
       " 'its a public restroom with a white sink and toilet.': 1.0,\n",
       " 'kids at a beach flying colourful kites.': 0.6,\n",
       " 'man and two girls are flying butterfly kites on a very windy and cloudy day': 0.8,\n",
       " 'roger federer about to back hand a tennis ball in a tennis match.': 0.4,\n",
       " \"someome is using a shower but it's hard to see due to the opaque glass\": 1.0,\n",
       " 'toilet paper roll is on top of the toilet in a mellow yellow painted bathroom': 1.0,\n",
       " 'two children and one adult stand on the beach holding kites and flying them into the sky': 1.0,\n",
       " 'wedding photographer is guiding a bride and groom as to how they should cut their cake': 1.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 7 columns):\n",
      "block           71 non-null int64\n",
      "condition       71 non-null category\n",
      "idx_in_block    71 non-null int64\n",
      "participant     71 non-null category\n",
      "specificity     71 non-null float64\n",
      "stimulus        71 non-null int64\n",
      "text            71 non-null object\n",
      "dtypes: category(2), float64(1), int64(3), object(1)\n",
      "memory usage: 3.5+ KB\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame([dict(trial, specificity=specificity_lookup[trial['text'].strip()]) for trial in trial_data])\n",
    "for col in ['condition', 'participant']:\n",
    "    results[col] = results[col].astype('category')\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "general     0.891667\n",
       "norecs      0.808333\n",
       "specific    0.808696\n",
       "Name: specificity, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby('condition').specificity.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many images does this caption apply to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/kcarnold/Downloads/Submitted Captions - Sheet1.csv\").iloc[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>idx_in_block</th>\n",
       "      <th>condition</th>\n",
       "      <th>participant</th>\n",
       "      <th>text</th>\n",
       "      <th>number of images it applies to (1 min limit)</th>\n",
       "      <th>is_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>specific</td>\n",
       "      <td>2vvj5m</td>\n",
       "      <td>a plate with pancakes with bananas and bacon w...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>specific</td>\n",
       "      <td>2vvj5m</td>\n",
       "      <td>a red bird and green bird about to eat out of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>2vvj5m</td>\n",
       "      <td>a man is watching a field of sheep eat grass.</td>\n",
       "      <td>some</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>2vvj5m</td>\n",
       "      <td>a man is standing with a very large colorful k...</td>\n",
       "      <td>some</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>2vvj5m</td>\n",
       "      <td>a very large kitchen with a nice big island wi...</td>\n",
       "      <td>some</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>general</td>\n",
       "      <td>2vvj5m</td>\n",
       "      <td>a black cat with big green eyes with something...</td>\n",
       "      <td>a couple</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>2vvj5m</td>\n",
       "      <td>a small white and blue bird perched on a branc...</td>\n",
       "      <td>1 exact, a few close</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>2vvj5m</td>\n",
       "      <td>a young girl in a red top and black skirt play...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>norecs</td>\n",
       "      <td>2vvj5m</td>\n",
       "      <td>a yellow light hanging above a pedestrian cros...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>m2xcp6</td>\n",
       "      <td>breakfast that consists of pancakes banana bac...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>m2xcp6</td>\n",
       "      <td>tri colored bird eating fruits from a bowl</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>norecs</td>\n",
       "      <td>m2xcp6</td>\n",
       "      <td>flock of sheep grazing in an open field</td>\n",
       "      <td>many</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>specific</td>\n",
       "      <td>m2xcp6</td>\n",
       "      <td>man with kite with a bike and roller blader in...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>specific</td>\n",
       "      <td>m2xcp6</td>\n",
       "      <td>kitchen with marble counter tops and wooden ca...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>m2xcp6</td>\n",
       "      <td>black kitty with a red knitted scarf</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>m2xcp6</td>\n",
       "      <td>a bluejay perched on a tree looking right</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>m2xcp6</td>\n",
       "      <td>a girl wearing red and black clothes playing t...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>general</td>\n",
       "      <td>m2xcp6</td>\n",
       "      <td>a yellow pedestrian crossing sign sittting bel...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>9fmfm4</td>\n",
       "      <td>a plate has several pancakes stacked on it wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>9fmfm4</td>\n",
       "      <td>a red bird is perched on the edge of a bowl wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>general</td>\n",
       "      <td>9fmfm4</td>\n",
       "      <td>a green field has a small group of white sheep...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>specific</td>\n",
       "      <td>9fmfm4</td>\n",
       "      <td>a man is in a field holding a kite to the ground</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>specific</td>\n",
       "      <td>9fmfm4</td>\n",
       "      <td>the lights are on in a green kitchen with dark...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>9fmfm4</td>\n",
       "      <td>a black cat looks to the left</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>9fmfm4</td>\n",
       "      <td>a bluejay sits pensive atop a fir tree branch</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>9fmfm4</td>\n",
       "      <td>a girl reacts to a bouncing tennis ball while ...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>norecs</td>\n",
       "      <td>9fmfm4</td>\n",
       "      <td>a light signal turns yellow above a pedestrian...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>84364r</td>\n",
       "      <td>a breakfast medley of pancakes, blueberries, b...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>84364r</td>\n",
       "      <td>a red parrot eating apple cuts out of a blue bowl</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>general</td>\n",
       "      <td>84364r</td>\n",
       "      <td>. a lone sheep by itself in a green field with...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>84364r</td>\n",
       "      <td>a man in blue pants setting up a multi-colored...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>84364r</td>\n",
       "      <td>a green colored kitchen with a tiled floor. th...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>norecs</td>\n",
       "      <td>84364r</td>\n",
       "      <td>black cat staring at something with a red knit...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>specific</td>\n",
       "      <td>84364r</td>\n",
       "      <td>a blue jay looking to the left on a fir branch.</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>specific</td>\n",
       "      <td>84364r</td>\n",
       "      <td>a female tennis player with a red shirt about ...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>84364r</td>\n",
       "      <td>a crossing sign with a traffic light above it ...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>4p58r7</td>\n",
       "      <td>a plate is covered with pancakes, bacon, banan...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>4p58r7</td>\n",
       "      <td>a red and green bird sits on the edge of a bow...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>general</td>\n",
       "      <td>4p58r7</td>\n",
       "      <td>a herd of sheep graze in a grassy field</td>\n",
       "      <td>many</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>4p58r7</td>\n",
       "      <td>a man stands next to a large kite on a grass lawn</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>4p58r7</td>\n",
       "      <td>a kitchen has dark wood cabinets and stainless...</td>\n",
       "      <td>many</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>norecs</td>\n",
       "      <td>4p58r7</td>\n",
       "      <td>a blacn cat has a red scarf on its neck</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>specific</td>\n",
       "      <td>4p58r7</td>\n",
       "      <td>a blue and white bird sits on a tree branch</td>\n",
       "      <td>many</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>specific</td>\n",
       "      <td>4p58r7</td>\n",
       "      <td>a woman plays tennis on an outdoor tennis court\\n</td>\n",
       "      <td>many</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>4p58r7</td>\n",
       "      <td>a traffic light shines yellow above a pedestri...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    block  idx_in_block condition participant  \\\n",
       "0       0             0  specific      2vvj5m   \n",
       "1       0             1  specific      2vvj5m   \n",
       "2       0             2  specific      2vvj5m   \n",
       "3       1             0   general      2vvj5m   \n",
       "4       1             1   general      2vvj5m   \n",
       "5       1             2   general      2vvj5m   \n",
       "6       2             0    norecs      2vvj5m   \n",
       "7       2             1    norecs      2vvj5m   \n",
       "8       2             2    norecs      2vvj5m   \n",
       "18      0             0    norecs      m2xcp6   \n",
       "19      0             1    norecs      m2xcp6   \n",
       "20      0             2    norecs      m2xcp6   \n",
       "21      1             0  specific      m2xcp6   \n",
       "22      1             1  specific      m2xcp6   \n",
       "23      1             2  specific      m2xcp6   \n",
       "24      2             0   general      m2xcp6   \n",
       "25      2             1   general      m2xcp6   \n",
       "26      2             2   general      m2xcp6   \n",
       "27      0             0   general      9fmfm4   \n",
       "28      0             1   general      9fmfm4   \n",
       "29      0             2   general      9fmfm4   \n",
       "30      1             0  specific      9fmfm4   \n",
       "31      1             1  specific      9fmfm4   \n",
       "32      1             2  specific      9fmfm4   \n",
       "33      2             0    norecs      9fmfm4   \n",
       "34      2             1    norecs      9fmfm4   \n",
       "35      2             2    norecs      9fmfm4   \n",
       "36      0             0   general      84364r   \n",
       "37      0             1   general      84364r   \n",
       "38      0             2   general      84364r   \n",
       "39      1             0    norecs      84364r   \n",
       "40      1             1    norecs      84364r   \n",
       "41      1             2    norecs      84364r   \n",
       "42      2             0  specific      84364r   \n",
       "43      2             1  specific      84364r   \n",
       "44      2             2  specific      84364r   \n",
       "45      0             0   general      4p58r7   \n",
       "46      0             1   general      4p58r7   \n",
       "47      0             2   general      4p58r7   \n",
       "48      1             0    norecs      4p58r7   \n",
       "49      1             1    norecs      4p58r7   \n",
       "50      1             2    norecs      4p58r7   \n",
       "51      2             0  specific      4p58r7   \n",
       "52      2             1  specific      4p58r7   \n",
       "53      2             2  specific      4p58r7   \n",
       "\n",
       "                                                 text  \\\n",
       "0   a plate with pancakes with bananas and bacon w...   \n",
       "1   a red bird and green bird about to eat out of ...   \n",
       "2       a man is watching a field of sheep eat grass.   \n",
       "3   a man is standing with a very large colorful k...   \n",
       "4   a very large kitchen with a nice big island wi...   \n",
       "5   a black cat with big green eyes with something...   \n",
       "6   a small white and blue bird perched on a branc...   \n",
       "7   a young girl in a red top and black skirt play...   \n",
       "8   a yellow light hanging above a pedestrian cros...   \n",
       "18  breakfast that consists of pancakes banana bac...   \n",
       "19         tri colored bird eating fruits from a bowl   \n",
       "20            flock of sheep grazing in an open field   \n",
       "21  man with kite with a bike and roller blader in...   \n",
       "22  kitchen with marble counter tops and wooden ca...   \n",
       "23               black kitty with a red knitted scarf   \n",
       "24          a bluejay perched on a tree looking right   \n",
       "25  a girl wearing red and black clothes playing t...   \n",
       "26  a yellow pedestrian crossing sign sittting bel...   \n",
       "27  a plate has several pancakes stacked on it wit...   \n",
       "28  a red bird is perched on the edge of a bowl wi...   \n",
       "29  a green field has a small group of white sheep...   \n",
       "30   a man is in a field holding a kite to the ground   \n",
       "31  the lights are on in a green kitchen with dark...   \n",
       "32                      a black cat looks to the left   \n",
       "33      a bluejay sits pensive atop a fir tree branch   \n",
       "34  a girl reacts to a bouncing tennis ball while ...   \n",
       "35  a light signal turns yellow above a pedestrian...   \n",
       "36  a breakfast medley of pancakes, blueberries, b...   \n",
       "37  a red parrot eating apple cuts out of a blue bowl   \n",
       "38  . a lone sheep by itself in a green field with...   \n",
       "39  a man in blue pants setting up a multi-colored...   \n",
       "40  a green colored kitchen with a tiled floor. th...   \n",
       "41  black cat staring at something with a red knit...   \n",
       "42    a blue jay looking to the left on a fir branch.   \n",
       "43  a female tennis player with a red shirt about ...   \n",
       "44  a crossing sign with a traffic light above it ...   \n",
       "45  a plate is covered with pancakes, bacon, banan...   \n",
       "46  a red and green bird sits on the edge of a bow...   \n",
       "47            a herd of sheep graze in a grassy field   \n",
       "48  a man stands next to a large kite on a grass lawn   \n",
       "49  a kitchen has dark wood cabinets and stainless...   \n",
       "50            a blacn cat has a red scarf on its neck   \n",
       "51        a blue and white bird sits on a tree branch   \n",
       "52  a woman plays tennis on an outdoor tennis court\\n   \n",
       "53  a traffic light shines yellow above a pedestri...   \n",
       "\n",
       "   number of images it applies to (1 min limit)  is_unique  \n",
       "0                                             1       True  \n",
       "1                                             1       True  \n",
       "2                                          some      False  \n",
       "3                                          some      False  \n",
       "4                                          some      False  \n",
       "5                                      a couple      False  \n",
       "6                          1 exact, a few close      False  \n",
       "7                                             1       True  \n",
       "8                                             3      False  \n",
       "18                                            1       True  \n",
       "19                                            1       True  \n",
       "20                                         many      False  \n",
       "21                                            1       True  \n",
       "22                                            5      False  \n",
       "23                                            1       True  \n",
       "24                                            3      False  \n",
       "25                                            4      False  \n",
       "26                                            1       True  \n",
       "27                                            1       True  \n",
       "28                                            1       True  \n",
       "29                                            6      False  \n",
       "30                                            2      False  \n",
       "31                                            3      False  \n",
       "32                                            3      False  \n",
       "33                                            3      False  \n",
       "34                                            5      False  \n",
       "35                                            3      False  \n",
       "36                                            1       True  \n",
       "37                                            1       True  \n",
       "38                                            2      False  \n",
       "39                                            2      False  \n",
       "40                                            1       True  \n",
       "41                                            1       True  \n",
       "42                                            1       True  \n",
       "43                                            4      False  \n",
       "44                                            3      False  \n",
       "45                                            1       True  \n",
       "46                                            1       True  \n",
       "47                                         many      False  \n",
       "48                                            4      False  \n",
       "49                                         many      False  \n",
       "50                                            2      False  \n",
       "51                                         many      False  \n",
       "52                                         many      False  \n",
       "53                                            3      False  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna().copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37777777777777777"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_unique'] = (data.iloc[:,5] == '1')\n",
    "data.is_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "block  idx_in_block  condition\n",
       "0      0             general      1.0\n",
       "                     norecs       1.0\n",
       "                     specific     1.0\n",
       "       1             general      1.0\n",
       "                     norecs       1.0\n",
       "                     specific     1.0\n",
       "       2             general      0.0\n",
       "                     norecs       0.0\n",
       "                     specific     0.0\n",
       "1      0             general      0.0\n",
       "                     norecs       0.0\n",
       "                     specific     0.5\n",
       "       1             general      0.0\n",
       "                     norecs       0.5\n",
       "                     specific     0.0\n",
       "       2             general      0.0\n",
       "                     norecs       0.5\n",
       "                     specific     0.5\n",
       "2      0             general      0.0\n",
       "                     norecs       0.0\n",
       "                     specific     0.5\n",
       "       1             general      0.0\n",
       "                     norecs       0.5\n",
       "                     specific     0.0\n",
       "       2             general      1.0\n",
       "                     norecs       0.0\n",
       "                     specific     0.0\n",
       "Name: is_unique, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['block', 'idx_in_block', 'condition']).is_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['participant'] = data['participant'].astype('category')\n",
    "data['condition'] = data['condition'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "general     0.466667\n",
       "norecs      0.333333\n",
       "specific    0.333333\n",
       "Name: is_unique, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('condition').is_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analysis of Variance of Aligned Rank Transformed Data\n",
       "\n",
       "Table Type: Analysis of Deviance Table (Type III Wald F tests with Kenward-Roger df) \n",
       "Model: Mixed Effects (lmer)\n",
       "Response: art(is_unique)\n",
       "\n",
       "                  F Df Df.res Pr(>F)  \n",
       "1 condition 0.36019  2     38 0.6999  \n",
       "---\n",
       "Signif. codes:   0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i data\n",
    "transformed <- art(is_unique ~ condition + (1|participant), data=data)\n",
    "summary(transformed)\n",
    "anova(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a yellow pedestrian crossing sign sittting below a signal light that is yellow. '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = trial_data[-1]['text']\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concepts: traffic light. COCO doesn't have \"pedestian crossing sign\". There are 4330 images with traffic lights in them in COCO. That's way too much. Looking at Visual Genome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Genome synsets are potentially best, but they're sometimes inaccurate. e.g., \"18 wheeler\" is \"cyclist.n.01\". So let's consider an object a match if matches either the synset or object name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_base = pathlib.Path('/Data/VisualGenome')\n",
    "image_objects = json.load(open(vg_base / 'objects.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_by_id = {img['image_id']: img for img in image_objects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_synsets = json.load(open(vg_base / 'object_synsets.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_attributes = json.load(open(vg_base / 'attributes.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108077, 108077)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obj_attributes), len(image_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_id', 'attributes'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_attributes[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_by_img = {att['image_id']: att['attributes'] for att in obj_attributes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'attributes': ['yellow', 'ellow'],\n",
       "  'h': 247,\n",
       "  'names': ['stop light', 'traffic signal'],\n",
       "  'object_id': 1072926,\n",
       "  'synsets': ['light.n.01'],\n",
       "  'w': 102,\n",
       "  'x': 393,\n",
       "  'y': 1},\n",
       " {'h': 82,\n",
       "  'names': ['yellow light'],\n",
       "  'object_id': 1072927,\n",
       "  'synsets': ['light.n.01'],\n",
       "  'w': 89,\n",
       "  'x': 393,\n",
       "  'y': 81},\n",
       " {'attributes': ['yellow', 'warig', 'hagig', 'working', 'here'],\n",
       "  'h': 76,\n",
       "  'names': ['traffic light', 'light'],\n",
       "  'object_id': 1072928,\n",
       "  'synsets': ['traffic_light.n.01'],\n",
       "  'w': 89,\n",
       "  'x': 396,\n",
       "  'y': 84},\n",
       " {'attributes': ['gloomy blue', 'blue', 'cloudy'],\n",
       "  'h': 768,\n",
       "  'names': ['sky'],\n",
       "  'object_id': 1072929,\n",
       "  'synsets': ['sky.n.01'],\n",
       "  'w': 1020,\n",
       "  'x': 1,\n",
       "  'y': 0},\n",
       " {'attributes': ['here', 'horizontal'],\n",
       "  'h': 432,\n",
       "  'names': ['power lines', 'electric wires'],\n",
       "  'object_id': 1072930,\n",
       "  'synsets': ['power_line.n.01'],\n",
       "  'w': 1022,\n",
       "  'x': 1,\n",
       "  'y': 0},\n",
       " {'attributes': ['black bolt',\n",
       "   'yellow',\n",
       "   'ellow',\n",
       "   'diamod shaped',\n",
       "   'here',\n",
       "   'diamond shaped'],\n",
       "  'h': 683,\n",
       "  'names': ['sign', 'crossing sign'],\n",
       "  'object_id': 1072931,\n",
       "  'synsets': ['sign.n.02'],\n",
       "  'w': 469,\n",
       "  'x': 438,\n",
       "  'y': 46},\n",
       " {'attributes': ['here'],\n",
       "  'h': 349,\n",
       "  'names': ['stick figure ma', 'image of person', 'stick man symbol'],\n",
       "  'object_id': 1072932,\n",
       "  'synsets': ['image.n.01', 'person.n.01'],\n",
       "  'w': 157,\n",
       "  'x': 559,\n",
       "  'y': 154},\n",
       " {'attributes': ['bare', 'pointy', 'very tall'],\n",
       "  'h': 627,\n",
       "  'names': ['trees'],\n",
       "  'object_id': 1072933,\n",
       "  'synsets': ['tree.n.01'],\n",
       "  'w': 1017,\n",
       "  'x': 4,\n",
       "  'y': 140},\n",
       " {'attributes': ['hanging'],\n",
       "  'h': 255,\n",
       "  'names': ['street light'],\n",
       "  'object_id': 1072934,\n",
       "  'synsets': [],\n",
       "  'w': 104,\n",
       "  'x': 395,\n",
       "  'y': 2},\n",
       " {'h': 21,\n",
       "  'names': ['bolt'],\n",
       "  'object_id': 1072935,\n",
       "  'synsets': ['thunderbolt.n.01'],\n",
       "  'w': 23,\n",
       "  'x': 594,\n",
       "  'y': 123},\n",
       " {'attributes': ['ot lit'],\n",
       "  'h': 80,\n",
       "  'names': ['gree light'],\n",
       "  'object_id': 1072937,\n",
       "  'synsets': [],\n",
       "  'w': 85,\n",
       "  'x': 398,\n",
       "  'y': 160},\n",
       " {'attributes': ['ot lit'],\n",
       "  'h': 80,\n",
       "  'names': ['red light'],\n",
       "  'object_id': 1072938,\n",
       "  'synsets': ['light.n.01'],\n",
       "  'w': 83,\n",
       "  'x': 396,\n",
       "  'y': 8},\n",
       " {'attributes': ['here'],\n",
       "  'h': 54,\n",
       "  'names': ['drawig of head'],\n",
       "  'object_id': 1072939,\n",
       "  'synsets': ['head.n.01'],\n",
       "  'w': 39,\n",
       "  'x': 578,\n",
       "  'y': 153},\n",
       " {'h': 57,\n",
       "  'names': ['pole'],\n",
       "  'object_id': 1072940,\n",
       "  'synsets': ['pole.n.01'],\n",
       "  'w': 51,\n",
       "  'x': 632,\n",
       "  'y': 709},\n",
       " {'h': 200,\n",
       "  'names': ['lies'],\n",
       "  'object_id': 1072936,\n",
       "  'synsets': ['lie.n.01'],\n",
       "  'w': 301,\n",
       "  'x': 499,\n",
       "  'y': 376}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_by_img[61514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def has_object(obj_name):\n",
    "#     return {\n",
    "#         img['image_id'] for img in image_objects\n",
    "#         if any(obj_name in '\\n'.join(obj['names']) for obj in img['objects'])\n",
    "#            }\n",
    "def has_object(imgid, obj_name):\n",
    "    return any(obj_name in '\\n'.join(obj['names']) for obj in attributes_by_img[imgid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def has_synset(obj_synset):\n",
    "#     return {\n",
    "#         img['image_id'] for img in image_objects\n",
    "#         if any(obj_synset in obj['synsets'] for obj in img['objects'])}\n",
    "def has_synset(imgid, obj_synset):\n",
    "    return any(obj_synset in obj['synsets'] for obj in attributes_by_img[imgid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_obj_with_attr(imgid, obj_name, attr):\n",
    "    return any(\n",
    "        (obj_name in '\\n'.join(obj['names'])) and (attr in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])\n",
    "\n",
    "def has_synset_with_attr(imgid, obj_synset, attr):\n",
    "    return any(\n",
    "        (obj_synset in obj['synsets']) and (attr in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])\n",
    "\n",
    "def has_obj_without_attr(imgid, obj_name, attr):\n",
    "    return any(\n",
    "        (obj_name in '\\n'.join(obj['names'])) and (attr not in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])\n",
    "\n",
    "def has_synset_without_attr(imgid, obj_synset, attr):\n",
    "    return any(\n",
    "        (obj_synset in obj['synsets']) and (attr not in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sign.n.02'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_synsets['pedestrian sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# candidates = (\n",
    "#     (has_object('pedestrian sign') | has_object('pedestrian crossing sign') | has_object('crossing sign') | has_object('sign')) &\n",
    "#     (has_object('traffic light') | has_synset('traffic_light.n.01'))\n",
    "# )\n",
    "candidates = {\n",
    "    imgid for imgid in attributes_by_img.keys()\n",
    "    if (\n",
    "        (\n",
    "            has_object(imgid, 'pedestrian sign') |\n",
    "            has_object(imgid, 'pedestrian crossing sign') |\n",
    "            has_object(imgid, 'crossing sign') |\n",
    "            has_obj_with_attr(imgid, 'sign', 'yellow')\n",
    "        ) & (\n",
    "            has_obj_without_attr(imgid, 'traffic light', 'red') |\n",
    "            has_synset_without_attr(imgid, 'traffic_light.n.01', 'red')\n",
    "        ))}\n",
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2347014.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2325511.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2376712.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2336268.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2405905.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2378769.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2340882.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2371094.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2343958.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2341400.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2328088.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2375706.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2390043.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2329115.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2357789.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2412572.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2341920.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2398241.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2361377.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2357281.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2405412.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2342433.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2357287.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2397224.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2403370.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2395691.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2356269.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2316334.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/498227.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2381876.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2336820.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2417717.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/3129.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2374204.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2356796.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2360895.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2316863.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2347074.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2327106.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2354758.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2335814.jpg\">\n",
       "<img src=\"http://cs.stanford.edu/people/rak248/VG_100K_2/61514.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2373706.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2348108.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2416714.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2350160.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2373713.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2362449.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2325589.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2384471.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2399833.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2362457.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/3676.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2364508.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2351199.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2412639.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2380386.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/61546.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2371178.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2413163.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2367599.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/1650.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2380914.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2397300.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2413172.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2406518.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2381943.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2401912.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2351735.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2369146.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2406011.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2370684.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2340989.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2332790.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2358400.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2346117.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2385036.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2357901.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2392208.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2410129.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2358930.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2383509.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2413206.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2359450.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2345114.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2338460.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2405021.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2317981.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2334879.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2317469.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2406051.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2390184.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2320556.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2407085.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2321581.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2317489.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2371252.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2380475.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2341563.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2361533.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2358461.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2368191.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2327740.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2317503.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2412734.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2412740.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2368715.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2257.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/1593042.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2406101.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2394837.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2365145.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2343132.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2319586.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2321123.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2348263.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2415337.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2355948.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2368757.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2409724.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2321148.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2405631.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2343167.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2398466.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2398467.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2351881.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2327819.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2397453.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2316561.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2326802.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2320658.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/3348.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2373908.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2317081.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2317082.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2320669.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2367774.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2350878.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2378528.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2347806.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2368802.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2343199.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2417437.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/1593127.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2344.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2385703.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2360618.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2368812.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2389807.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2373428.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2416948.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/1592118.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2409274.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2357562.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2347325.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2378046.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2333504.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2361155.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2369350.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2363212.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2372429.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2353997.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2389328.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2350929.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2360658.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2344274.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2376532.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2342228.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2350423.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2364760.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2374490.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2316636.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2345821.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/864.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2323812.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2337127.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2357097.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2370922.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2373996.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2376046.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2390895.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2391408.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2409844.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2322292.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2395510.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2352503.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2333048.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2320244.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2317175.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2400636.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2316671.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2318722.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2335108.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2373003.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2349453.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2324368.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2355602.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2336660.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2336150.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2416022.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/2397081.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/1592219.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/1592731.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2373019.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2363294.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2329503.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2384288.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2319783.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2402728.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2321321.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2412455.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2346923.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2392492.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2365873.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2407863.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2369463.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2368440.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2318777.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/713659.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2338244.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2343365.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/150470.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/1483.jpg\">\n",
       "<img src=\"https://cs.stanford.edu/people/rak248/VG_100K_2/460.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2337741.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2404302.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2337228.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2411984.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2355665.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2365398.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2362839.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2405342.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/1508.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2389478.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2376680.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2401770.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2359275.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2413037.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2371571.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2407924.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2372596.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2411510.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2353653.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2374651.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2386430.jpg\">\n",
       "<img src=\"http://crowdfile.blob.core.chinacloudapi.cn/4615/2322431.jpg\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_images(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61514, 2361514]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[img['image_id'] for img in image_objects if '61514' in img.get('image_url', '')]\n",
    "#Image(img_by_id[61514]['image_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 61514,\n",
       " 'image_url': 'http://cs.stanford.edu/people/rak248/VG_100K_2/61514.jpg',\n",
       " 'objects': [{'h': 21,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['bolt'],\n",
       "   'object_id': 1072935,\n",
       "   'synsets': ['thunderbolt.n.01'],\n",
       "   'w': 42,\n",
       "   'x': 595,\n",
       "   'y': 123},\n",
       "  {'h': 54,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['drawig of head'],\n",
       "   'object_id': 1072939,\n",
       "   'synsets': ['head.n.01'],\n",
       "   'w': 37,\n",
       "   'x': 577,\n",
       "   'y': 152},\n",
       "  {'h': 76,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['gree light'],\n",
       "   'object_id': 1072937,\n",
       "   'synsets': [],\n",
       "   'w': 91,\n",
       "   'x': 397,\n",
       "   'y': 160},\n",
       "  {'h': 206,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['lies'],\n",
       "   'object_id': 1072936,\n",
       "   'synsets': ['lie.n.01'],\n",
       "   'w': 304,\n",
       "   'x': 493,\n",
       "   'y': 376},\n",
       "  {'h': 56,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['pole'],\n",
       "   'object_id': 1072940,\n",
       "   'synsets': ['pole.n.01'],\n",
       "   'w': 59,\n",
       "   'x': 631,\n",
       "   'y': 714},\n",
       "  {'h': 432,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['power lines'],\n",
       "   'object_id': 1072930,\n",
       "   'synsets': ['power_line.n.01'],\n",
       "   'w': 1022,\n",
       "   'x': 2,\n",
       "   'y': 0},\n",
       "  {'h': 81,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['red light'],\n",
       "   'object_id': 1072938,\n",
       "   'synsets': ['light.n.01'],\n",
       "   'w': 102,\n",
       "   'x': 388,\n",
       "   'y': 8},\n",
       "  {'h': 682,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['sign'],\n",
       "   'object_id': 1072931,\n",
       "   'synsets': ['sign.n.02'],\n",
       "   'w': 475,\n",
       "   'x': 437,\n",
       "   'y': 46},\n",
       "  {'h': 770,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['sky'],\n",
       "   'object_id': 1072929,\n",
       "   'synsets': ['sky.n.01'],\n",
       "   'w': 1019,\n",
       "   'x': 2,\n",
       "   'y': 0},\n",
       "  {'h': 358,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['stick figure ma'],\n",
       "   'object_id': 1072932,\n",
       "   'synsets': ['image.n.01', 'person.n.01'],\n",
       "   'w': 155,\n",
       "   'x': 558,\n",
       "   'y': 155},\n",
       "  {'h': 243,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['stop light'],\n",
       "   'object_id': 1072926,\n",
       "   'synsets': ['light.n.01'],\n",
       "   'w': 104,\n",
       "   'x': 393,\n",
       "   'y': 4},\n",
       "  {'h': 86,\n",
       "   'merged_object_ids': [1072927],\n",
       "   'names': ['traffic light'],\n",
       "   'object_id': 1072928,\n",
       "   'synsets': ['traffic_light.n.01'],\n",
       "   'w': 101,\n",
       "   'x': 392,\n",
       "   'y': 80},\n",
       "  {'h': 626,\n",
       "   'merged_object_ids': [],\n",
       "   'names': ['trees'],\n",
       "   'object_id': 1072933,\n",
       "   'synsets': ['tree.n.01'],\n",
       "   'w': 1021,\n",
       "   'x': 0,\n",
       "   'y': 140}]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_by_id[61514]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use paired comparisons to analyze specificity and accuracy. For a target image $x$ and a fixed set of imposter images $Y$, the **specific accuracy** of a caption is the fraction of comparisons that chose $x$. \n",
    "\n",
    "We start with our dataset of paired comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [\n",
    "    \"exactly how are both the dog and the person going to fit on that skateboard?\",\n",
    "    \"the dark haired dog is trying to ride on the skateboard.\",\n",
    "    \"a person in shorts and a black dog both have one foot on a skateboard.\",\n",
    "    \"a dog with a black head and black legs and ears standing up has one black paw on a black skateboard with white wheels and a guy with black and white shoes and white socks has one foot on the skateboard also and there are bikes and other people in the background\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a dog with a black head and black legs and ears standing up has one black paw on a black skateboard with white wheels and a guy with black and white shoes and white socks has one foot on the skateboard also and there are bikes and other people in the background': ['dog-and-guy-on-skateboard',\n",
       "  'just-dog-on-skateboard',\n",
       "  'guy-on-skateboard-holding-dog',\n",
       "  'dog-and-guy-next-to-skateboard'],\n",
       " 'a person in shorts and a black dog both have one foot on a skateboard.': ['dog-and-guy-on-skateboard'],\n",
       " 'exactly how are both the dog and the person going to fit on that skateboard?': ['dog-and-guy-on-skateboard',\n",
       "  'dog-and-guy-next-to-skateboard'],\n",
       " 'the dark haired dog is trying to ride on the skateboard.': ['just-dog-on-skateboard']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternatives = 'dog-and-guy-on-skateboard just-dog-on-skateboard guy-on-skateboard-holding-dog dog-and-guy-next-to-skateboard'.split()\n",
    "target = alternatives[0]\n",
    "imposters = alternatives[1:]\n",
    "applies_to = [\n",
    "    'dog-and-guy-on-skateboard dog-and-guy-next-to-skateboard'.split(),\n",
    "    'just-dog-on-skateboard'.split(),\n",
    "    'dog-and-guy-on-skateboard'.split(),\n",
    "    'dog-and-guy-on-skateboard just-dog-on-skateboard guy-on-skateboard-holding-dog dog-and-guy-next-to-skateboard'.split()\n",
    "]\n",
    "applies_to = {cap: tgts for cap, tgts in zip(captions, applies_to)}\n",
    "applies_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dog-and-guy-on-skateboard', 'just-dog-on-skateboard'],\n",
       " ['dog-and-guy-on-skateboard', 'guy-on-skateboard-holding-dog'],\n",
       " ['dog-and-guy-next-to-skateboard', 'dog-and-guy-on-skateboard']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "pairs = [[target, imposter] for imposter in imposters]\n",
    "for pair in pairs:\n",
    "    random.shuffle(pair)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fake_answer_pairs_for_caption(applies, pairs):\n",
    "    outcomes = []\n",
    "    for a, b in pairs:\n",
    "        choices = []\n",
    "        if a in applies:\n",
    "            choices.append(0)\n",
    "        if b in applies:\n",
    "            choices.append(1)\n",
    "        if len(choices) == 0:\n",
    "            choices = [0, 1]\n",
    "        outcomes.append(random.choice(choices))\n",
    "    return outcomes\n",
    "fake_answer_pairs_for_caption(applies_to[captions[0]], pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_comparisons_data = []\n",
    "for caption in captions:\n",
    "    for annotator in range(5):\n",
    "        for pair, outcome in zip(pairs, fake_answer_pairs_for_caption(applies_to[caption], pairs)):\n",
    "            picked = pair[outcome]\n",
    "            fake_comparisons_data.append(dict(\n",
    "                caption=caption,\n",
    "                annotator=annotator,\n",
    "                pair=pair,\n",
    "                picked=picked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(fake_comparisons_data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caption\n",
       "a dog with a black head and black legs and ears standing up has one black paw on a black skateboard with white wheels and a guy with black and white shoes and white socks has one foot on the skateboard also and there are bikes and other people in the background    0.266667\n",
       "the dark haired dog is trying to ride on the skateboard.                                                                                                                                                                                                                 0.466667\n",
       "exactly how are both the dog and the person going to fit on that skateboard?                                                                                                                                                                                             0.800000\n",
       "a person in shorts and a black dog both have one foot on a skateboard.                                                                                                                                                                                                   1.000000\n",
       "Name: picked_correct, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['picked_correct'] = data['picked'] == 'dog-and-guy-on-skateboard'\n",
    "data.groupby('caption').picked_correct.mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a main effect of writing condition on outcome specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "    dict(participant_id=participant_id, condition=condition)\n",
    "    for participant_id in 'abc def ghi'.split() for condition in 'general specific norecs'.split()\n",
    "])\n",
    "results['participant_id'] = results['participant_id'].astype('category')\n",
    "results['condition'] = results['condition'].astype('category')\n",
    "results['specificity'] = np.random.randn(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#install.packages(\"ARTool\")\n",
    "library(ARTool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     block          condition   idx_in_block     participant  specificity    \n",
       " Min.   :0.000   general :24   Min.   :0.0000   36x2r3 : 9   Min.   :0.2000  \n",
       " 1st Qu.:0.000   norecs  :24   1st Qu.:0.0000   3vf5fg : 9   1st Qu.:0.7750  \n",
       " Median :1.000   specific:23   Median :1.0000   692c8j : 9   Median :1.0000  \n",
       " Mean   :1.014                 Mean   :0.9859   77j4mf : 9   Mean   :0.8359  \n",
       " 3rd Qu.:2.000                 3rd Qu.:2.0000   gg65g6 : 9   3rd Qu.:1.0000  \n",
       " Max.   :2.000                 Max.   :2.0000   jvccx2 : 9   Max.   :1.0000  \n",
       "                                                (Other):17                   \n",
       "    stimulus          text          \n",
       " Min.   : 71815   Length:71         \n",
       " 1st Qu.:223777   Class :character  \n",
       " Median :240275   Mode  :character  \n",
       " Mean   :254672                     \n",
       " 3rd Qu.:275449                     \n",
       " Max.   :431140                     \n",
       "                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i results\n",
    "summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analysis of Variance of Aligned Rank Transformed Data\n",
       "\n",
       "Table Type: Analysis of Deviance Table (Type III Wald F tests with Kenward-Roger df) \n",
       "Model: Mixed Effects (lmer)\n",
       "Response: art(specificity)\n",
       "\n",
       "                  F Df Df.res  Pr(>F)  \n",
       "1 condition 0.90884  2 61.179 0.40836  \n",
       "---\n",
       "Signif. codes:   0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i results\n",
    "transformed <- art(specificity ~ condition + (1|participant), data=results)\n",
    "summary(transformed)\n",
    "anova(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

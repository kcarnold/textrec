{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis pipeline for Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/code/textrec\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/textrec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import toolz\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<module 'textrec.analysis_util' from '/Users/kcarnold/code/textrec/src/textrec/analysis_util.py'>,\n",
       " <module 'textrec.util' from '/Users/kcarnold/code/textrec/src/textrec/util.py'>,\n",
       " <module 'textrec.notebook_util' from '/Users/kcarnold/code/textrec/src/textrec/notebook_util.py'>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textrec.paths import paths\n",
    "from textrec import analysis_util, util, notebook_util\n",
    "reload(analysis_util), reload(util), reload(notebook_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrec.notebook_util import images, id2img, id2url, show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>val/184613</div><img src=\"http://images.cocodataset.org/train2017/000000184613.jpg\"><div>A child holding a flowered umbrella and petting a yak.</div>\n",
       "<div>A young man holding an umbrella next to a herd of cattle.</div>\n",
       "<div>a young boy barefoot holding an umbrella touching the horn of a cow</div>\n",
       "<div>A young boy with an umbrella who is touching the horn of a cow.</div>\n",
       "<div>A boy holding an umbrella while standing next to livestock.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(show_images([images_by_split['val'][0]['cocoid']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of writing experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -m textrec.batch_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = get_participants_by_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2018-04-09', '2018-04-24', '2018-04-27', '2018-05-02-invalid', '2018-05-02-old', '2018-05-02'])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(participants['2018-05-02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "h52x67\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:specific:a cat sitting next to a glass bowl, looking up to the camera\n",
      "final-0-1:specific:a shower with dirty glass doors has a beige towel hanging on the outside\n",
      "final-0-2:specific:there is no image here \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a bride and groom cutting their wedding cake, while a photographer guides them\n",
      "final-1-1:norecs:a man helping his children fly a multicolor butterfly kite on a clear day\n",
      "final-1-2:norecs:a passenger train approaching a small quaint station with a blue and white building on the background\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a busy street in a historic town with a red bus driving on the street. \n",
      "final-2-1:general:a tennis player hits a ball during a game \n",
      "final-2-2:general:a surfer riding a wave on a sunny day \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: There was no image in he third task.\n",
      "postTask-0-other: The keyboard seemed to have the words I wanted already there, on many of them all I had to do was touch the word.\n",
      "postTask-1-techDiff: None.\n",
      "postTask-1-other: It was a little more challenging this time, because there were no predicted words. Also I had to be extra careful with spelling!\n",
      "postTask-2-techDiff: No.\n",
      "postTask-2-other: This also had predicted words, but somehow I had a harder time coming up with good descriptions. The photos seemed too generic for some reason.\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 41\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: Just the fact that the third photo in keyboard 1 never loaded.\n",
      "postExp-other: It was fun! Just feel a little unsure that I will be penalized for not writing a caption for the third photo on keyboard 1. I hope that was OK. Thank you!\n",
      "\n",
      "Total time: 47.0m\n",
      "ExperimentScreen: 2094.0\n",
      "PostTaskSurvey: 276.4\n",
      "PostExpSurvey: 156.4\n",
      "Instructions: 127.3\n",
      "TaskDescription: 72.3\n",
      "Welcome: 34.8\n",
      "StudyDesc: 31.9\n",
      "IntroSurvey: 15.5\n",
      "PostPractice: 9.9\n",
      "\n",
      "jvccx2\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a yellow cat with strips is setting on a place mat  on a table behind a half of glass of red wine\n",
      "final-0-1:general:a small bath with a shower with a blue mat on the floor\n",
      "final-0-2:general:a bath room with a white toilet and a white washbasin \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a newly wedded couple cutting there wedding cake with a lady helping the bride cut the cake\n",
      "final-1-1:norecs:a group of people flying kites on a beach and its a beautiful day\n",
      "final-1-2:norecs:a train station with three building to the left it is a nice sunny day\n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a busy city street with cars and people along the streets with high-rise buildings on both sides\n",
      "final-2-1:specific:a tennis player is trying hard to return the ball oronto is written in the grass\n",
      "final-2-2:specific:a surfer is riding a wave the water looks so refreshing its a beautiful day \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None\n",
      "postTask-0-other: Fun study\n",
      "postTask-1-techDiff: None\n",
      "postTask-1-other: The key board was difficult\n",
      "postTask-2-techDiff: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 36\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: None\n",
      "postExp-other: Use  my data\n",
      "\n",
      "Total time: 34.9m\n",
      "ExperimentScreen: 1478.8\n",
      "PostTaskSurvey: 274.4\n",
      "PostExpSurvey: 125.0\n",
      "TaskDescription: 70.6\n",
      "PostPractice: 38.5\n",
      "Welcome: 36.4\n",
      "IntroSurvey: 27.0\n",
      "StudyDesc: 25.1\n",
      "Instructions: 16.6\n",
      "\n",
      "36x2r3\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a tricolor cat is sitting in front of a partially full wine glass\n",
      "final-0-1:norecs:someome is using a shower but it's hard to see due to the opaque glass\n",
      "final-0-2:norecs:a clean bathroom with a white sink near a white toilet\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:specific:a black and white photo or a large man and a woman cutting thwir wedding cake\n",
      "final-1-1:specific:colorful kites are flown above a sandy beach by two children and an adult\n",
      "final-1-2:specific:a brown trai  pulls into the tracka next to some colorful buildings\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red trolley drives through a stree surrounded by plain brick buildings. \n",
      "final-2-1:general:a tennis player is ready to hit the tennis ball across the court. \n",
      "final-2-2:general:a surfer leans forward to ride a wave\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-0-other: None\n",
      "postTask-1-techDiff: None\n",
      "postTask-1-other: None\n",
      "postTask-2-techDiff: None\n",
      "postTask-2-other: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 24\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: Mone\n",
      "postExp-other: None\n",
      "\n",
      "Total time: 10.2m\n",
      "ExperimentScreen: 332.4\n",
      "PostTaskSurvey: 92.8\n",
      "TaskDescription: 75.7\n",
      "PostExpSurvey: 46.4\n",
      "Welcome: 26.7\n",
      "StudyDesc: 16.6\n",
      "IntroSurvey: 11.9\n",
      "Instructions: 6.1\n",
      "PostPractice: 3.6\n",
      "\n",
      "gg65g6\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a car is sitting on a table behind a wine glass with red wine in it. \n",
      "final-0-1:general:i see a standing shower with two hazy sliding glass doors and a towel hanging off of one. \n",
      "final-0-2:general:its a public restroom with a white sink and toilet. \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a bride and groom are both holding onto the same knife to cut their wedding cake. \n",
      "final-1-1:norecs:kids at a beach flying colourful kites. \n",
      "final-1-2:norecs:a train is pulling into the train station. \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a busy city street with cars, a large red bus and pedestrians going about their day. \n",
      "final-2-1:specific:roger federer about to back hand a tennis ball in a tennis match. \n",
      "final-2-2:specific:a male surfer riding on his surfboard in the ocean. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None.\n",
      "postTask-1-techDiff: None.\n",
      "postTask-2-techDiff: None.\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 26\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: None.\n",
      "postExp-other: No problems, hit was fine. Really liked the third board, it was the best one by far.\n",
      "\n",
      "Total time: 17.9m\n",
      "ExperimentScreen: 623.5\n",
      "PostTaskSurvey: 179.3\n",
      "PostExpSurvey: 117.0\n",
      "TaskDescription: 63.2\n",
      "Welcome: 31.6\n",
      "StudyDesc: 25.8\n",
      "IntroSurvey: 22.0\n",
      "PostPractice: 8.2\n",
      "Instructions: 3.9\n",
      "\n",
      "692c8j\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a tabby cat standing behind a glass of wine stares at me\n",
      "final-0-1:norecs:a tan towel hangs in front of a glass shower\n",
      "final-0-2:norecs:a wrapped roll of toilet paper sits on top of a toilet in front if a metal bar and next to a porcelain sink. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a woman in a wedding dress cuts a cake with her husband and the photographer. \n",
      "final-1-1:general:a man flies a butterfly kite with his two daughters. \n",
      "final-1-2:general:a train is approaching the station and passing in front of blue and white buildings \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a double decker red bus drives down a crowded street with a car behind it. \n",
      "final-2-1:specific:a tennis player uses his backhand to swing at a tennis ball on a green and blue court \n",
      "final-2-2:specific:a blonde man in a wetsuit surfs a wave. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: No\n",
      "postTask-2-techDiff: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 27\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No \n",
      "\n",
      "Total time: 24.7m\n",
      "ExperimentScreen: 1063.2\n",
      "PostTaskSurvey: 185.6\n",
      "StudyDesc: 54.5\n",
      "Welcome: 51.7\n",
      "TaskDescription: 50.0\n",
      "PostExpSurvey: 47.3\n",
      "IntroSurvey: 17.5\n",
      "PostPractice: 8.2\n",
      "Instructions: 6.4\n",
      "\n",
      "qmwvwv\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:brown cat is crouching in the background of a glass of wine\n",
      "final-0-1:specific:brown towel is hanging on a sliding shower door\n",
      "final-0-2:specific:toilet paper roll is on top of the toilet in a mellow yellow painted bathroom \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:wedding photographer is guiding a bride and groom as to how they should cut their cake\n",
      "final-1-1:norecs:man and two girls are flying butterfly kites on a very windy and cloudy day\n",
      "final-1-2:norecs:a train passes by a series of brightly blue and white station buildings\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red two story city bus is driving in a european city with pedestrians all around \n",
      "final-2-1:general:a tennis player is about to hit the tennis ball \n",
      "final-2-2:general:a surfer in a white and black suit is leaning forward and riding a wave \n",
      "\n",
      "intro-use_predictive: No\n",
      "postTask-0-techDiff: None\n",
      "postTask-1-techDiff: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 30\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "\n",
      "Total time: 13.6m\n",
      "ExperimentScreen: 550.7\n",
      "PostTaskSurvey: 112.8\n",
      "PostExpSurvey: 48.3\n",
      "TaskDescription: 41.2\n",
      "StudyDesc: 18.9\n",
      "IntroSurvey: 17.6\n",
      "Welcome: 12.1\n",
      "PostPractice: 10.6\n",
      "Instructions: 3.9\n",
      "\n",
      "77j4mf\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a glass of red wine sitting in fronf of a brown cat with brown stripes on a brown mat\n",
      "final-0-1:norecs:a beige towel hangs over the rightmost shower door both of which are wet with water\n",
      "final-0-2:norecs:a toilet with the seat down and a roll of toilet paper on top is next to a white sink\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:specific:a husband, bride and female all stand in front of a table holding a knife cutting a cake\n",
      "final-1-1:specific:two children and one adult stand on the beach holding kites and flying them into the sky \n",
      "final-1-2:specific:a train on the tracks passes a white house with blue paint before approaching another white house\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red double-decker bus passes a group of people to its lefg while a black car looks to pass\n",
      "final-2-1:general:a man with a tennis racket, white shirt and shoes holds his racket back in order to hit the ball\n",
      "final-2-2:general:a man with a white shirt and blue pants stands on a surfboard as the wave rises\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-other: Annoying \n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 23\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-other: This was very annoying\n",
      "\n",
      "Total time: 13.2m\n",
      "ExperimentScreen: 490.0\n",
      "PostTaskSurvey: 168.1\n",
      "Welcome: 43.3\n",
      "PostExpSurvey: 41.7\n",
      "TaskDescription: 24.0\n",
      "IntroSurvey: 11.3\n",
      "StudyDesc: 9.8\n",
      "PostPractice: 3.5\n",
      "Instructions: 3.3\n",
      "\n",
      "4ggxj8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a gray and beige cat looks upward as a half full glass of wine can be seen in the foreground\n",
      "final-0-1:norecs:a closed shower door with crackled glass encases some hanging colored toiletries\n",
      "final-0-2:norecs:a white bathroom sink and toilet with a mirror and a roll of unopened toilet paper\n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a man in a tuxexo and a woman in a gown are show how to cut their wedding cake by a woman holding a camera \n",
      "final-1-1:general:a man in a red shirt and two children stand on the beach and fly kites\n",
      "final-1-2:general:an old train runs on the tracks in front of powder blue and white buildings\n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a gorgeous european city with tall gothic buildings and a red trolley on the street between them. at \n",
      "final-2-1:specific:a male tennis player in a pink shirt prepares to return a volley in toronto\n",
      "final-2-2:specific:a surfer in a full bodysuit rides a wave expertly \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-0-other: This is an outstanding HIT!\n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: I like the auto fill as it helps boost speed\n",
      "postTask-2-techDiff: No\n",
      "postTask-2-other: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 43\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "postExp-other: It went well but my initial survey responses might not be in complete alignment with my final responses on this page.  That's because seeing my captions on this page gave me a better perspective with the benefit of hindsight.  Thanks for the HIT!  I did my best and hope the data is useful!\n",
      "\n",
      "Total time: 25.7m\n",
      "ExperimentScreen: 906.9\n",
      "PostExpSurvey: 290.3\n",
      "PostTaskSurvey: 181.2\n",
      "TaskDescription: 77.7\n",
      "Welcome: 28.9\n",
      "IntroSurvey: 22.0\n",
      "StudyDesc: 21.9\n",
      "PostPractice: 6.0\n",
      "Instructions: 5.5\n",
      "\n",
      "5c39rx\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:an orange cat is laying near a wine glass with red wine\n",
      "final-0-1:specific:a rusty and dirty shower in the bathroom has a tan towel over its handle\n",
      "final-0-2:specific:there is a roll of toilet paper on the lid of the toilet in a small bathroom \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a photographer is helping the bride and groom cut the cake \n",
      "final-1-1:general:a man in a red shirt is helping his children fly a large rainbow-colored kite \n",
      "final-1-2:general:an old fashioned train is coming into the station \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a red double-decker bus is coming down the street\n",
      "final-2-1:norecs:a tennis player in a white shirt and tan shorts is about to hit back the tennis ball\n",
      "final-2-2:norecs:a surfer in a white and blue wetsuit is riding the waves\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-2-techDiff: No issues\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 29\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "\n",
      "Total time: 16.6m\n",
      "ExperimentScreen: 560.4\n",
      "PostTaskSurvey: 140.0\n",
      "Welcome: 93.3\n",
      "TaskDescription: 82.2\n",
      "PostExpSurvey: 65.9\n",
      "StudyDesc: 24.9\n",
      "IntroSurvey: 17.0\n",
      "PostPractice: 9.2\n",
      "Instructions: 5.2\n",
      "\n",
      "fvwhpc\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a cat looks up from behind a glass of red wine \n",
      "final-0-1:general:a sliding glass shower door with a bath mat hanging on it \n",
      "final-0-2:general:a view of a bathroom looking toward the toilet from behind the sink \n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a black and white picture of a bride and groom cutting their wedding cake with a photographer helping them pose \n",
      "final-1-1:specific:six kites flying in a blue sky above a field \n",
      "final-1-2:specific:a train passing a few small buildings, perhaps the station \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a red double-decker bus and car on a street running between old, ornate buildings\n",
      "final-2-1:norecs:a tennis player about to hit a tennis ball with a backhand\n",
      "final-2-2:norecs:a surfer in a wetsuit riding a fairly small wave\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: Nope\n",
      "postTask-0-other: Not yet\n",
      "postTask-1-techDiff: Nope\n",
      "postTask-1-other: Nope\n",
      "postTask-2-techDiff: Nope\n",
      "postTask-2-other: Not yet\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 41\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: Nope\n",
      "postExp-other: Can I type this one on the computer? One: I love the fact that after going to this page straight from the HIT on my computer, the page stayed synced when I went to it from my phone. There are some HITs I've done that could really benefit from that little nicety. Two: I feel like the suggestions really tend toward making me lazy, to some small extent. Having to type it all, you have to think about what to say, whereas faced with suggested options, you might say to yourself \"Yeah, that'll do.\" Three: I didn't notice much of a difference between the first two keyboards, honestly. \n",
      "\n",
      "Total time: 23.9m\n",
      "ExperimentScreen: 730.5\n",
      "PostExpSurvey: 323.3\n",
      "PostTaskSurvey: 191.3\n",
      "Welcome: 104.4\n",
      "TaskDescription: 36.0\n",
      "IntroSurvey: 18.1\n",
      "StudyDesc: 15.1\n",
      "PostPractice: 7.1\n",
      "Instructions: 5.3\n",
      "\n",
      "26w4jv\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:a cat sitting on top of the table next to a wine glass \n",
      "final-0-1:specific:a shower with a towel hanging on the handle of the door \n",
      "final-0-2:specific:a bathroom with a toilet and sink and with a roll of toilet paper on the toilet \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a man and woman getting assistance cutting their wedding cake \n",
      "final-1-1:general:a man assisting children with flying kites \n",
      "final-1-2:general:a train is traveling on the tracks through a marketplace \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a red city bus heading  down the street\n",
      "final-2-1:norecs:a man with a tennis rackett forcefully swinging at the tennis ball\n",
      "final-2-2:norecs:a man-woman gracefully riding a wave using a surfboard. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None\n",
      "postTask-0-other: None\n",
      "postTask-1-techDiff: None\n",
      "postTask-1-other: None\n",
      "postTask-2-techDiff: None\n",
      "postTask-2-other: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 37\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: None\n",
      "postExp-other: No, I really enjoyed this task ☺️\n",
      "\n",
      "Total time: 24.7m\n",
      "ExperimentScreen: 781.6\n",
      "PostTaskSurvey: 188.0\n",
      "Welcome: 156.7\n",
      "PostExpSurvey: 154.4\n",
      "TaskDescription: 88.2\n",
      "IntroSurvey: 46.4\n",
      "StudyDesc: 40.7\n",
      "PostPractice: 13.9\n",
      "Instructions: 12.7\n",
      "\n",
      "7g8xw8\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:general:a curious orange and black cat with yellow eyes is crouched on a tan sisal rug and is partly obstructed by a half full glass of red wine \n",
      "final-0-1:general:a tan towel is hanging from a chrome handle on a textured glass shower door\n",
      "final-0-2:general:in a drab yellow bathroom is a very clinical white sink with an unadorned mirror above and adjacent white toilet with a roll of toilet paper on top\n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a woman in a bridal gown stands next to a man in a tuxedo in front of a weding cake while a photographer explains how to position her hand for a photi\n",
      "final-1-1:norecs:a man in a red shirt with two children are on a beach holding a multi-colored kite while other people fly kites in the background\n",
      "final-1-2:norecs:an old train is stopped on the train tracks in front of a lovely cape cod cottage with bright blue trim and adjacent matching cottages\n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a red double decker bus is traveling down a busy european street lined with historic buildings and people on the sidewalks. \n",
      "final-2-1:specific:a tennis player is swinging his racket on a green tennis court with writing on the grass. \n",
      "final-2-2:specific:a blonde surfer in a black and white wetsuit is riding a large wave in the water. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-0-other: Was a good experience \n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: This was absolutely horrible \n",
      "postTask-2-techDiff: No\n",
      "postTask-2-other: Way better than the last one \n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 39\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "postExp-other: Everything was great. First and third were pretty equal. Second was awful.\n",
      "\n",
      "Total time: 33.7m\n",
      "ExperimentScreen: 1206.6\n",
      "Welcome: 417.2\n",
      "PostTaskSurvey: 158.6\n",
      "PostExpSurvey: 137.5\n",
      "TaskDescription: 52.0\n",
      "StudyDesc: 20.5\n",
      "IntroSurvey: 15.9\n",
      "PostPractice: 7.3\n",
      "Instructions: 4.5\n",
      "\n",
      "533r6c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a  brownish-orange cat with yellow eyes is look to his left past a glass of red wine  \n",
      "final-0-1:general:a person is taking a shower in a shower with very opaque sliding doors  \n",
      "final-0-2:general:a bathroom with one white sink and a white toilet with a toilet paper roll on the back lid sits next to the sink which has a mirror above it which shows the exact same toilet across the room \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a obvious dressed bride and groom at a wedding reception are cutting into their wedding cake with the help of the photographer whose hand is guiding theirs\n",
      "final-1-1:norecs:a man and his two children are flying multicolored kites on a sandy beach \n",
      "final-1-2:norecs:a brown colored train is parked at an outdoor train station with three blue and white buildings\n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a city view of a busy london street filled with a black car and a red double decker bus driving on the street. many people fill the sidewalk mostly the right side\n",
      "final-2-1:specific:a male tennis player is on a tennis court with the letters toronto on the mat. the man is swinging his red racket at a yellow tennis ball\n",
      "final-2-2:specific:a male surfer in a white shirt black sleeves and black pants is surfing waves on a white surfboard \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 28\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-other: Being able to not have to backspace to redo typing\n",
      "\n",
      "Total time: 67.0m\n",
      "ExperimentScreen: 1647.5\n",
      "Welcome: 855.5\n",
      "TaskDescription: 583.0\n",
      "PostTaskSurvey: 320.5\n",
      "PostExpSurvey: 241.0\n",
      "IntroSurvey: 175.9\n",
      "StudyDesc: 173.7\n",
      "PostPractice: 14.2\n",
      "Instructions: 9.2\n",
      "\n",
      "74v545\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a glass of wine in front of a cat on a mat on a table\n",
      "final-0-1:norecs:a bathroom towel hanging on a shower door with a toilet in view\n",
      "final-0-2:norecs:a restroom containing a porcelain toilet and sink. a mirror sits above the sunk on the wall. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a black and white photo of a wedding. the groom and a camerawoman are helping the bride cut the wedding cake on the table filled with glasses and chocloates. \n",
      "final-1-1:general:a family is flying several kites on a beach on a clear day. the kites are very colorful. \n",
      "final-1-2:general:the image shows a railroad track with a train on it further out in te distance. multiple white building hug the side if the track, with some woods behind them. \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:the photo shows a downtown scene of a city. there are old buildings everywhere, and a red bus is prominent in the middle of the road. many people walk down the sidewalks. \n",
      "final-2-1:specific:a tennis olayer is ready to hit the ball back to the opponent who is off screen. they are on a professional sponsored court. \n",
      "final-2-2:specific:a blonde surfer wearing a wetsuit rides an ocean wave. the water looks clear. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No difficulties here\n",
      "postTask-1-techDiff: Nope\n",
      "postTask-2-techDiff: No\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 26\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "\n",
      "Total time: 13.8m\n",
      "ExperimentScreen: 654.9\n",
      "PostTaskSurvey: 86.5\n",
      "PostExpSurvey: 52.7\n",
      "IntroSurvey: 9.6\n",
      "Instructions: 6.3\n",
      "PostPractice: 6.1\n",
      "Welcome: 5.0\n",
      "TaskDescription: 2.9\n",
      "StudyDesc: 1.3\n",
      "\n",
      "vxjcf7\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:an orange and brown cat looks at a glass of red wine\n",
      "final-0-1:general:a beige towel hangs up on the outside of an enclosed shower containing toiletries \n",
      "final-0-2:general:a toilet paper roll sits on a toilet next to a mirror and a white porcelain sink\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a bride and a groom are seen cutting a cake with a photographer in black and white \n",
      "final-1-1:specific:several multicolored kites with streamers are seen soaring above the heads of people\n",
      "final-1-2:specific:a brown train is seen at a station near some colorful buildings and trees \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:dozens of people line the gray sidewalks adjacent to tall buildings as a two deck bus and vehicle progress on the street\n",
      "final-2-1:norecs:a male tennis player wearing khacki shorts swings towards the yellow tennis ball on the green and blue court\n",
      "final-2-2:norecs:a surfer wearing black and white decends from a small wave in the blue ocean\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 34\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-other: Had to scroll to see the entire image, seems like it slowed down the task a bit. Other than that, task was fluid, progressed at a good pace.\n",
      "\n",
      "Total time: 37.8m\n",
      "ExperimentScreen: 936.1\n",
      "PostExpSurvey: 389.5\n",
      "IntroSurvey: 301.8\n",
      "Welcome: 208.4\n",
      "PostTaskSurvey: 207.4\n",
      "TaskDescription: 104.9\n",
      "StudyDesc: 72.5\n",
      "PostPractice: 39.4\n",
      "Instructions: 10.7\n",
      "\n",
      "9f5xwx\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling textrec.analysis_util.get_log_analysis_raw...\n",
      "get_log_analysis_raw('/Users/kcarnold/code/textrec/logs/9f5xwx.jsonl', 491600, git_rev='25a4b8a', analysis_files={ 'analyze.js': '76f95f2156828639ea7c756411b37a4e03cdd403',\n",
      "  'run-analysis': '11083c5f51c5c469297e930142323920f09fe548',\n",
      "  'src/Analyzer.js': 'e8d4e8df767b71fe55698cf95fd9ceddd7b6d3bb'})\n",
      "_____________________________________________get_log_analysis_raw - 4.2s, 0.1min\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:a cat behind a glass vase \n",
      "final-0-1:specific:a shower door \n",
      "final-0-2:specific:a bathroom with a sink and a toilet \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:an old timey wedding\n",
      "final-1-1:norecs:kites in the sky\n",
      "final-1-2:norecs:train on tracks next to homes\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:old european architecture \n",
      "final-2-1:general:man playing tennis \n",
      "final-2-2:general:man surfing \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 21\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "\n",
      "Total time: 122.4m\n",
      "ExperimentScreen: 7187.1\n",
      "PostTaskSurvey: 75.4\n",
      "PostExpSurvey: 36.7\n",
      "IntroSurvey: 11.7\n",
      "TaskDescription: 11.2\n",
      "StudyDesc: 10.6\n",
      "Welcome: 7.3\n",
      "Instructions: 3.3\n",
      "PostPractice: 2.7\n",
      "\n",
      "3267ww\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:a cat is sitting behind a glass of wine\n",
      "\n",
      "final-0-1:specific:a toilet and a shower door hanging with a towel \n",
      "final-0-2:specific:a toilet with a roll of toilet paper and a sink \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a bride and a groom are cutting a cake with the help of a woman\n",
      "final-1-1:norecs:one adult and two kids are playing with kites\n",
      "final-1-2:norecs:a train is coming on a rail road\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red double-decker bus driving on the road, many people walking on the sidewalk\n",
      "\n",
      "final-2-1:general:an adult is holding a tennis racket trying to hit a ball \n",
      "final-2-2:general:a man is standing on water with skis \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 28\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Fluent\n",
      "\n",
      "Total time: 11.7m\n",
      "ExperimentScreen: 502.9\n",
      "PostTaskSurvey: 100.7\n",
      "PostExpSurvey: 50.7\n",
      "IntroSurvey: 18.6\n",
      "Welcome: 11.4\n",
      "Instructions: 6.0\n",
      "TaskDescription: 5.6\n",
      "PostPractice: 5.3\n",
      "StudyDesc: 2.0\n",
      "\n",
      "wf4c3m\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a wine glass with red wine less than half full and an orange striped tabby cat in the background behind the glass\n",
      "final-0-1:general:sliding glass, frosted, shower doors with a tan towel hanging on the handle and a white toilet with a blue floor rug\n",
      "final-0-2:general:a bathroom sink and mirror and toilet with a silver handle attached to the wall behind it\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:specific:a groom and bride slicing a white wedding cake on the banquet food table \n",
      "final-1-1:specific:some people on a sandy beach flying kites with a clear blue sky \n",
      "final-1-2:specific:some train tracks with a train on it traveling beside some white and blue buildings with green trees in the background and a clear blue sky \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a downtown city street and buildings with a vehicle and a bus and some people standing and walking on the sidewalk\n",
      "final-2-1:norecs:a professional tennis court with a professional tennis player hitting at a tennis ball\n",
      "final-2-2:norecs:a surfer in the ocean surfing on a wave\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No. Except what was already explained about the keyboard having to use backspace if I need to correct a word. It won't let me tsp the curser on the exact place I need to correct. But I'm assuming that's part of the keyboard experiment so I wouldn't classify that as technical difficulty. \n",
      "postTask-0-other: Pleasant and interesting experiment. \n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: N/a\n",
      "postTask-2-techDiff: I noticed the keyboard didn't offer word suggestions to choose from. \n",
      "postTask-2-other: N/a\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 46\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No. \n",
      "postExp-other: The experiment was pleasant. The keyboards one and two were very similar. I'm not sure I noticed a big difference between them. Definitely the option to pinpoint correct would be a good option as  is auto correct. But that's it that I can think of.\n",
      "\n",
      "Total time: 67.0m\n",
      "ExperimentScreen: 1730.7\n",
      "PostTaskSurvey: 712.7\n",
      "IntroSurvey: 439.3\n",
      "Welcome: 415.7\n",
      "PostExpSurvey: 394.0\n",
      "TaskDescription: 194.4\n",
      "StudyDesc: 73.7\n",
      "Instructions: 46.9\n",
      "PostPractice: 10.8\n",
      "\n",
      "7jcm37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a half full glass of red wine on a table in front of a calico cat\n",
      "\n",
      "final-0-1:general:a beige towel hanging on a translucent glass shower door\n",
      "final-0-2:general:a white toilet and a white sink with a mirror above the sink \n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a photographer holding the hand of a bride and groom as they cut their wedding cake \n",
      "final-1-1:specific:a msn helping two kids try to fly a kite on the beach \n",
      "final-1-2:specific:a train leaving a train station that has a blue and white building \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a double decker bus driving down a street with old architecture buildings\n",
      "final-2-1:norecs:a tennis player returning a shot on a court in the rogers centre in toronto\n",
      "final-2-2:norecs:a man with blonde hair and a white and black wetsuit surfing a wave. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-0-other: No\n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: No\n",
      "postTask-2-techDiff: No\n",
      "postTask-2-other: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 46\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "postExp-other: It went smooth no issues \n",
      "\n",
      "Total time: 19.5m\n",
      "ExperimentScreen: 726.8\n",
      "PostTaskSurvey: 126.8\n",
      "PostExpSurvey: 87.7\n",
      "Welcome: 79.8\n",
      "TaskDescription: 74.6\n",
      "IntroSurvey: 36.2\n",
      "StudyDesc: 19.7\n",
      "PostPractice: 9.0\n",
      "Instructions: 8.5\n",
      "\n",
      "cf9p8m\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling textrec.analysis_util.get_log_analysis_raw...\n",
      "get_log_analysis_raw('/Users/kcarnold/code/textrec/logs/cf9p8m.jsonl', 909078, git_rev='25a4b8a', analysis_files={ 'analyze.js': '76f95f2156828639ea7c756411b37a4e03cdd403',\n",
      "  'run-analysis': '11083c5f51c5c469297e930142323920f09fe548',\n",
      "  'src/Analyzer.js': 'e8d4e8df767b71fe55698cf95fd9ceddd7b6d3bb'})\n",
      "_____________________________________________get_log_analysis_raw - 2.4s, 0.0min\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a brown and tan cat lays behind a glass of red wine\n",
      "final-0-1:norecs:a beige towel sits on a glass shower door\n",
      "final-0-2:norecs:an unopened roll of toilet tissue rests upon a white toilet\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a woman in black helps a bride and groom cut into their wedding cake\n",
      "final-1-1:specific:families stand around by the water flying kites on a sunny day\n",
      "final-1-2:specific:a train sits on a set of tracks inbetween two platforms resting next to three blue and white buildings\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red double-decker bus driving down a street next to tall buildings and a cloudy sky in london.\n",
      "final-2-1:general:a man is standing in a field with a tennins racket swinging at a ball\n",
      "final-2-2:general:a blonde haired man surfs on a surfboard in the ocean \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 30\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Fluent\n",
      "postExp-other: Everything went smoothly. Thank you\n",
      "\n",
      "Total time: 32.3m\n",
      "Welcome: 1182.9\n",
      "ExperimentScreen: 462.9\n",
      "PostTaskSurvey: 162.5\n",
      "PostExpSurvey: 44.9\n",
      "TaskDescription: 43.2\n",
      "IntroSurvey: 18.3\n",
      "StudyDesc: 16.2\n",
      "Instructions: 3.1\n",
      "PostPractice: 2.6\n",
      "\n",
      "phqcw9\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling textrec.analysis_util.get_log_analysis_raw...\n",
      "get_log_analysis_raw('/Users/kcarnold/code/textrec/logs/phqcw9.jsonl', 1227466, git_rev='25a4b8a', analysis_files={ 'analyze.js': '76f95f2156828639ea7c756411b37a4e03cdd403',\n",
      "  'run-analysis': '11083c5f51c5c469297e930142323920f09fe548',\n",
      "  'src/Analyzer.js': 'e8d4e8df767b71fe55698cf95fd9ceddd7b6d3bb'})\n",
      "_____________________________________________get_log_analysis_raw - 2.4s, 0.0min\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:specific:a curious cat sits perched upon a table, next to a glass of wine\n",
      "final-0-1:specific:a closed wavy glass door in the bathroom peers intk the walk in shower \n",
      "final-0-2:specific:a toilet paper sits on top of a toilet next to the sink, in a plain bathroom \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a black-and-white picture of a young couple cuttinf the wedding cake with the help of a young photographer at the wedding event\n",
      "final-1-1:general:two children with an adult flying kites on the beach around others doing the same in the afternoon \n",
      "final-1-2:general:a landscape of a train stop with an old-looking brownish train and a few brightly colored buildings to one side\n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:looking down a london street on a crowded evening with a london double bus in clear focus and old-style buildings next to each other on both sides\n",
      "final-2-1:norecs:roger federer moves towards the tennis ball, intently ready to smack it and win\n",
      "final-2-2:norecs:a young blond man in a water suit catching a small wave on his surfboard\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: I did not\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 039\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "\n",
      "Total time: 14.5m\n",
      "ExperimentScreen: 629.0\n",
      "PostTaskSurvey: 77.6\n",
      "TaskDescription: 73.5\n",
      "PostExpSurvey: 50.3\n",
      "StudyDesc: 14.6\n",
      "IntroSurvey: 11.6\n",
      "Instructions: 4.7\n",
      "Welcome: 4.6\n",
      "PostPractice: 4.4\n",
      "\n",
      "5jj59g\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling textrec.analysis_util.get_log_analysis_raw...\n",
      "get_log_analysis_raw('/Users/kcarnold/code/textrec/logs/5jj59g.jsonl', 1041656, git_rev='25a4b8a', analysis_files={ 'analyze.js': '76f95f2156828639ea7c756411b37a4e03cdd403',\n",
      "  'run-analysis': '11083c5f51c5c469297e930142323920f09fe548',\n",
      "  'src/Analyzer.js': 'e8d4e8df767b71fe55698cf95fd9ceddd7b6d3bb'})\n",
      "_____________________________________________get_log_analysis_raw - 2.4s, 0.0min\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a cat sitting on a placemat on a table behind a wineglass\n",
      "final-0-1:norecs:a closed shower with a pattern on the door making it hard to see inside\n",
      "final-0-2:norecs:a sink, mirror and toilet, all in white with a roll of toilet paper on the toilet\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a bride and groom cutting a cake with the photographer showing them how to cut the four tier cake\n",
      "final-1-1:specific:a man and two children about to fly kites with people in the background flying kites above the beach \n",
      "final-1-2:specific:an old train about to arrive at a station stop with no people present \n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a large street with people on the sidewalk while a red double decker bus approaches a pedestrian crossing. \n",
      "final-2-1:general:a tennis player on the court about to swing and hit a ball appproaching him\n",
      "final-2-2:general:a surfer on a a surfboard riding wave in the ocean\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No issues\n",
      "postTask-1-techDiff: No issues\n",
      "postTask-2-techDiff: No issues\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 37\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No issues\n",
      "\n",
      "Total time: 12.8m\n",
      "ExperimentScreen: 473.5\n",
      "PostTaskSurvey: 145.6\n",
      "PostExpSurvey: 52.1\n",
      "TaskDescription: 48.5\n",
      "StudyDesc: 22.3\n",
      "IntroSurvey: 11.9\n",
      "Welcome: 7.5\n",
      "Instructions: 3.9\n",
      "PostPractice: 3.6\n",
      "\n",
      "gw3w72\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling textrec.analysis_util.get_log_analysis_raw...\n",
      "get_log_analysis_raw('/Users/kcarnold/code/textrec/logs/gw3w72.jsonl', 563501, git_rev='25a4b8a', analysis_files={ 'analyze.js': '76f95f2156828639ea7c756411b37a4e03cdd403',\n",
      "  'run-analysis': '11083c5f51c5c469297e930142323920f09fe548',\n",
      "  'src/Analyzer.js': 'e8d4e8df767b71fe55698cf95fd9ceddd7b6d3bb'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________get_log_analysis_raw - 2.3s, 0.0min\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a tabby cat is sitting in front of a wine glass\n",
      "final-0-1:norecs:the doors to the shower are closed and made of glass you can partially see through. \n",
      "final-0-2:norecs:the mirror shows there are more than one toliets in this bathroom. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a woman is standing next to a couple in front of a cake with a knife in it and holding the other womans hands\n",
      "final-1-1:general:people are standing on the beach flying colorful kites \n",
      "final-1-2:general:there is a train stopped at a train station platform \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:there are people walking down the street with a red double decker bus in the middle of the street \n",
      "final-2-1:specific:the tennis player is swinging his racket at a tennis ball in front of him. \n",
      "final-2-2:specific:a man riding a wave on top of a surfboard in the middle of the ocean with his surfboard \n",
      "\n",
      "intro-use_predictive: No\n",
      "postTask-0-techDiff: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 41\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-other: There were no problems in taking this study\n",
      "\n",
      "Total time: 18.1m\n",
      "ExperimentScreen: 665.1\n",
      "PostTaskSurvey: 148.7\n",
      "PostExpSurvey: 109.0\n",
      "TaskDescription: 86.5\n",
      "StudyDesc: 25.5\n",
      "Welcome: 21.0\n",
      "IntroSurvey: 19.3\n",
      "PostPractice: 8.1\n",
      "Instructions: 4.5\n",
      "\n",
      "559x69\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling textrec.analysis_util.get_log_analysis_raw...\n",
      "get_log_analysis_raw('/Users/kcarnold/code/textrec/logs/559x69.jsonl', 914668, git_rev='25a4b8a', analysis_files={ 'analyze.js': '76f95f2156828639ea7c756411b37a4e03cdd403',\n",
      "  'run-analysis': '11083c5f51c5c469297e930142323920f09fe548',\n",
      "  'src/Analyzer.js': 'e8d4e8df767b71fe55698cf95fd9ceddd7b6d3bb'})\n",
      "_____________________________________________get_log_analysis_raw - 2.4s, 0.0min\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a cat sits on a table behind a barely filled wine glass. \n",
      "final-0-1:norecs:a loofah and other items are blurry looking through an opaque shower door. \n",
      "final-0-2:norecs:a toilet has a roll of toilet paper on it, and there is a sink that matches it to the right. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:the photographer helps the bride and groom cut the wedding cake. \n",
      "final-1-1:general:there is one kite flying over four other kites on a blue sky. \n",
      "final-1-2:general:a train is arriving at a quaint beach side looking station. \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a double-decker bus drives through a busy city street in london. \n",
      "final-2-1:specific:a tennis player lunges across the court towards the ball with his tennis racquet. \n",
      "final-2-2:specific:a surfer wearing a wetsuit is catching a wave. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 32\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "\n",
      "Total time: 22.9m\n",
      "ExperimentScreen: 878.9\n",
      "PostTaskSurvey: 152.8\n",
      "TaskDescription: 143.2\n",
      "IntroSurvey: 73.1\n",
      "Instructions: 40.2\n",
      "PostExpSurvey: 35.9\n",
      "StudyDesc: 22.6\n",
      "Welcome: 14.1\n",
      "PostPractice: 10.3\n",
      "\n",
      "gvwqp6\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling textrec.analysis_util.get_log_analysis_raw...\n",
      "get_log_analysis_raw('/Users/kcarnold/code/textrec/logs/gvwqp6.jsonl', 579578, git_rev='25a4b8a', analysis_files={ 'analyze.js': '76f95f2156828639ea7c756411b37a4e03cdd403',\n",
      "  'run-analysis': '11083c5f51c5c469297e930142323920f09fe548',\n",
      "  'src/Analyzer.js': 'e8d4e8df767b71fe55698cf95fd9ceddd7b6d3bb'})\n",
      "_____________________________________________get_log_analysis_raw - 2.2s, 0.0min\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a chubby faced brown and yellow tabby cat looks beyond a glass of red wine\n",
      "final-0-1:norecs:a towel folded over a rack on sliding shower doors\n",
      "final-0-2:norecs:a bathroom with a white sink and white toilet. a roll of unwrapped toilet paper sits on the bowl\n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a bride and groom cut a wedding cake together \n",
      "final-1-1:general:a family flies their kites together at a beach in the sun \n",
      "final-1-2:general:a train is traveling down the tracks near a rail road station \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a double decker bus traveling down the middle of the street in the city streets. \n",
      "final-2-1:specific:a male tennis player hits the ball with his racket on the tennis court. \n",
      "final-2-2:specific:a surfer rides the crest of the waves in the ocean. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-1-techDiff: No\n",
      "postTask-2-techDiff: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 41\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Fluent\n",
      "postExp-techDiff: No\n",
      "postExp-other: I really enjoyed this experiment. Well done!! Thank you for considering my data.\n",
      "\n",
      "Total time: 19.7m\n",
      "ExperimentScreen: 677.1\n",
      "PostTaskSurvey: 155.5\n",
      "TaskDescription: 127.2\n",
      "PostExpSurvey: 114.4\n",
      "IntroSurvey: 52.6\n",
      "StudyDesc: 20.6\n",
      "Welcome: 18.4\n",
      "PostPractice: 10.7\n",
      "Instructions: 6.3\n"
     ]
    }
   ],
   "source": [
    "# summarize('2018-04-27')\n",
    "summarize('2018-05-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = get_trial_data(participants['2018-05-02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in trial_data:\n",
    "    trial['text'] = trial['text'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had the wrong URL for one image when one person ran it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_data = [trial for trial in trial_data if not (trial['stimulus'] == 431140 and trial['participant'] == 'h52x67')]\n",
    "trial_data = [trial for trial in trial_data if not trial['participant'] == 'h52x67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(toolz.pluck('text', trial_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(toolz.pluck('participant', trial_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trial_data).to_csv('data/trial_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(trial_data).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-8f854cfa7fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblock_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_survey_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2018-05-02'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/textrec/src/textrec/batch_analysis.py\u001b[0m in \u001b[0;36mget_survey_data\u001b[0;34m(participants)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     return (\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'participant block name value'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         pd.DataFrame(experiment_level, columns='participant name value'.split()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "block_level, experiment_level = get_survey_data(participants['2018-05-02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>use_predictive</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I like to solve complex problems.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I have difficulty understanding abstract ideas.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I feel comfortable around people.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I have little to say.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I need things explained only once.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I try to avoid complex people.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I make friends easily.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I keep in the background.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I can handle a lot of information.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I avoid difficult reading material.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I am skilled in handling social situations.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I would describe my experiences as somewhat dull.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I love to think up new ways of doing things.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I avoid philosophical discussions.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I am the life of the party.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I don't like to draw attention to myself.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-specific-most-idx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-specific-most-condition</td>\n",
       "      <td>specific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-specific-least-idx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-specific-least-condition</td>\n",
       "      <td>norecs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-accurate-most-idx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-accurate-most-condition</td>\n",
       "      <td>specific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-accurate-least-idx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-accurate-least-condition</td>\n",
       "      <td>norecs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-quick-most-idx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-quick-most-condition</td>\n",
       "      <td>specific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-quick-least-idx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>helpfulRank-quick-least-condition</td>\n",
       "      <td>norecs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>I am quick to understand things.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I can handle a lot of information.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I avoid difficult reading material.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I am skilled in handling social situations.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I would describe my experiences as somewhat dull.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I love to think up new ways of doing things.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I avoid philosophical discussions.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I am the life of the party.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I don't like to draw attention to myself.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-specific-most-idx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-specific-most-condition</td>\n",
       "      <td>specific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-specific-least-idx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-specific-least-condition</td>\n",
       "      <td>norecs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-accurate-most-idx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-accurate-most-condition</td>\n",
       "      <td>specific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-accurate-least-idx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-accurate-least-condition</td>\n",
       "      <td>norecs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-quick-most-idx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-quick-most-condition</td>\n",
       "      <td>specific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-quick-least-idx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>helpfulRank-quick-least-condition</td>\n",
       "      <td>norecs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I am quick to understand things.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I know how to captivate people.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I don't talk a lot.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>I love to read challenging material.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>verbalized_during</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>age</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>gender</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>english_proficiency</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>techDiff</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>other</td>\n",
       "      <td>I really enjoyed this experiment. Well done!! ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>956 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1  \\\n",
       "0    h52x67                                     use_predictive   \n",
       "1    h52x67                  I like to solve complex problems.   \n",
       "2    h52x67    I have difficulty understanding abstract ideas.   \n",
       "3    h52x67                  I feel comfortable around people.   \n",
       "4    h52x67                              I have little to say.   \n",
       "5    h52x67                 I need things explained only once.   \n",
       "6    h52x67                     I try to avoid complex people.   \n",
       "7    h52x67                             I make friends easily.   \n",
       "8    h52x67                          I keep in the background.   \n",
       "9    h52x67                 I can handle a lot of information.   \n",
       "10   h52x67                I avoid difficult reading material.   \n",
       "11   h52x67        I am skilled in handling social situations.   \n",
       "12   h52x67  I would describe my experiences as somewhat dull.   \n",
       "13   h52x67       I love to think up new ways of doing things.   \n",
       "14   h52x67                 I avoid philosophical discussions.   \n",
       "15   h52x67                        I am the life of the party.   \n",
       "16   h52x67          I don't like to draw attention to myself.   \n",
       "17   h52x67                      helpfulRank-specific-most-idx   \n",
       "18   h52x67                helpfulRank-specific-most-condition   \n",
       "19   h52x67                     helpfulRank-specific-least-idx   \n",
       "20   h52x67               helpfulRank-specific-least-condition   \n",
       "21   h52x67                      helpfulRank-accurate-most-idx   \n",
       "22   h52x67                helpfulRank-accurate-most-condition   \n",
       "23   h52x67                     helpfulRank-accurate-least-idx   \n",
       "24   h52x67               helpfulRank-accurate-least-condition   \n",
       "25   h52x67                         helpfulRank-quick-most-idx   \n",
       "26   h52x67                   helpfulRank-quick-most-condition   \n",
       "27   h52x67                        helpfulRank-quick-least-idx   \n",
       "28   h52x67                  helpfulRank-quick-least-condition   \n",
       "29   h52x67                   I am quick to understand things.   \n",
       "..      ...                                                ...   \n",
       "926  gvwqp6                 I can handle a lot of information.   \n",
       "927  gvwqp6                I avoid difficult reading material.   \n",
       "928  gvwqp6        I am skilled in handling social situations.   \n",
       "929  gvwqp6  I would describe my experiences as somewhat dull.   \n",
       "930  gvwqp6       I love to think up new ways of doing things.   \n",
       "931  gvwqp6                 I avoid philosophical discussions.   \n",
       "932  gvwqp6                        I am the life of the party.   \n",
       "933  gvwqp6          I don't like to draw attention to myself.   \n",
       "934  gvwqp6                      helpfulRank-specific-most-idx   \n",
       "935  gvwqp6                helpfulRank-specific-most-condition   \n",
       "936  gvwqp6                     helpfulRank-specific-least-idx   \n",
       "937  gvwqp6               helpfulRank-specific-least-condition   \n",
       "938  gvwqp6                      helpfulRank-accurate-most-idx   \n",
       "939  gvwqp6                helpfulRank-accurate-most-condition   \n",
       "940  gvwqp6                     helpfulRank-accurate-least-idx   \n",
       "941  gvwqp6               helpfulRank-accurate-least-condition   \n",
       "942  gvwqp6                         helpfulRank-quick-most-idx   \n",
       "943  gvwqp6                   helpfulRank-quick-most-condition   \n",
       "944  gvwqp6                        helpfulRank-quick-least-idx   \n",
       "945  gvwqp6                  helpfulRank-quick-least-condition   \n",
       "946  gvwqp6                   I am quick to understand things.   \n",
       "947  gvwqp6                    I know how to captivate people.   \n",
       "948  gvwqp6                                I don't talk a lot.   \n",
       "949  gvwqp6               I love to read challenging material.   \n",
       "950  gvwqp6                                  verbalized_during   \n",
       "951  gvwqp6                                                age   \n",
       "952  gvwqp6                                             gender   \n",
       "953  gvwqp6                                english_proficiency   \n",
       "954  gvwqp6                                           techDiff   \n",
       "955  gvwqp6                                              other   \n",
       "\n",
       "                                                     2  \n",
       "0                                                  Yes  \n",
       "1                                                    2  \n",
       "2                                                    1  \n",
       "3                                                    3  \n",
       "4                                                    2  \n",
       "5                                                    3  \n",
       "6                                                    4  \n",
       "7                                                    3  \n",
       "8                                                    3  \n",
       "9                                                    3  \n",
       "10                                                   3  \n",
       "11                                                   3  \n",
       "12                                                   1  \n",
       "13                                                   3  \n",
       "14                                                   1  \n",
       "15                                                   2  \n",
       "16                                                   4  \n",
       "17                                                   0  \n",
       "18                                            specific  \n",
       "19                                                   1  \n",
       "20                                              norecs  \n",
       "21                                                   0  \n",
       "22                                            specific  \n",
       "23                                                   1  \n",
       "24                                              norecs  \n",
       "25                                                   0  \n",
       "26                                            specific  \n",
       "27                                                   1  \n",
       "28                                              norecs  \n",
       "29                                                   3  \n",
       "..                                                 ...  \n",
       "926                                                  3  \n",
       "927                                                  1  \n",
       "928                                                  2  \n",
       "929                                                  1  \n",
       "930                                                  3  \n",
       "931                                                  1  \n",
       "932                                                  1  \n",
       "933                                                  2  \n",
       "934                                                  2  \n",
       "935                                           specific  \n",
       "936                                                  0  \n",
       "937                                             norecs  \n",
       "938                                                  2  \n",
       "939                                           specific  \n",
       "940                                                  0  \n",
       "941                                             norecs  \n",
       "942                                                  2  \n",
       "943                                           specific  \n",
       "944                                                  0  \n",
       "945                                             norecs  \n",
       "946                                                  3  \n",
       "947                                                  3  \n",
       "948                                                  2  \n",
       "949                                                  4  \n",
       "950                                                 No  \n",
       "951                                                 41  \n",
       "952                                               Male  \n",
       "953                                             Fluent  \n",
       "954                                                 No  \n",
       "955  I really enjoyed this experiment. Well done!! ...  \n",
       "\n",
       "[956 rows x 3 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(experiment_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [analyzed['byExpPage'][page]['condition'] for page in analyzed['pageSeq']][::4]\n",
    "\n",
    "block_level = []\n",
    "experiment_level = []\n",
    "\n",
    "for k, v in analyzed['allControlledInputs']:\n",
    "    segment, rest = k.split('-', 1)\n",
    "    if segment == 'intro':\n",
    "        experiment_level.append((participant_id, rest, v))\n",
    "    elif segment == 'postTask':\n",
    "        block, rest = rest.split('-', 1)\n",
    "        block = int(block)\n",
    "        if ' ' in rest:\n",
    "            # Traits, TODO\n",
    "            experiment_level.append((participant_id, rest, v))\n",
    "        else:\n",
    "            block_level.append((participant_id, block, rest, v))\n",
    "    elif segment == 'postExp':\n",
    "        if rest == 'age':\n",
    "            v = int(v)\n",
    "        if rest.startswith('helpfulRank'):\n",
    "            # Decode which keyboard they're talking about\n",
    "            assert v.startswith('Keyboard Design ')\n",
    "            condition_idx = int(v[-1]) - 1\n",
    "            experiment_level.append((participant_id, f'{rest}-idx', condition_idx))\n",
    "            experiment_level.append((participant_id, f'{rest}-condition', conditions[condition_idx]))\n",
    "        else:\n",
    "            experiment_level.append((participant_id, rest, v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h52x67', 'use_predictive', 'Yes'),\n",
       " ('h52x67', 'I like to solve complex problems.', 2),\n",
       " ('h52x67', 'I have difficulty understanding abstract ideas.', 1),\n",
       " ('h52x67', 'I feel comfortable around people.', 3),\n",
       " ('h52x67', 'I have little to say.', 2),\n",
       " ('h52x67', 'I need things explained only once.', 3),\n",
       " ('h52x67', 'I try to avoid complex people.', 4),\n",
       " ('h52x67', 'I make friends easily.', 3),\n",
       " ('h52x67', 'I keep in the background.', 3),\n",
       " ('h52x67', 'I can handle a lot of information.', 3),\n",
       " ('h52x67', 'I avoid difficult reading material.', 3),\n",
       " ('h52x67', 'I am skilled in handling social situations.', 3),\n",
       " ('h52x67', 'I would describe my experiences as somewhat dull.', 1),\n",
       " ('h52x67', 'I love to think up new ways of doing things.', 3),\n",
       " ('h52x67', 'I avoid philosophical discussions.', 1),\n",
       " ('h52x67', 'I am the life of the party.', 2),\n",
       " ('h52x67', \"I don't like to draw attention to myself.\", 4),\n",
       " ('h52x67', 'helpfulRank-specific-most-idx', 0),\n",
       " ('h52x67', 'helpfulRank-specific-most-condition', 'specific'),\n",
       " ('h52x67', 'helpfulRank-specific-least-idx', 1),\n",
       " ('h52x67', 'helpfulRank-specific-least-condition', 'norecs'),\n",
       " ('h52x67', 'helpfulRank-accurate-most-idx', 0),\n",
       " ('h52x67', 'helpfulRank-accurate-most-condition', 'specific'),\n",
       " ('h52x67', 'helpfulRank-accurate-least-idx', 1),\n",
       " ('h52x67', 'helpfulRank-accurate-least-condition', 'norecs'),\n",
       " ('h52x67', 'helpfulRank-quick-most-idx', 0),\n",
       " ('h52x67', 'helpfulRank-quick-most-condition', 'specific'),\n",
       " ('h52x67', 'helpfulRank-quick-least-idx', 1),\n",
       " ('h52x67', 'helpfulRank-quick-least-condition', 'norecs'),\n",
       " ('h52x67', 'I am quick to understand things.', 3),\n",
       " ('h52x67', 'I know how to captivate people.', 2),\n",
       " ('h52x67', \"I don't talk a lot.\", 3),\n",
       " ('h52x67', 'I love to read challenging material.', 0),\n",
       " ('h52x67', 'verbalized_during', 'No'),\n",
       " ('h52x67', 'age', 41),\n",
       " ('h52x67', 'gender', 'Female'),\n",
       " ('h52x67', 'english_proficiency', 'Native or bilingual'),\n",
       " ('h52x67',\n",
       "  'techDiff',\n",
       "  'Just the fact that the third photo in keyboard 1 never loaded.'),\n",
       " ('h52x67',\n",
       "  'other',\n",
       "  'It was fun! Just feel a little unsure that I will be penalized for not writing a caption for the third photo on keyboard 1. I hope that was OK. Thank you!')]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h52x67', 0, 'sys-specific', 6),\n",
       " ('h52x67', 0, 'sys-accurate', 5),\n",
       " ('h52x67', 0, 'sys-fast', 6),\n",
       " ('h52x67', 0, 'mental', 3),\n",
       " ('h52x67', 0, 'physical', 0),\n",
       " ('h52x67', 0, 'temporal', 3),\n",
       " ('h52x67', 0, 'performance', 3),\n",
       " ('h52x67', 0, 'effort', 5),\n",
       " ('h52x67', 0, 'frustration', 5),\n",
       " ('h52x67', 0, 'techDiff', 'There was no image in he third task.'),\n",
       " ('h52x67',\n",
       "  0,\n",
       "  'other',\n",
       "  'The keyboard seemed to have the words I wanted already there, on many of them all I had to do was touch the word.'),\n",
       " ('h52x67', 1, 'sys-specific', 0),\n",
       " ('h52x67', 1, 'sys-accurate', 3),\n",
       " ('h52x67', 1, 'sys-fast', 1),\n",
       " ('h52x67', 1, 'mental', 4),\n",
       " ('h52x67', 1, 'physical', 1),\n",
       " ('h52x67', 1, 'temporal', 4),\n",
       " ('h52x67', 1, 'performance', 2),\n",
       " ('h52x67', 1, 'effort', 2),\n",
       " ('h52x67', 1, 'frustration', 1),\n",
       " ('h52x67', 1, 'techDiff', 'None.'),\n",
       " ('h52x67',\n",
       "  1,\n",
       "  'other',\n",
       "  'It was a little more challenging this time, because there were no predicted words. Also I had to be extra careful with spelling!'),\n",
       " ('h52x67', 2, 'sys-specific', 4),\n",
       " ('h52x67', 2, 'sys-accurate', 5),\n",
       " ('h52x67', 2, 'sys-fast', 6),\n",
       " ('h52x67', 2, 'mental', 1),\n",
       " ('h52x67', 2, 'physical', 0),\n",
       " ('h52x67', 2, 'temporal', 3),\n",
       " ('h52x67', 2, 'performance', 3),\n",
       " ('h52x67', 2, 'effort', 4),\n",
       " ('h52x67', 2, 'frustration', 2),\n",
       " ('h52x67', 2, 'techDiff', 'No.'),\n",
       " ('h52x67',\n",
       "  2,\n",
       "  'other',\n",
       "  'This also had predicted words, but somehow I had a harder time coming up with good descriptions. The photos seemed too generic for some reason.')]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate nAFC task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each stimulus image, choose a foil set. It should be about equally difficult for each condition. Simplest approach: find the nearest caption to the concatenation of all captions we got for that image.\n",
    "\n",
    "TODO: should we be computing similarities of individual captions, rather than complete images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vectorizer, caption_vecs = util.get_vectorized_captions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123287, 9952)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://images.cocodataset.org/train2017/000000570528.jpg'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2url[570528]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([275449, 396295, 431140, 227326, 200451, 223777, 247576, 71815, 240275])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_captions = {stimulus: '\\n'.join(toolz.pluck('text', trials))\n",
    "                   for stimulus, trials in toolz.groupby('stimulus', trial_data).items()}\n",
    "concat_captions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a small bath with a shower with a blue mat on the floor\n",
      "someome is using a shower but it's hard to see due to the opaque glass\n",
      "i see a standing shower with two hazy sliding glass doors and a towel hanging off of one.\n",
      "a tan towel hangs in front of a glass shower\n",
      "brown towel is hanging on a sliding shower door\n",
      "a beige towel hangs over the rightmost shower door both of which are wet with water\n",
      "a closed shower door with crackled glass encases some hanging colored toiletries\n",
      "a rusty and dirty shower in the bathroom has a tan towel over its handle\n",
      "a sliding glass shower door with a bath mat hanging on it\n",
      "a shower with a towel hanging on the handle of the door\n",
      "a tan towel is hanging from a chrome handle on a textured glass shower door\n",
      "a person is taking a shower in a shower with very opaque sliding doors\n",
      "a bathroom towel hanging on a shower door with a toilet in view\n",
      "a beige towel hangs up on the outside of an enclosed shower containing toiletries\n",
      "a shower door\n",
      "a toilet and a shower door hanging with a towel\n",
      "sliding glass, frosted, shower doors with a tan towel hanging on the handle and a white toilet with a blue floor rug\n",
      "a beige towel hanging on a translucent glass shower door\n",
      "a beige towel sits on a glass shower door\n",
      "a closed wavy glass door in the bathroom peers intk the walk in shower\n",
      "a closed shower with a pattern on the door making it hard to see inside\n",
      "the doors to the shower are closed and made of glass you can partially see through.\n",
      "a loofah and other items are blurry looking through an opaque shower door.\n",
      "a towel folded over a rack on sliding shower doors\n"
     ]
    }
   ],
   "source": [
    "# print(concat_captions[71815])\n",
    "# print(concat_captions[275449])\n",
    "print(concat_captions[396295])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 275449, the foil images are fixated on the 'wine'. But unsurprising, since all but one caption mentions it, and it's probably less common than \"cat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_similar_images(caption, n=10):\n",
    "    query_vec = cap_vectorizer.transform([caption])\n",
    "    similarity = caption_vecs.dot(query_vec.T).A.ravel()\n",
    "    return [images[idx]['cocoid'] for idx in np.argsort(similarity)[-n:][::-1]]\n",
    "query_caption = concat_captions[396295].replace('wine', '') #trial_data[0]['text']\n",
    "# query_caption = \"a rusty and dirty shower in the bathroom has a tan towel over its handle\"\n",
    "# query_caption = \"a sliding glass shower door with a bath mat hanging on it\"\n",
    "query_caption = \"a closed shower door with crackled glass encases some hanging colored toiletries\"\n",
    "# print(query_caption)\n",
    "# HTML(show_images(get_similar_images(query_caption)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[490872, 233737, 372775, 396295, 409842, 262284, 503200, 510852, 98257, 212082]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_foil_set(*, stimulus, caption, rs):\n",
    "    similar_images = get_similar_images(caption, n=10)\n",
    "    if stimulus not in similar_images:\n",
    "        print(\"Inserting\", stimulus, 'into foil set')\n",
    "        similar_images[-1] = stimulus\n",
    "    rs.shuffle(similar_images)\n",
    "    return similar_images\n",
    "stimulus = trial_data[1]['stimulus']\n",
    "get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=np.random.RandomState(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 200451 into foil set\n",
      "Inserting 240275 into foil set\n",
      "Inserting 431140 into foil set\n"
     ]
    }
   ],
   "source": [
    "rs = np.random.RandomState(1234)\n",
    "foil_sets = {\n",
    "    stimulus: get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=rs)\n",
    "    for stimulus in sorted(concat_captions.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group tasks so that (1) each annotator never gets the same target image twice and (2) each annotator never sees two captions from the same person. The latter criterion cannot always be met, though, since the number of annotators may not evenly divide the number of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffled(lst):\n",
    "    lst = lst[:]\n",
    "    random.shuffle(lst)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    trials_by_img = toolz.groupby('stimulus', shuffled(trial_data))\n",
    "    annotators = []\n",
    "    while not any(len(trials) == 0 for trials in trials_by_img.values()):\n",
    "        trials_for_annotator = []\n",
    "        participants_seen_by_annotator = set()\n",
    "        for stimulus, trials in trials_by_img.items():\n",
    "            for i in range(len(trials)):\n",
    "                participant = trials[i]['participant']\n",
    "                if participant not in participants_seen_by_annotator:\n",
    "                    trials_for_annotator.append(trials.pop(i))\n",
    "                    participants_seen_by_annotator.add(participant)\n",
    "                    break\n",
    "            else:\n",
    "#                 print(\"Have to use the same participant again\")\n",
    "                trials_for_annotator.append(trials.pop(0))\n",
    "\n",
    "        annotators.append(shuffled(trials_for_annotator))\n",
    "    if all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators):\n",
    "        break\n",
    "    assert all(len(trials) == 0 for trials in trials_by_img.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = annotators[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{71815: [],\n",
       " 227326: [],\n",
       " 247576: [],\n",
       " 223777: [],\n",
       " 240275: [],\n",
       " 275449: [],\n",
       " 431140: [],\n",
       " 200451: [],\n",
       " 396295: []}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_by_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never gets the same target image twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('stimulus', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never sees two captions from the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(trials) for trials in annotators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_task(stimulus, text):\n",
    "    foil_set = foil_sets[stimulus]\n",
    "    return dict(\n",
    "        description=text,\n",
    "        correct_idx=foil_set.index(stimulus),\n",
    "        images=[id2url[idx] for idx in foil_set]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'dozens of people line the gray sidewalks adjacent to tall buildings as a two deck bus and vehicle progress on the street',\n",
       " 'correct_idx': 2,\n",
       " 'images': ['http://images.cocodataset.org/train2017/000000200447.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000578233.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000247576.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000050752.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000024600.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000551983.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000318107.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000282343.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000059611.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000360528.jpg']}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = annotators[0][0]\n",
    "make_task(trial['stimulus'], trial['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_task = pd.DataFrame([\n",
    "    json.dumps([make_task(trial['stimulus'], trial['text']) for trial in annotator_trials])\n",
    "    for annotator_trials in annotators], columns=['task'])\n",
    "guesses_task.iloc[:1].to_csv(str(paths.data / 'anno-tasks' / 'guesses_test.csv'), index=False)\n",
    "guesses_task.iloc[1:].to_csv(str(paths.data / 'anno-tasks' / 'guesses_remain.csv'), index=False)\n",
    "guesses_task.to_csv(str(paths.data / 'anno-tasks' / 'guesses.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MTurk results so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = list((paths.data / 'mturk').glob('*-guesses.csv'))\n",
    "batched_guesses_results = (\n",
    "    pd.concat([pd.read_csv(str(f)) for f in result_files], axis=0, ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19b910860>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19cf07278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(batched_guesses_results['WorkTimeInSeconds']/60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>guesser</th>\n",
       "      <th>num_guesses</th>\n",
       "      <th>stimulus_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dozens of people line the gray sidewalks adjac...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a man with blonde hair and a white and black w...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people are standing on the beach flying colorf...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a train is coming on a rail road</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>6</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a tricolor cat is sitting in front of a partia...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a closed shower door with crackled glass encas...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a tennis player in a white shirt and tan short...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a bathroom with a toilet and sink and with a r...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dozens of people line the gray sidewalks adjac...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a man with blonde hair and a white and black w...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>people are standing on the beach flying colorf...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a train is coming on a rail road</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>7</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a tricolor cat is sitting in front of a partia...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a closed shower door with crackled glass encas...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a tennis player in a white shirt and tan short...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a bathroom with a toilet and sink and with a r...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dozens of people line the gray sidewalks adjac...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a man with blonde hair and a white and black w...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>people are standing on the beach flying colorf...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a train is coming on a rail road</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>10</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a tricolor cat is sitting in front of a partia...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>a closed shower door with crackled glass encas...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a tennis player in a white shirt and tan short...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>a bathroom with a toilet and sink and with a r...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>a gorgeous european city with tall gothic buil...</td>\n",
       "      <td>A23437BMZ5T1FH</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>a restroom containing a porcelain toilet and s...</td>\n",
       "      <td>A23437BMZ5T1FH</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A23437BMZ5T1FH</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>a brown trai  pulls into the tracka next to so...</td>\n",
       "      <td>AIZTLQM7HHQN6</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>a young blond man in a water suit catching a s...</td>\n",
       "      <td>AIZTLQM7HHQN6</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>a gray and beige cat looks upward as a half fu...</td>\n",
       "      <td>AIZTLQM7HHQN6</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>a man and his two children are flying multicol...</td>\n",
       "      <td>AIQT0DPRTXYYD</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>a man and woman getting assistance cutting the...</td>\n",
       "      <td>AIQT0DPRTXYYD</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>a wine glass with red wine less than half full...</td>\n",
       "      <td>AIQT0DPRTXYYD</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>a surfer leans forward to ride a wave</td>\n",
       "      <td>AIQT0DPRTXYYD</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>roger federer about to back hand a tennis ball...</td>\n",
       "      <td>AIQT0DPRTXYYD</td>\n",
       "      <td>6</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>a large street with people on the sidewalk whi...</td>\n",
       "      <td>AIQT0DPRTXYYD</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>a train is approaching the station and passing...</td>\n",
       "      <td>AIQT0DPRTXYYD</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>a white bathroom sink and toilet with a mirror...</td>\n",
       "      <td>AIQT0DPRTXYYD</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>a sliding glass shower door with a bath mat ha...</td>\n",
       "      <td>AIQT0DPRTXYYD</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>a man and his two children are flying multicol...</td>\n",
       "      <td>A33LYSCQQU1YDJ</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>a man and woman getting assistance cutting the...</td>\n",
       "      <td>A33LYSCQQU1YDJ</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>a wine glass with red wine less than half full...</td>\n",
       "      <td>A33LYSCQQU1YDJ</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>a surfer leans forward to ride a wave</td>\n",
       "      <td>A33LYSCQQU1YDJ</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>roger federer about to back hand a tennis ball...</td>\n",
       "      <td>A33LYSCQQU1YDJ</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>a large street with people on the sidewalk whi...</td>\n",
       "      <td>A33LYSCQQU1YDJ</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>a train is approaching the station and passing...</td>\n",
       "      <td>A33LYSCQQU1YDJ</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>a white bathroom sink and toilet with a mirror...</td>\n",
       "      <td>A33LYSCQQU1YDJ</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>a sliding glass shower door with a bath mat ha...</td>\n",
       "      <td>A33LYSCQQU1YDJ</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>a man and his two children are flying multicol...</td>\n",
       "      <td>AAASQIW3J32OL</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>a man and woman getting assistance cutting the...</td>\n",
       "      <td>AAASQIW3J32OL</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>a wine glass with red wine less than half full...</td>\n",
       "      <td>AAASQIW3J32OL</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>a surfer leans forward to ride a wave</td>\n",
       "      <td>AAASQIW3J32OL</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>roger federer about to back hand a tennis ball...</td>\n",
       "      <td>AAASQIW3J32OL</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>a large street with people on the sidewalk whi...</td>\n",
       "      <td>AAASQIW3J32OL</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>a train is approaching the station and passing...</td>\n",
       "      <td>AAASQIW3J32OL</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>a white bathroom sink and toilet with a mirror...</td>\n",
       "      <td>AAASQIW3J32OL</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>a sliding glass shower door with a bath mat ha...</td>\n",
       "      <td>AAASQIW3J32OL</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description         guesser  \\\n",
       "0    dozens of people line the gray sidewalks adjac...   A89R5XGMHOTJE   \n",
       "1    a newly wedded couple cutting there wedding ca...   A89R5XGMHOTJE   \n",
       "2    a man with blonde hair and a white and black w...   A89R5XGMHOTJE   \n",
       "3    people are standing on the beach flying colorf...   A89R5XGMHOTJE   \n",
       "4                     a train is coming on a rail road   A89R5XGMHOTJE   \n",
       "5    a tricolor cat is sitting in front of a partia...   A89R5XGMHOTJE   \n",
       "6    a closed shower door with crackled glass encas...   A89R5XGMHOTJE   \n",
       "7    a tennis player in a white shirt and tan short...   A89R5XGMHOTJE   \n",
       "8    a bathroom with a toilet and sink and with a r...   A89R5XGMHOTJE   \n",
       "9    dozens of people line the gray sidewalks adjac...  A1DKVUTOBPQH11   \n",
       "10   a newly wedded couple cutting there wedding ca...  A1DKVUTOBPQH11   \n",
       "11   a man with blonde hair and a white and black w...  A1DKVUTOBPQH11   \n",
       "12   people are standing on the beach flying colorf...  A1DKVUTOBPQH11   \n",
       "13                    a train is coming on a rail road  A1DKVUTOBPQH11   \n",
       "14   a tricolor cat is sitting in front of a partia...  A1DKVUTOBPQH11   \n",
       "15   a closed shower door with crackled glass encas...  A1DKVUTOBPQH11   \n",
       "16   a tennis player in a white shirt and tan short...  A1DKVUTOBPQH11   \n",
       "17   a bathroom with a toilet and sink and with a r...  A1DKVUTOBPQH11   \n",
       "18   dozens of people line the gray sidewalks adjac...  A1T9KDKDFO114S   \n",
       "19   a newly wedded couple cutting there wedding ca...  A1T9KDKDFO114S   \n",
       "20   a man with blonde hair and a white and black w...  A1T9KDKDFO114S   \n",
       "21   people are standing on the beach flying colorf...  A1T9KDKDFO114S   \n",
       "22                    a train is coming on a rail road  A1T9KDKDFO114S   \n",
       "23   a tricolor cat is sitting in front of a partia...  A1T9KDKDFO114S   \n",
       "24   a closed shower door with crackled glass encas...  A1T9KDKDFO114S   \n",
       "25   a tennis player in a white shirt and tan short...  A1T9KDKDFO114S   \n",
       "26   a bathroom with a toilet and sink and with a r...  A1T9KDKDFO114S   \n",
       "27   a gorgeous european city with tall gothic buil...  A23437BMZ5T1FH   \n",
       "28   a restroom containing a porcelain toilet and s...  A23437BMZ5T1FH   \n",
       "29   a family flies their kites together at a beach...  A23437BMZ5T1FH   \n",
       "..                                                 ...             ...   \n",
       "618  a brown trai  pulls into the tracka next to so...   AIZTLQM7HHQN6   \n",
       "619  a young blond man in a water suit catching a s...   AIZTLQM7HHQN6   \n",
       "620  a gray and beige cat looks upward as a half fu...   AIZTLQM7HHQN6   \n",
       "621  a man and his two children are flying multicol...   AIQT0DPRTXYYD   \n",
       "622  a man and woman getting assistance cutting the...   AIQT0DPRTXYYD   \n",
       "623  a wine glass with red wine less than half full...   AIQT0DPRTXYYD   \n",
       "624              a surfer leans forward to ride a wave   AIQT0DPRTXYYD   \n",
       "625  roger federer about to back hand a tennis ball...   AIQT0DPRTXYYD   \n",
       "626  a large street with people on the sidewalk whi...   AIQT0DPRTXYYD   \n",
       "627  a train is approaching the station and passing...   AIQT0DPRTXYYD   \n",
       "628  a white bathroom sink and toilet with a mirror...   AIQT0DPRTXYYD   \n",
       "629  a sliding glass shower door with a bath mat ha...   AIQT0DPRTXYYD   \n",
       "630  a man and his two children are flying multicol...  A33LYSCQQU1YDJ   \n",
       "631  a man and woman getting assistance cutting the...  A33LYSCQQU1YDJ   \n",
       "632  a wine glass with red wine less than half full...  A33LYSCQQU1YDJ   \n",
       "633              a surfer leans forward to ride a wave  A33LYSCQQU1YDJ   \n",
       "634  roger federer about to back hand a tennis ball...  A33LYSCQQU1YDJ   \n",
       "635  a large street with people on the sidewalk whi...  A33LYSCQQU1YDJ   \n",
       "636  a train is approaching the station and passing...  A33LYSCQQU1YDJ   \n",
       "637  a white bathroom sink and toilet with a mirror...  A33LYSCQQU1YDJ   \n",
       "638  a sliding glass shower door with a bath mat ha...  A33LYSCQQU1YDJ   \n",
       "639  a man and his two children are flying multicol...   AAASQIW3J32OL   \n",
       "640  a man and woman getting assistance cutting the...   AAASQIW3J32OL   \n",
       "641  a wine glass with red wine less than half full...   AAASQIW3J32OL   \n",
       "642              a surfer leans forward to ride a wave   AAASQIW3J32OL   \n",
       "643  roger federer about to back hand a tennis ball...   AAASQIW3J32OL   \n",
       "644  a large street with people on the sidewalk whi...   AAASQIW3J32OL   \n",
       "645  a train is approaching the station and passing...   AAASQIW3J32OL   \n",
       "646  a white bathroom sink and toilet with a mirror...   AAASQIW3J32OL   \n",
       "647  a sliding glass shower door with a bath mat ha...   AAASQIW3J32OL   \n",
       "\n",
       "     num_guesses                                       stimulus_url  \n",
       "0              1  http://images.cocodataset.org/train2017/000000...  \n",
       "1              1  http://images.cocodataset.org/train2017/000000...  \n",
       "2              1  http://images.cocodataset.org/train2017/000000...  \n",
       "3              4  http://images.cocodataset.org/train2017/000000...  \n",
       "4              6  http://images.cocodataset.org/train2017/000000...  \n",
       "5              3  http://images.cocodataset.org/train2017/000000...  \n",
       "6              1  http://images.cocodataset.org/train2017/000000...  \n",
       "7              1  http://images.cocodataset.org/train2017/000000...  \n",
       "8              1  http://images.cocodataset.org/val2017/00000043...  \n",
       "9              2  http://images.cocodataset.org/train2017/000000...  \n",
       "10             1  http://images.cocodataset.org/train2017/000000...  \n",
       "11             1  http://images.cocodataset.org/train2017/000000...  \n",
       "12             3  http://images.cocodataset.org/train2017/000000...  \n",
       "13             7  http://images.cocodataset.org/train2017/000000...  \n",
       "14             2  http://images.cocodataset.org/train2017/000000...  \n",
       "15             1  http://images.cocodataset.org/train2017/000000...  \n",
       "16             1  http://images.cocodataset.org/train2017/000000...  \n",
       "17             1  http://images.cocodataset.org/val2017/00000043...  \n",
       "18             2  http://images.cocodataset.org/train2017/000000...  \n",
       "19             1  http://images.cocodataset.org/train2017/000000...  \n",
       "20             1  http://images.cocodataset.org/train2017/000000...  \n",
       "21             2  http://images.cocodataset.org/train2017/000000...  \n",
       "22            10  http://images.cocodataset.org/train2017/000000...  \n",
       "23             1  http://images.cocodataset.org/train2017/000000...  \n",
       "24             2  http://images.cocodataset.org/train2017/000000...  \n",
       "25             2  http://images.cocodataset.org/train2017/000000...  \n",
       "26             1  http://images.cocodataset.org/val2017/00000043...  \n",
       "27             1  http://images.cocodataset.org/train2017/000000...  \n",
       "28             5  http://images.cocodataset.org/val2017/00000043...  \n",
       "29             1  http://images.cocodataset.org/train2017/000000...  \n",
       "..           ...                                                ...  \n",
       "618            1  http://images.cocodataset.org/train2017/000000...  \n",
       "619            1  http://images.cocodataset.org/train2017/000000...  \n",
       "620            2  http://images.cocodataset.org/train2017/000000...  \n",
       "621            1  http://images.cocodataset.org/train2017/000000...  \n",
       "622            1  http://images.cocodataset.org/train2017/000000...  \n",
       "623            1  http://images.cocodataset.org/train2017/000000...  \n",
       "624            4  http://images.cocodataset.org/train2017/000000...  \n",
       "625            6  http://images.cocodataset.org/train2017/000000...  \n",
       "626            1  http://images.cocodataset.org/train2017/000000...  \n",
       "627            1  http://images.cocodataset.org/train2017/000000...  \n",
       "628            1  http://images.cocodataset.org/val2017/00000043...  \n",
       "629            4  http://images.cocodataset.org/train2017/000000...  \n",
       "630            1  http://images.cocodataset.org/train2017/000000...  \n",
       "631            1  http://images.cocodataset.org/train2017/000000...  \n",
       "632            1  http://images.cocodataset.org/train2017/000000...  \n",
       "633            1  http://images.cocodataset.org/train2017/000000...  \n",
       "634            3  http://images.cocodataset.org/train2017/000000...  \n",
       "635            2  http://images.cocodataset.org/train2017/000000...  \n",
       "636            1  http://images.cocodataset.org/train2017/000000...  \n",
       "637            1  http://images.cocodataset.org/val2017/00000043...  \n",
       "638            5  http://images.cocodataset.org/train2017/000000...  \n",
       "639            1  http://images.cocodataset.org/train2017/000000...  \n",
       "640            1  http://images.cocodataset.org/train2017/000000...  \n",
       "641            1  http://images.cocodataset.org/train2017/000000...  \n",
       "642            1  http://images.cocodataset.org/train2017/000000...  \n",
       "643            5  http://images.cocodataset.org/train2017/000000...  \n",
       "644            1  http://images.cocodataset.org/train2017/000000...  \n",
       "645            1  http://images.cocodataset.org/train2017/000000...  \n",
       "646            1  http://images.cocodataset.org/val2017/00000043...  \n",
       "647            5  http://images.cocodataset.org/train2017/000000...  \n",
       "\n",
       "[648 rows x 4 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses_results = []\n",
    "for i, row in batched_guesses_results.iterrows():\n",
    "    for page in json.loads(row['Answer.results']):\n",
    "#         print(page)\n",
    "        guess_indices = [guess['idx'] for guess in page['guesses']]\n",
    "#         guessed_right_sometime = [row.correctIdx in row.guess_indices for row in mturk_nafc_results.itertuples()]\n",
    "        stimulus_url = [img for img in page['images'] if img['isCorrect']][0]['url']\n",
    "        guesses_results.append(dict(\n",
    "            guesser=row['WorkerId'],\n",
    "            description=page['description'],\n",
    "            num_guesses=len(guess_indices),\n",
    "            stimulus_url=stimulus_url))\n",
    "pd.DataFrame(guesses_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = list((paths.data / 'mturk').glob('*-guesstheimage.csv'))\n",
    "mturk_nafc_results = (\n",
    "    pd.concat([pd.read_csv(str(f)) for f in result_files], axis=0, ignore_index=True)\n",
    "    if len(result_files)\n",
    "    else pd.DataFrame([], columns=['Answer.description', 'Answer.guesses', 'Input.correct_idx']))\n",
    "mturk_nafc_results = mturk_nafc_results.rename(columns={'Input.correct_idx': 'correctIdx'})\n",
    "print(\"Loaded\", len(mturk_nafc_results), \"guess task results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['guesses'] = mturk_nafc_results['Answer.guesses'].map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['guess_indices'] = [[guess['idx'] for guess in row.guesses] for row in mturk_nafc_results.itertuples()]\n",
    "mturk_nafc_results['guessed_right_sometime'] = [row.correctIdx in row.guess_indices for row in mturk_nafc_results.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results = mturk_nafc_results[mturk_nafc_results['guessed_right_sometime']]\n",
    "print(len(mturk_nafc_results), \"remain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['num_guesses'] = [row.guess_indices.index(row.correctIdx) + 1 for row in mturk_nafc_results.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_responses_by_caption = mturk_nafc_results.groupby('Answer.description').size().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tasks remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_todo = [trial for trial in trial_data if num_responses_by_caption.get(trial['text'], 0) < 3]\n",
    "len(trial_data), len(trials_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while True:\n",
    "    out_fn = paths.data / 'anno-tasks' / f'{datetime.date.today().isoformat()}-{i}-nAFC.csv'\n",
    "    if not out_fn.exists():\n",
    "        break\n",
    "    i += 1\n",
    "out_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(1234)\n",
    "pd.DataFrame([make_task(trial, rs) for trial in trials_todo]).to_csv(out_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the actual HIT text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "html = Template(open(paths.top_level / 'HITs' / '2018-05-04-image-description-match.jinja.html').read()).render(dict(\n",
    "    description='${description}',\n",
    "    images=['${image_%d_url}' % i for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html2 = html\n",
    "trial = trial_data[18+7*9]\n",
    "for k, v in make_task(trial['stimulus'], trial['text']).items():\n",
    "    html2 = html2.replace('${' + k + '}', str(v))\n",
    "HTML('<div style=\"height: 1000px; position: relative;\">'+html2+'</div>')\n",
    "# print(html2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.Popen('pbcopy', stdin=subprocess.PIPE).communicate(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MTurk results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results.groupby('Answer.description').num_guesses.mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mturk_nafc_results['WorkTimeInSeconds'][mturk_nafc_results['WorkTimeInSeconds'] < 5*60] / 60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(mturk_nafc_results['WorkTimeInSeconds'] / 60) * 9/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    15 # participants\n",
    "    * 3 # conditions per participant\n",
    "    * 3 # captions per condition\n",
    "    - 1 # image not shown\n",
    ") * 3 # annotators per description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    * .24 # reward per annotator\n",
    ") * 1.2 # MTurk 20% fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the same worker see the same target image multiple times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data.iterrows())[1]['Input.image_0_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['target_image_url'] = [row['Input.image_'+str(row['correctIdx'])+\"_url\"] for _, row in mturk_nafc_results.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_worker_image_pairs = set()\n",
    "for worker_id, data in mturk_nafc_results.groupby('WorkerId'):\n",
    "    target_images = [row['target_image_url'] for _, row in data.iterrows()]\n",
    "    if len(target_images) != len(set(target_images)):\n",
    "#         print(worker_id)\n",
    "        value_counts = pd.Series(target_images).value_counts()\n",
    "        value_counts = value_counts[value_counts > 1]\n",
    "#         print(value_counts)\n",
    "        for img in value_counts.index:\n",
    "            bad_worker_image_pairs.add((worker_id, img))\n",
    "bad_worker_image_pairs\n",
    "\n",
    "annotation_row_is_bad = [\n",
    "    (row['WorkerId'], row['target_image_url']) in bad_worker_image_pairs\n",
    "    for _, row in mturk_nafc_results.iterrows()\n",
    "]\n",
    "mturk_nafc_results['row_is_bad'] = annotation_row_is_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['row_is_bad'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_results = mturk_nafc_results[~mturk_nafc_results['row_is_bad']].rename(columns={'Answer.description': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mturk_nafc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(guess_results), len(trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    guess_results.rename(columns={'WorkerId': 'guesser'}).drop(['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'RequesterAnnotation', 'guesses'], axis=1),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guesser': 'A89R5XGMHOTJE',\n",
       " 'description': 'dozens of people line the gray sidewalks adjacent to tall buildings as a two deck bus and vehicle progress on the street',\n",
       " 'num_guesses': 1,\n",
       " 'stimulus_url': 'http://images.cocodataset.org/train2017/000000247576.jpg'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>condition</th>\n",
       "      <th>idx</th>\n",
       "      <th>idx_in_block</th>\n",
       "      <th>writer</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>text</th>\n",
       "      <th>guesser</th>\n",
       "      <th>num_guesses</th>\n",
       "      <th>stimulus_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>275449</td>\n",
       "      <td>a yellow cat with strips is setting on a place...</td>\n",
       "      <td>A1TARNH07A75CG</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>275449</td>\n",
       "      <td>a yellow cat with strips is setting on a place...</td>\n",
       "      <td>A3GEL5PWFIK05S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>275449</td>\n",
       "      <td>a yellow cat with strips is setting on a place...</td>\n",
       "      <td>A185P3B2MC2K83</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>396295</td>\n",
       "      <td>a small bath with a shower with a blue mat on ...</td>\n",
       "      <td>A3VENK02U0X16N</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>396295</td>\n",
       "      <td>a small bath with a shower with a blue mat on ...</td>\n",
       "      <td>AJRY9ALX8069Y</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>396295</td>\n",
       "      <td>a small bath with a shower with a blue mat on ...</td>\n",
       "      <td>A3L2FPKRD46FRW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bath room with a white toilet and a white wa...</td>\n",
       "      <td>A2ECXGDFC0NJEL</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bath room with a white toilet and a white wa...</td>\n",
       "      <td>A3FCZNB9E8K3CX</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bath room with a white toilet and a white wa...</td>\n",
       "      <td>AIZTLQM7HHQN6</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>227326</td>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>227326</td>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>227326</td>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>200451</td>\n",
       "      <td>a group of people flying kites on a beach and ...</td>\n",
       "      <td>A2P76QVLSGJR45</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>200451</td>\n",
       "      <td>a group of people flying kites on a beach and ...</td>\n",
       "      <td>A2ZNOMZ35LKY8Q</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>200451</td>\n",
       "      <td>a group of people flying kites on a beach and ...</td>\n",
       "      <td>A1USR9JCAMDGM3</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train station with three building to the lef...</td>\n",
       "      <td>A18XFOKU5G1OL1</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train station with three building to the lef...</td>\n",
       "      <td>A2GZ00IMOT6L3X</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train station with three building to the lef...</td>\n",
       "      <td>A2KSAAQBU5R0F6</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>247576</td>\n",
       "      <td>a busy city street with cars and people along ...</td>\n",
       "      <td>A1NSHNH3MNFRGW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>247576</td>\n",
       "      <td>a busy city street with cars and people along ...</td>\n",
       "      <td>A1ZN6V0PU8VVAH</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>247576</td>\n",
       "      <td>a busy city street with cars and people along ...</td>\n",
       "      <td>A125KW9P18V5Z1</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>71815</td>\n",
       "      <td>a tennis player is trying hard to return the b...</td>\n",
       "      <td>A23437BMZ5T1FH</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>71815</td>\n",
       "      <td>a tennis player is trying hard to return the b...</td>\n",
       "      <td>A2YGAEODJ5SSF6</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>71815</td>\n",
       "      <td>a tennis player is trying hard to return the b...</td>\n",
       "      <td>A1T208Y507O4RS</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer is riding a wave the water looks so r...</td>\n",
       "      <td>A1U5BE8XJRXKW3</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer is riding a wave the water looks so r...</td>\n",
       "      <td>A30YUB0WTMKX73</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer is riding a wave the water looks so r...</td>\n",
       "      <td>AAYL7UAXO9E4T</td>\n",
       "      <td>10</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36x2r3</td>\n",
       "      <td>275449</td>\n",
       "      <td>a tricolor cat is sitting in front of a partia...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36x2r3</td>\n",
       "      <td>275449</td>\n",
       "      <td>a tricolor cat is sitting in front of a partia...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36x2r3</td>\n",
       "      <td>275449</td>\n",
       "      <td>a tricolor cat is sitting in front of a partia...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>559x69</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer wearing a wetsuit is catching a wave.</td>\n",
       "      <td>A214HWAW1PYWO8</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>559x69</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer wearing a wetsuit is catching a wave.</td>\n",
       "      <td>A3L8LSM7V7KX3T</td>\n",
       "      <td>7</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>559x69</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer wearing a wetsuit is catching a wave.</td>\n",
       "      <td>A4T4577P6JL6R</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>275449</td>\n",
       "      <td>a chubby faced brown and yellow tabby cat look...</td>\n",
       "      <td>A3BI0AX5T5GVO3</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>275449</td>\n",
       "      <td>a chubby faced brown and yellow tabby cat look...</td>\n",
       "      <td>A13PXTFOXDCKBF</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>275449</td>\n",
       "      <td>a chubby faced brown and yellow tabby cat look...</td>\n",
       "      <td>A1CA46R2A6TV9W</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>396295</td>\n",
       "      <td>a towel folded over a rack on sliding shower d...</td>\n",
       "      <td>A2S75O867RJG0I</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>396295</td>\n",
       "      <td>a towel folded over a rack on sliding shower d...</td>\n",
       "      <td>A1ZB2NY0F9QNP0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>396295</td>\n",
       "      <td>a towel folded over a rack on sliding shower d...</td>\n",
       "      <td>A12A5GVJX5RZC4</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bathroom with a white sink and white toilet....</td>\n",
       "      <td>A1BIN5R8FF4FQR</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bathroom with a white sink and white toilet....</td>\n",
       "      <td>A29VL3MZE7YPBZ</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0</td>\n",
       "      <td>norecs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bathroom with a white sink and white toilet....</td>\n",
       "      <td>A3IGZ3N6TNPXUU</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>227326</td>\n",
       "      <td>a bride and groom cut a wedding cake together</td>\n",
       "      <td>A12BTFPKFKKD2I</td>\n",
       "      <td>7</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>227326</td>\n",
       "      <td>a bride and groom cut a wedding cake together</td>\n",
       "      <td>A3NZAEOHAO5LT6</td>\n",
       "      <td>8</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>227326</td>\n",
       "      <td>a bride and groom cut a wedding cake together</td>\n",
       "      <td>A2K2R8TF8Q2YZU</td>\n",
       "      <td>8</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>200451</td>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A23437BMZ5T1FH</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>200451</td>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A2YGAEODJ5SSF6</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>200451</td>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A1T208Y507O4RS</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train is traveling down the tracks near a ra...</td>\n",
       "      <td>A26M997VYVK0E6</td>\n",
       "      <td>7</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train is traveling down the tracks near a ra...</td>\n",
       "      <td>A3JT2I4GGKDYPE</td>\n",
       "      <td>10</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train is traveling down the tracks near a ra...</td>\n",
       "      <td>A2MGH3MBXMKD96</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>247576</td>\n",
       "      <td>a double decker bus traveling down the middle ...</td>\n",
       "      <td>A3VENK02U0X16N</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>247576</td>\n",
       "      <td>a double decker bus traveling down the middle ...</td>\n",
       "      <td>AJRY9ALX8069Y</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>247576</td>\n",
       "      <td>a double decker bus traveling down the middle ...</td>\n",
       "      <td>A3L2FPKRD46FRW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>71815</td>\n",
       "      <td>a male tennis player hits the ball with his ra...</td>\n",
       "      <td>A1NSHNH3MNFRGW</td>\n",
       "      <td>8</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>71815</td>\n",
       "      <td>a male tennis player hits the ball with his ra...</td>\n",
       "      <td>A1ZN6V0PU8VVAH</td>\n",
       "      <td>6</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>71815</td>\n",
       "      <td>a male tennis player hits the ball with his ra...</td>\n",
       "      <td>A125KW9P18V5Z1</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer rides the crest of the waves in the o...</td>\n",
       "      <td>AZ9BU8QI4YKF3</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer rides the crest of the waves in the o...</td>\n",
       "      <td>AR1IWBDA7MC86</td>\n",
       "      <td>10</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer rides the crest of the waves in the o...</td>\n",
       "      <td>A2WC2NO555XU3J</td>\n",
       "      <td>6</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     block condition  idx  idx_in_block  writer  stimulus  \\\n",
       "0        0   general    0             0  jvccx2    275449   \n",
       "1        0   general    0             0  jvccx2    275449   \n",
       "2        0   general    0             0  jvccx2    275449   \n",
       "3        0   general    1             1  jvccx2    396295   \n",
       "4        0   general    1             1  jvccx2    396295   \n",
       "5        0   general    1             1  jvccx2    396295   \n",
       "6        0   general    2             2  jvccx2    431140   \n",
       "7        0   general    2             2  jvccx2    431140   \n",
       "8        0   general    2             2  jvccx2    431140   \n",
       "9        1    norecs    3             0  jvccx2    227326   \n",
       "10       1    norecs    3             0  jvccx2    227326   \n",
       "11       1    norecs    3             0  jvccx2    227326   \n",
       "12       1    norecs    4             1  jvccx2    200451   \n",
       "13       1    norecs    4             1  jvccx2    200451   \n",
       "14       1    norecs    4             1  jvccx2    200451   \n",
       "15       1    norecs    5             2  jvccx2    223777   \n",
       "16       1    norecs    5             2  jvccx2    223777   \n",
       "17       1    norecs    5             2  jvccx2    223777   \n",
       "18       2  specific    6             0  jvccx2    247576   \n",
       "19       2  specific    6             0  jvccx2    247576   \n",
       "20       2  specific    6             0  jvccx2    247576   \n",
       "21       2  specific    7             1  jvccx2     71815   \n",
       "22       2  specific    7             1  jvccx2     71815   \n",
       "23       2  specific    7             1  jvccx2     71815   \n",
       "24       2  specific    8             2  jvccx2    240275   \n",
       "25       2  specific    8             2  jvccx2    240275   \n",
       "26       2  specific    8             2  jvccx2    240275   \n",
       "27       0    norecs    0             0  36x2r3    275449   \n",
       "28       0    norecs    0             0  36x2r3    275449   \n",
       "29       0    norecs    0             0  36x2r3    275449   \n",
       "..     ...       ...  ...           ...     ...       ...   \n",
       "618      2  specific    8             2  559x69    240275   \n",
       "619      2  specific    8             2  559x69    240275   \n",
       "620      2  specific    8             2  559x69    240275   \n",
       "621      0    norecs    0             0  gvwqp6    275449   \n",
       "622      0    norecs    0             0  gvwqp6    275449   \n",
       "623      0    norecs    0             0  gvwqp6    275449   \n",
       "624      0    norecs    1             1  gvwqp6    396295   \n",
       "625      0    norecs    1             1  gvwqp6    396295   \n",
       "626      0    norecs    1             1  gvwqp6    396295   \n",
       "627      0    norecs    2             2  gvwqp6    431140   \n",
       "628      0    norecs    2             2  gvwqp6    431140   \n",
       "629      0    norecs    2             2  gvwqp6    431140   \n",
       "630      1   general    3             0  gvwqp6    227326   \n",
       "631      1   general    3             0  gvwqp6    227326   \n",
       "632      1   general    3             0  gvwqp6    227326   \n",
       "633      1   general    4             1  gvwqp6    200451   \n",
       "634      1   general    4             1  gvwqp6    200451   \n",
       "635      1   general    4             1  gvwqp6    200451   \n",
       "636      1   general    5             2  gvwqp6    223777   \n",
       "637      1   general    5             2  gvwqp6    223777   \n",
       "638      1   general    5             2  gvwqp6    223777   \n",
       "639      2  specific    6             0  gvwqp6    247576   \n",
       "640      2  specific    6             0  gvwqp6    247576   \n",
       "641      2  specific    6             0  gvwqp6    247576   \n",
       "642      2  specific    7             1  gvwqp6     71815   \n",
       "643      2  specific    7             1  gvwqp6     71815   \n",
       "644      2  specific    7             1  gvwqp6     71815   \n",
       "645      2  specific    8             2  gvwqp6    240275   \n",
       "646      2  specific    8             2  gvwqp6    240275   \n",
       "647      2  specific    8             2  gvwqp6    240275   \n",
       "\n",
       "                                                  text         guesser  \\\n",
       "0    a yellow cat with strips is setting on a place...  A1TARNH07A75CG   \n",
       "1    a yellow cat with strips is setting on a place...  A3GEL5PWFIK05S   \n",
       "2    a yellow cat with strips is setting on a place...  A185P3B2MC2K83   \n",
       "3    a small bath with a shower with a blue mat on ...  A3VENK02U0X16N   \n",
       "4    a small bath with a shower with a blue mat on ...   AJRY9ALX8069Y   \n",
       "5    a small bath with a shower with a blue mat on ...  A3L2FPKRD46FRW   \n",
       "6    a bath room with a white toilet and a white wa...  A2ECXGDFC0NJEL   \n",
       "7    a bath room with a white toilet and a white wa...  A3FCZNB9E8K3CX   \n",
       "8    a bath room with a white toilet and a white wa...   AIZTLQM7HHQN6   \n",
       "9    a newly wedded couple cutting there wedding ca...   A89R5XGMHOTJE   \n",
       "10   a newly wedded couple cutting there wedding ca...  A1DKVUTOBPQH11   \n",
       "11   a newly wedded couple cutting there wedding ca...  A1T9KDKDFO114S   \n",
       "12   a group of people flying kites on a beach and ...  A2P76QVLSGJR45   \n",
       "13   a group of people flying kites on a beach and ...  A2ZNOMZ35LKY8Q   \n",
       "14   a group of people flying kites on a beach and ...  A1USR9JCAMDGM3   \n",
       "15   a train station with three building to the lef...  A18XFOKU5G1OL1   \n",
       "16   a train station with three building to the lef...  A2GZ00IMOT6L3X   \n",
       "17   a train station with three building to the lef...  A2KSAAQBU5R0F6   \n",
       "18   a busy city street with cars and people along ...  A1NSHNH3MNFRGW   \n",
       "19   a busy city street with cars and people along ...  A1ZN6V0PU8VVAH   \n",
       "20   a busy city street with cars and people along ...  A125KW9P18V5Z1   \n",
       "21   a tennis player is trying hard to return the b...  A23437BMZ5T1FH   \n",
       "22   a tennis player is trying hard to return the b...  A2YGAEODJ5SSF6   \n",
       "23   a tennis player is trying hard to return the b...  A1T208Y507O4RS   \n",
       "24   a surfer is riding a wave the water looks so r...  A1U5BE8XJRXKW3   \n",
       "25   a surfer is riding a wave the water looks so r...  A30YUB0WTMKX73   \n",
       "26   a surfer is riding a wave the water looks so r...   AAYL7UAXO9E4T   \n",
       "27   a tricolor cat is sitting in front of a partia...   A89R5XGMHOTJE   \n",
       "28   a tricolor cat is sitting in front of a partia...  A1DKVUTOBPQH11   \n",
       "29   a tricolor cat is sitting in front of a partia...  A1T9KDKDFO114S   \n",
       "..                                                 ...             ...   \n",
       "618     a surfer wearing a wetsuit is catching a wave.  A214HWAW1PYWO8   \n",
       "619     a surfer wearing a wetsuit is catching a wave.  A3L8LSM7V7KX3T   \n",
       "620     a surfer wearing a wetsuit is catching a wave.   A4T4577P6JL6R   \n",
       "621  a chubby faced brown and yellow tabby cat look...  A3BI0AX5T5GVO3   \n",
       "622  a chubby faced brown and yellow tabby cat look...  A13PXTFOXDCKBF   \n",
       "623  a chubby faced brown and yellow tabby cat look...  A1CA46R2A6TV9W   \n",
       "624  a towel folded over a rack on sliding shower d...  A2S75O867RJG0I   \n",
       "625  a towel folded over a rack on sliding shower d...  A1ZB2NY0F9QNP0   \n",
       "626  a towel folded over a rack on sliding shower d...  A12A5GVJX5RZC4   \n",
       "627  a bathroom with a white sink and white toilet....  A1BIN5R8FF4FQR   \n",
       "628  a bathroom with a white sink and white toilet....  A29VL3MZE7YPBZ   \n",
       "629  a bathroom with a white sink and white toilet....  A3IGZ3N6TNPXUU   \n",
       "630      a bride and groom cut a wedding cake together  A12BTFPKFKKD2I   \n",
       "631      a bride and groom cut a wedding cake together  A3NZAEOHAO5LT6   \n",
       "632      a bride and groom cut a wedding cake together  A2K2R8TF8Q2YZU   \n",
       "633  a family flies their kites together at a beach...  A23437BMZ5T1FH   \n",
       "634  a family flies their kites together at a beach...  A2YGAEODJ5SSF6   \n",
       "635  a family flies their kites together at a beach...  A1T208Y507O4RS   \n",
       "636  a train is traveling down the tracks near a ra...  A26M997VYVK0E6   \n",
       "637  a train is traveling down the tracks near a ra...  A3JT2I4GGKDYPE   \n",
       "638  a train is traveling down the tracks near a ra...  A2MGH3MBXMKD96   \n",
       "639  a double decker bus traveling down the middle ...  A3VENK02U0X16N   \n",
       "640  a double decker bus traveling down the middle ...   AJRY9ALX8069Y   \n",
       "641  a double decker bus traveling down the middle ...  A3L2FPKRD46FRW   \n",
       "642  a male tennis player hits the ball with his ra...  A1NSHNH3MNFRGW   \n",
       "643  a male tennis player hits the ball with his ra...  A1ZN6V0PU8VVAH   \n",
       "644  a male tennis player hits the ball with his ra...  A125KW9P18V5Z1   \n",
       "645  a surfer rides the crest of the waves in the o...   AZ9BU8QI4YKF3   \n",
       "646  a surfer rides the crest of the waves in the o...   AR1IWBDA7MC86   \n",
       "647  a surfer rides the crest of the waves in the o...  A2WC2NO555XU3J   \n",
       "\n",
       "     num_guesses                                       stimulus_url  \n",
       "0              1  http://images.cocodataset.org/train2017/000000...  \n",
       "1              1  http://images.cocodataset.org/train2017/000000...  \n",
       "2              1  http://images.cocodataset.org/train2017/000000...  \n",
       "3              1  http://images.cocodataset.org/train2017/000000...  \n",
       "4              1  http://images.cocodataset.org/train2017/000000...  \n",
       "5              1  http://images.cocodataset.org/train2017/000000...  \n",
       "6              2  http://images.cocodataset.org/val2017/00000043...  \n",
       "7              2  http://images.cocodataset.org/val2017/00000043...  \n",
       "8              2  http://images.cocodataset.org/val2017/00000043...  \n",
       "9              1  http://images.cocodataset.org/train2017/000000...  \n",
       "10             1  http://images.cocodataset.org/train2017/000000...  \n",
       "11             1  http://images.cocodataset.org/train2017/000000...  \n",
       "12             4  http://images.cocodataset.org/train2017/000000...  \n",
       "13             1  http://images.cocodataset.org/train2017/000000...  \n",
       "14             2  http://images.cocodataset.org/train2017/000000...  \n",
       "15             1  http://images.cocodataset.org/train2017/000000...  \n",
       "16             1  http://images.cocodataset.org/train2017/000000...  \n",
       "17             1  http://images.cocodataset.org/train2017/000000...  \n",
       "18             1  http://images.cocodataset.org/train2017/000000...  \n",
       "19             1  http://images.cocodataset.org/train2017/000000...  \n",
       "20             1  http://images.cocodataset.org/train2017/000000...  \n",
       "21             1  http://images.cocodataset.org/train2017/000000...  \n",
       "22             1  http://images.cocodataset.org/train2017/000000...  \n",
       "23             1  http://images.cocodataset.org/train2017/000000...  \n",
       "24             3  http://images.cocodataset.org/train2017/000000...  \n",
       "25             2  http://images.cocodataset.org/train2017/000000...  \n",
       "26            10  http://images.cocodataset.org/train2017/000000...  \n",
       "27             3  http://images.cocodataset.org/train2017/000000...  \n",
       "28             2  http://images.cocodataset.org/train2017/000000...  \n",
       "29             1  http://images.cocodataset.org/train2017/000000...  \n",
       "..           ...                                                ...  \n",
       "618            5  http://images.cocodataset.org/train2017/000000...  \n",
       "619            7  http://images.cocodataset.org/train2017/000000...  \n",
       "620            3  http://images.cocodataset.org/train2017/000000...  \n",
       "621            1  http://images.cocodataset.org/train2017/000000...  \n",
       "622            2  http://images.cocodataset.org/train2017/000000...  \n",
       "623            1  http://images.cocodataset.org/train2017/000000...  \n",
       "624            1  http://images.cocodataset.org/train2017/000000...  \n",
       "625            1  http://images.cocodataset.org/train2017/000000...  \n",
       "626            3  http://images.cocodataset.org/train2017/000000...  \n",
       "627            1  http://images.cocodataset.org/val2017/00000043...  \n",
       "628            2  http://images.cocodataset.org/val2017/00000043...  \n",
       "629            2  http://images.cocodataset.org/val2017/00000043...  \n",
       "630            7  http://images.cocodataset.org/train2017/000000...  \n",
       "631            8  http://images.cocodataset.org/train2017/000000...  \n",
       "632            8  http://images.cocodataset.org/train2017/000000...  \n",
       "633            1  http://images.cocodataset.org/train2017/000000...  \n",
       "634            1  http://images.cocodataset.org/train2017/000000...  \n",
       "635            1  http://images.cocodataset.org/train2017/000000...  \n",
       "636            7  http://images.cocodataset.org/train2017/000000...  \n",
       "637           10  http://images.cocodataset.org/train2017/000000...  \n",
       "638            3  http://images.cocodataset.org/train2017/000000...  \n",
       "639            1  http://images.cocodataset.org/train2017/000000...  \n",
       "640            5  http://images.cocodataset.org/train2017/000000...  \n",
       "641            1  http://images.cocodataset.org/train2017/000000...  \n",
       "642            8  http://images.cocodataset.org/train2017/000000...  \n",
       "643            6  http://images.cocodataset.org/train2017/000000...  \n",
       "644            5  http://images.cocodataset.org/train2017/000000...  \n",
       "645            2  http://images.cocodataset.org/train2017/000000...  \n",
       "646           10  http://images.cocodataset.org/train2017/000000...  \n",
       "647            6  http://images.cocodataset.org/train2017/000000...  \n",
       "\n",
       "[648 rows x 10 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    pd.DataFrame(guesses_results).rename(columns={'description': 'text'}),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data.to_csv('annotator_level_data_2018-05-22.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/anaconda3/envs/py36/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: Loading required package: Matrix\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/kcarnold/anaconda3/envs/py36/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: Need help? Try the ggplot2 mailing list:\n",
      "http://groups.google.com/group/ggplot2.\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by REML ['lmerMod']\n",
       "Formula: num_guesses ~ condition + (1 | writer) + (1 | guesser) + (1 |  \n",
       "    stimulus)\n",
       "   Data: annotator_level_data\n",
       "REML criterion at convergence: 2796.064\n",
       "Random effects:\n",
       " Groups   Name        Std.Dev.\n",
       " guesser  (Intercept) 0.3940  \n",
       " writer   (Intercept) 0.5924  \n",
       " stimulus (Intercept) 0.5444  \n",
       " Residual             1.9864  \n",
       "Number of obs: 648, groups:  guesser, 72; writer, 24; stimulus, 9\n",
       "Fixed Effects:\n",
       "      (Intercept)    conditionnorecs  conditionspecific  \n",
       "           2.4894            -0.2437            -0.2058  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i annotator_level_data\n",
    "(model = lmer(num_guesses ~ condition + (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by REML ['lmerMod']\n",
       "Formula: num_guesses ~ (1 | writer) + (1 | guesser) + (1 | stimulus)\n",
       "   Data: annotator_level_data\n",
       "REML criterion at convergence: 2794.715\n",
       "Random effects:\n",
       " Groups   Name        Std.Dev.\n",
       " guesser  (Intercept) 0.4056  \n",
       " writer   (Intercept) 0.5907  \n",
       " stimulus (Intercept) 0.5415  \n",
       " Residual             1.9846  \n",
       "Number of obs: 648, groups:  guesser, 72; writer, 24; stimulus, 9\n",
       "Fixed Effects:\n",
       "(Intercept)  \n",
       "       2.34  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i annotator_level_data\n",
    "(null_model = lmer(num_guesses ~ (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(pbkrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F-test with Kenward-Roger approximation; computing time: 1.37 sec.\n",
       "large : num_guesses ~ condition + (1 | writer) + (1 | guesser) + (1 | \n",
       "    stimulus)\n",
       "small : num_guesses ~ (1 | writer) + (1 | guesser) + (1 | stimulus)\n",
       "          stat      ndf      ddf F.scaling p.value\n",
       "Ftest   0.8853   2.0000 613.4016   0.99998  0.4131\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "(kr <- KRmodcomp(model, null_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(glm.full = glmer(num_guesses ~ condition + (1|writer) + (1|target_image_url), annotator_level_data, family=poisson()))\n",
    "#  (1|guesser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "(glm.null = glmer(num_guesses ~ (1|writer) + (1|target_image_url), annotator_level_data, family=poisson()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "confint(glm.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "anova(glm.full, glm.null, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([dict(trial, specificity=specificity_lookup[trial['text'].strip()]) for trial in trial_data])\n",
    "for col in ['condition', 'participant']:\n",
    "    results[col] = results[col].astype('category')\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('condition').specificity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trial_data).sample(frac=1.0).sort_values('stimulus').to_csv('trial_data_by_stimulus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many images does this caption apply to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/kcarnold/Downloads/Submitted Captions - Sheet1.csv\").iloc[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna().copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_unique'] = (data.iloc[:,5] == '1')\n",
    "data.is_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['block', 'idx_in_block', 'condition']).is_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['participant'] = data['participant'].astype('category')\n",
    "data['condition'] = data['condition'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('condition').is_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i data\n",
    "transformed <- art(is_unique ~ condition + (1|participant), data=data)\n",
    "summary(transformed)\n",
    "anova(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = trial_data[-1]['text']\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concepts: traffic light. COCO doesn't have \"pedestian crossing sign\". There are 4330 images with traffic lights in them in COCO. That's way too much. Looking at Visual Genome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Genome synsets are potentially best, but they're sometimes inaccurate. e.g., \"18 wheeler\" is \"cyclist.n.01\". So let's consider an object a match if matches either the synset or object name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_base = pathlib.Path('/Data/VisualGenome')\n",
    "image_objects = json.load(open(vg_base / 'objects.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_by_id = {img['image_id']: img for img in image_objects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_synsets = json.load(open(vg_base / 'object_synsets.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_attributes = json.load(open(vg_base / 'attributes.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(obj_attributes), len(image_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_attributes[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_by_img = {att['image_id']: att['attributes'] for att in obj_attributes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_by_img[61514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def has_object(obj_name):\n",
    "#     return {\n",
    "#         img['image_id'] for img in image_objects\n",
    "#         if any(obj_name in '\\n'.join(obj['names']) for obj in img['objects'])\n",
    "#            }\n",
    "def has_object(imgid, obj_name):\n",
    "    return any(obj_name in '\\n'.join(obj['names']) for obj in attributes_by_img[imgid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def has_synset(obj_synset):\n",
    "#     return {\n",
    "#         img['image_id'] for img in image_objects\n",
    "#         if any(obj_synset in obj['synsets'] for obj in img['objects'])}\n",
    "def has_synset(imgid, obj_synset):\n",
    "    return any(obj_synset in obj['synsets'] for obj in attributes_by_img[imgid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_obj_with_attr(imgid, obj_name, attr):\n",
    "    return any(\n",
    "        (obj_name in '\\n'.join(obj['names'])) and (attr in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])\n",
    "\n",
    "def has_synset_with_attr(imgid, obj_synset, attr):\n",
    "    return any(\n",
    "        (obj_synset in obj['synsets']) and (attr in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])\n",
    "\n",
    "def has_obj_without_attr(imgid, obj_name, attr):\n",
    "    return any(\n",
    "        (obj_name in '\\n'.join(obj['names'])) and (attr not in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])\n",
    "\n",
    "def has_synset_without_attr(imgid, obj_synset, attr):\n",
    "    return any(\n",
    "        (obj_synset in obj['synsets']) and (attr not in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_synsets['pedestrian sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates = (\n",
    "#     (has_object('pedestrian sign') | has_object('pedestrian crossing sign') | has_object('crossing sign') | has_object('sign')) &\n",
    "#     (has_object('traffic light') | has_synset('traffic_light.n.01'))\n",
    "# )\n",
    "candidates = {\n",
    "    imgid for imgid in attributes_by_img.keys()\n",
    "    if (\n",
    "        (\n",
    "            has_object(imgid, 'pedestrian sign') |\n",
    "            has_object(imgid, 'pedestrian crossing sign') |\n",
    "            has_object(imgid, 'crossing sign') |\n",
    "            has_obj_with_attr(imgid, 'sign', 'yellow')\n",
    "        ) & (\n",
    "            has_obj_without_attr(imgid, 'traffic light', 'red') |\n",
    "            has_synset_without_attr(imgid, 'traffic_light.n.01', 'red')\n",
    "        ))}\n",
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_images(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[img['image_id'] for img in image_objects if '61514' in img.get('image_url', '')]\n",
    "#Image(img_by_id[61514]['image_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_by_id[61514]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use paired comparisons to analyze specificity and accuracy. For a target image $x$ and a fixed set of imposter images $Y$, the **specific accuracy** of a caption is the fraction of comparisons that chose $x$. \n",
    "\n",
    "We start with our dataset of paired comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [\n",
    "    \"exactly how are both the dog and the person going to fit on that skateboard?\",\n",
    "    \"the dark haired dog is trying to ride on the skateboard.\",\n",
    "    \"a person in shorts and a black dog both have one foot on a skateboard.\",\n",
    "    \"a dog with a black head and black legs and ears standing up has one black paw on a black skateboard with white wheels and a guy with black and white shoes and white socks has one foot on the skateboard also and there are bikes and other people in the background\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternatives = 'dog-and-guy-on-skateboard just-dog-on-skateboard guy-on-skateboard-holding-dog dog-and-guy-next-to-skateboard'.split()\n",
    "target = alternatives[0]\n",
    "imposters = alternatives[1:]\n",
    "applies_to = [\n",
    "    'dog-and-guy-on-skateboard dog-and-guy-next-to-skateboard'.split(),\n",
    "    'just-dog-on-skateboard'.split(),\n",
    "    'dog-and-guy-on-skateboard'.split(),\n",
    "    'dog-and-guy-on-skateboard just-dog-on-skateboard guy-on-skateboard-holding-dog dog-and-guy-next-to-skateboard'.split()\n",
    "]\n",
    "applies_to = {cap: tgts for cap, tgts in zip(captions, applies_to)}\n",
    "applies_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "pairs = [[target, imposter] for imposter in imposters]\n",
    "for pair in pairs:\n",
    "    random.shuffle(pair)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_answer_pairs_for_caption(applies, pairs):\n",
    "    outcomes = []\n",
    "    for a, b in pairs:\n",
    "        choices = []\n",
    "        if a in applies:\n",
    "            choices.append(0)\n",
    "        if b in applies:\n",
    "            choices.append(1)\n",
    "        if len(choices) == 0:\n",
    "            choices = [0, 1]\n",
    "        outcomes.append(random.choice(choices))\n",
    "    return outcomes\n",
    "fake_answer_pairs_for_caption(applies_to[captions[0]], pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_comparisons_data = []\n",
    "for caption in captions:\n",
    "    for annotator in range(5):\n",
    "        for pair, outcome in zip(pairs, fake_answer_pairs_for_caption(applies_to[caption], pairs)):\n",
    "            picked = pair[outcome]\n",
    "            fake_comparisons_data.append(dict(\n",
    "                caption=caption,\n",
    "                annotator=annotator,\n",
    "                pair=pair,\n",
    "                picked=picked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(fake_comparisons_data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['picked_correct'] = data['picked'] == 'dog-and-guy-on-skateboard'\n",
    "data.groupby('caption').picked_correct.mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a main effect of writing condition on outcome specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "    dict(participant_id=participant_id, condition=condition)\n",
    "    for participant_id in 'abc def ghi'.split() for condition in 'general specific norecs'.split()\n",
    "])\n",
    "results['participant_id'] = results['participant_id'].astype('category')\n",
    "results['condition'] = results['condition'].astype('category')\n",
    "results['specificity'] = np.random.randn(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#install.packages(\"ARTool\")\n",
    "library(ARTool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i results\n",
    "summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i results\n",
    "transformed <- art(specificity ~ condition + (1|participant), data=results)\n",
    "summary(transformed)\n",
    "anova(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

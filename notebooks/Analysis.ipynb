{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis pipeline for Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/code/textrec\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/textrec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import toolz\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<module 'textrec.analysis_util' from '/Users/kcarnold/code/textrec/src/textrec/analysis_util.py'>,\n",
       " <module 'textrec.util' from '/Users/kcarnold/code/textrec/src/textrec/util.py'>,\n",
       " <module 'textrec.notebook_util' from '/Users/kcarnold/code/textrec/src/textrec/notebook_util.py'>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textrec.paths import paths\n",
    "from textrec import analysis_util, util, notebook_util\n",
    "reload(analysis_util), reload(util), reload(notebook_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrec.notebook_util import images, id2img, id2url, show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML(show_images([images_by_split['val'][0]['cocoid']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of writing experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -m textrec.batch_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = get_participants_by_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2018-04-09', '2018-04-24', '2018-04-27', '2018-05-02-invalid', '2018-05-02-old', '2018-05-02'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(participants['2018-05-02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "h52x67\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:specific:a cat sitting next to a glass bowl, looking up to the camera\n",
      "final-0-1:specific:a shower with dirty glass doors has a beige towel hanging on the outside\n",
      "final-0-2:specific:there is no image here \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a bride and groom cutting their wedding cake, while a photographer guides them\n",
      "final-1-1:norecs:a man helping his children fly a multicolor butterfly kite on a clear day\n",
      "final-1-2:norecs:a passenger train approaching a small quaint station with a blue and white building on the background\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a busy street in a historic town with a red bus driving on the street. \n",
      "final-2-1:general:a tennis player hits a ball during a game \n",
      "final-2-2:general:a surfer riding a wave on a sunny day \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: There was no image in he third task.\n",
      "postTask-0-other: The keyboard seemed to have the words I wanted already there, on many of them all I had to do was touch the word.\n",
      "postTask-1-techDiff: None.\n",
      "postTask-1-other: It was a little more challenging this time, because there were no predicted words. Also I had to be extra careful with spelling!\n",
      "postTask-2-techDiff: No.\n",
      "postTask-2-other: This also had predicted words, but somehow I had a harder time coming up with good descriptions. The photos seemed too generic for some reason.\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 41\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: Just the fact that the third photo in keyboard 1 never loaded.\n",
      "postExp-other: It was fun! Just feel a little unsure that I will be penalized for not writing a caption for the third photo on keyboard 1. I hope that was OK. Thank you!\n",
      "\n",
      "Total time: 47.0m\n",
      "ExperimentScreen: 2094.0\n",
      "PostTaskSurvey: 276.4\n",
      "PostExpSurvey: 156.4\n",
      "Instructions: 127.3\n",
      "TaskDescription: 72.3\n",
      "Welcome: 34.8\n",
      "StudyDesc: 31.9\n",
      "IntroSurvey: 15.5\n",
      "PostPractice: 9.9\n",
      "\n",
      "jvccx2\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a yellow cat with strips is setting on a place mat  on a table behind a half of glass of red wine\n",
      "final-0-1:general:a small bath with a shower with a blue mat on the floor\n",
      "final-0-2:general:a bath room with a white toilet and a white washbasin \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a newly wedded couple cutting there wedding cake with a lady helping the bride cut the cake\n",
      "final-1-1:norecs:a group of people flying kites on a beach and its a beautiful day\n",
      "final-1-2:norecs:a train station with three building to the left it is a nice sunny day\n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a busy city street with cars and people along the streets with high-rise buildings on both sides\n",
      "final-2-1:specific:a tennis player is trying hard to return the ball oronto is written in the grass\n",
      "final-2-2:specific:a surfer is riding a wave the water looks so refreshing its a beautiful day \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None\n",
      "postTask-0-other: Fun study\n",
      "postTask-1-techDiff: None\n",
      "postTask-1-other: The key board was difficult\n",
      "postTask-2-techDiff: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 36\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: None\n",
      "postExp-other: Use  my data\n",
      "\n",
      "Total time: 34.9m\n",
      "ExperimentScreen: 1478.8\n",
      "PostTaskSurvey: 274.4\n",
      "PostExpSurvey: 125.0\n",
      "TaskDescription: 70.6\n",
      "PostPractice: 38.5\n",
      "Welcome: 36.4\n",
      "IntroSurvey: 27.0\n",
      "StudyDesc: 25.1\n",
      "Instructions: 16.6\n",
      "\n",
      "36x2r3\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a tricolor cat is sitting in front of a partially full wine glass\n",
      "final-0-1:norecs:someome is using a shower but it's hard to see due to the opaque glass\n",
      "final-0-2:norecs:a clean bathroom with a white sink near a white toilet\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:specific:a black and white photo or a large man and a woman cutting thwir wedding cake\n",
      "final-1-1:specific:colorful kites are flown above a sandy beach by two children and an adult\n",
      "final-1-2:specific:a brown trai  pulls into the tracka next to some colorful buildings\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red trolley drives through a stree surrounded by plain brick buildings. \n",
      "final-2-1:general:a tennis player is ready to hit the tennis ball across the court. \n",
      "final-2-2:general:a surfer leans forward to ride a wave\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-0-other: None\n",
      "postTask-1-techDiff: None\n",
      "postTask-1-other: None\n",
      "postTask-2-techDiff: None\n",
      "postTask-2-other: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 24\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: Mone\n",
      "postExp-other: None\n",
      "\n",
      "Total time: 10.2m\n",
      "ExperimentScreen: 332.4\n",
      "PostTaskSurvey: 92.8\n",
      "TaskDescription: 75.7\n",
      "PostExpSurvey: 46.4\n",
      "Welcome: 26.7\n",
      "StudyDesc: 16.6\n",
      "IntroSurvey: 11.9\n",
      "Instructions: 6.1\n",
      "PostPractice: 3.6\n",
      "\n",
      "gg65g6\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a car is sitting on a table behind a wine glass with red wine in it. \n",
      "final-0-1:general:i see a standing shower with two hazy sliding glass doors and a towel hanging off of one. \n",
      "final-0-2:general:its a public restroom with a white sink and toilet. \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a bride and groom are both holding onto the same knife to cut their wedding cake. \n",
      "final-1-1:norecs:kids at a beach flying colourful kites. \n",
      "final-1-2:norecs:a train is pulling into the train station. \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a busy city street with cars, a large red bus and pedestrians going about their day. \n",
      "final-2-1:specific:roger federer about to back hand a tennis ball in a tennis match. \n",
      "final-2-2:specific:a male surfer riding on his surfboard in the ocean. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None.\n",
      "postTask-1-techDiff: None.\n",
      "postTask-2-techDiff: None.\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 26\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: None.\n",
      "postExp-other: No problems, hit was fine. Really liked the third board, it was the best one by far.\n",
      "\n",
      "Total time: 17.9m\n",
      "ExperimentScreen: 623.5\n",
      "PostTaskSurvey: 179.3\n",
      "PostExpSurvey: 117.0\n",
      "TaskDescription: 63.2\n",
      "Welcome: 31.6\n",
      "StudyDesc: 25.8\n",
      "IntroSurvey: 22.0\n",
      "PostPractice: 8.2\n",
      "Instructions: 3.9\n",
      "\n",
      "692c8j\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a tabby cat standing behind a glass of wine stares at me\n",
      "final-0-1:norecs:a tan towel hangs in front of a glass shower\n",
      "final-0-2:norecs:a wrapped roll of toilet paper sits on top of a toilet in front if a metal bar and next to a porcelain sink. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a woman in a wedding dress cuts a cake with her husband and the photographer. \n",
      "final-1-1:general:a man flies a butterfly kite with his two daughters. \n",
      "final-1-2:general:a train is approaching the station and passing in front of blue and white buildings \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a double decker red bus drives down a crowded street with a car behind it. \n",
      "final-2-1:specific:a tennis player uses his backhand to swing at a tennis ball on a green and blue court \n",
      "final-2-2:specific:a blonde man in a wetsuit surfs a wave. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: No\n",
      "postTask-2-techDiff: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 27\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No \n",
      "\n",
      "Total time: 24.7m\n",
      "ExperimentScreen: 1063.2\n",
      "PostTaskSurvey: 185.6\n",
      "StudyDesc: 54.5\n",
      "Welcome: 51.7\n",
      "TaskDescription: 50.0\n",
      "PostExpSurvey: 47.3\n",
      "IntroSurvey: 17.5\n",
      "PostPractice: 8.2\n",
      "Instructions: 6.4\n",
      "\n",
      "qmwvwv\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:brown cat is crouching in the background of a glass of wine\n",
      "final-0-1:specific:brown towel is hanging on a sliding shower door\n",
      "final-0-2:specific:toilet paper roll is on top of the toilet in a mellow yellow painted bathroom \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:wedding photographer is guiding a bride and groom as to how they should cut their cake\n",
      "final-1-1:norecs:man and two girls are flying butterfly kites on a very windy and cloudy day\n",
      "final-1-2:norecs:a train passes by a series of brightly blue and white station buildings\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red two story city bus is driving in a european city with pedestrians all around \n",
      "final-2-1:general:a tennis player is about to hit the tennis ball \n",
      "final-2-2:general:a surfer in a white and black suit is leaning forward and riding a wave \n",
      "\n",
      "intro-use_predictive: No\n",
      "postTask-0-techDiff: None\n",
      "postTask-1-techDiff: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 30\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "\n",
      "Total time: 13.6m\n",
      "ExperimentScreen: 550.7\n",
      "PostTaskSurvey: 112.8\n",
      "PostExpSurvey: 48.3\n",
      "TaskDescription: 41.2\n",
      "StudyDesc: 18.9\n",
      "IntroSurvey: 17.6\n",
      "Welcome: 12.1\n",
      "PostPractice: 10.6\n",
      "Instructions: 3.9\n",
      "\n",
      "77j4mf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a glass of red wine sitting in fronf of a brown cat with brown stripes on a brown mat\n",
      "final-0-1:norecs:a beige towel hangs over the rightmost shower door both of which are wet with water\n",
      "final-0-2:norecs:a toilet with the seat down and a roll of toilet paper on top is next to a white sink\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:specific:a husband, bride and female all stand in front of a table holding a knife cutting a cake\n",
      "final-1-1:specific:two children and one adult stand on the beach holding kites and flying them into the sky \n",
      "final-1-2:specific:a train on the tracks passes a white house with blue paint before approaching another white house\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red double-decker bus passes a group of people to its lefg while a black car looks to pass\n",
      "final-2-1:general:a man with a tennis racket, white shirt and shoes holds his racket back in order to hit the ball\n",
      "final-2-2:general:a man with a white shirt and blue pants stands on a surfboard as the wave rises\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-other: Annoying \n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 23\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-other: This was very annoying\n",
      "\n",
      "Total time: 13.2m\n",
      "ExperimentScreen: 490.0\n",
      "PostTaskSurvey: 168.1\n",
      "Welcome: 43.3\n",
      "PostExpSurvey: 41.7\n",
      "TaskDescription: 24.0\n",
      "IntroSurvey: 11.3\n",
      "StudyDesc: 9.8\n",
      "PostPractice: 3.5\n",
      "Instructions: 3.3\n",
      "\n",
      "4ggxj8\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a gray and beige cat looks upward as a half full glass of wine can be seen in the foreground\n",
      "final-0-1:norecs:a closed shower door with crackled glass encases some hanging colored toiletries\n",
      "final-0-2:norecs:a white bathroom sink and toilet with a mirror and a roll of unopened toilet paper\n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a man in a tuxexo and a woman in a gown are show how to cut their wedding cake by a woman holding a camera \n",
      "final-1-1:general:a man in a red shirt and two children stand on the beach and fly kites\n",
      "final-1-2:general:an old train runs on the tracks in front of powder blue and white buildings\n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a gorgeous european city with tall gothic buildings and a red trolley on the street between them. at \n",
      "final-2-1:specific:a male tennis player in a pink shirt prepares to return a volley in toronto\n",
      "final-2-2:specific:a surfer in a full bodysuit rides a wave expertly \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-0-other: This is an outstanding HIT!\n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: I like the auto fill as it helps boost speed\n",
      "postTask-2-techDiff: No\n",
      "postTask-2-other: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 43\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "postExp-other: It went well but my initial survey responses might not be in complete alignment with my final responses on this page.  That's because seeing my captions on this page gave me a better perspective with the benefit of hindsight.  Thanks for the HIT!  I did my best and hope the data is useful!\n",
      "\n",
      "Total time: 25.7m\n",
      "ExperimentScreen: 906.9\n",
      "PostExpSurvey: 290.3\n",
      "PostTaskSurvey: 181.2\n",
      "TaskDescription: 77.7\n",
      "Welcome: 28.9\n",
      "IntroSurvey: 22.0\n",
      "StudyDesc: 21.9\n",
      "PostPractice: 6.0\n",
      "Instructions: 5.5\n",
      "\n",
      "5c39rx\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:an orange cat is laying near a wine glass with red wine\n",
      "final-0-1:specific:a rusty and dirty shower in the bathroom has a tan towel over its handle\n",
      "final-0-2:specific:there is a roll of toilet paper on the lid of the toilet in a small bathroom \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a photographer is helping the bride and groom cut the cake \n",
      "final-1-1:general:a man in a red shirt is helping his children fly a large rainbow-colored kite \n",
      "final-1-2:general:an old fashioned train is coming into the station \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a red double-decker bus is coming down the street\n",
      "final-2-1:norecs:a tennis player in a white shirt and tan shorts is about to hit back the tennis ball\n",
      "final-2-2:norecs:a surfer in a white and blue wetsuit is riding the waves\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-2-techDiff: No issues\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 29\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "\n",
      "Total time: 16.6m\n",
      "ExperimentScreen: 560.4\n",
      "PostTaskSurvey: 140.0\n",
      "Welcome: 93.3\n",
      "TaskDescription: 82.2\n",
      "PostExpSurvey: 65.9\n",
      "StudyDesc: 24.9\n",
      "IntroSurvey: 17.0\n",
      "PostPractice: 9.2\n",
      "Instructions: 5.2\n",
      "\n",
      "fvwhpc\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a cat looks up from behind a glass of red wine \n",
      "final-0-1:general:a sliding glass shower door with a bath mat hanging on it \n",
      "final-0-2:general:a view of a bathroom looking toward the toilet from behind the sink \n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a black and white picture of a bride and groom cutting their wedding cake with a photographer helping them pose \n",
      "final-1-1:specific:six kites flying in a blue sky above a field \n",
      "final-1-2:specific:a train passing a few small buildings, perhaps the station \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a red double-decker bus and car on a street running between old, ornate buildings\n",
      "final-2-1:norecs:a tennis player about to hit a tennis ball with a backhand\n",
      "final-2-2:norecs:a surfer in a wetsuit riding a fairly small wave\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: Nope\n",
      "postTask-0-other: Not yet\n",
      "postTask-1-techDiff: Nope\n",
      "postTask-1-other: Nope\n",
      "postTask-2-techDiff: Nope\n",
      "postTask-2-other: Not yet\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 41\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: Nope\n",
      "postExp-other: Can I type this one on the computer? One: I love the fact that after going to this page straight from the HIT on my computer, the page stayed synced when I went to it from my phone. There are some HITs I've done that could really benefit from that little nicety. Two: I feel like the suggestions really tend toward making me lazy, to some small extent. Having to type it all, you have to think about what to say, whereas faced with suggested options, you might say to yourself \"Yeah, that'll do.\" Three: I didn't notice much of a difference between the first two keyboards, honestly. \n",
      "\n",
      "Total time: 23.9m\n",
      "ExperimentScreen: 730.5\n",
      "PostExpSurvey: 323.3\n",
      "PostTaskSurvey: 191.3\n",
      "Welcome: 104.4\n",
      "TaskDescription: 36.0\n",
      "IntroSurvey: 18.1\n",
      "StudyDesc: 15.1\n",
      "PostPractice: 7.1\n",
      "Instructions: 5.3\n",
      "\n",
      "26w4jv\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:a cat sitting on top of the table next to a wine glass \n",
      "final-0-1:specific:a shower with a towel hanging on the handle of the door \n",
      "final-0-2:specific:a bathroom with a toilet and sink and with a roll of toilet paper on the toilet \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a man and woman getting assistance cutting their wedding cake \n",
      "final-1-1:general:a man assisting children with flying kites \n",
      "final-1-2:general:a train is traveling on the tracks through a marketplace \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a red city bus heading  down the street\n",
      "final-2-1:norecs:a man with a tennis rackett forcefully swinging at the tennis ball\n",
      "final-2-2:norecs:a man-woman gracefully riding a wave using a surfboard. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None\n",
      "postTask-0-other: None\n",
      "postTask-1-techDiff: None\n",
      "postTask-1-other: None\n",
      "postTask-2-techDiff: None\n",
      "postTask-2-other: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 37\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: None\n",
      "postExp-other: No, I really enjoyed this task ☺️\n",
      "\n",
      "Total time: 24.7m\n",
      "ExperimentScreen: 781.6\n",
      "PostTaskSurvey: 188.0\n",
      "Welcome: 156.7\n",
      "PostExpSurvey: 154.4\n",
      "TaskDescription: 88.2\n",
      "IntroSurvey: 46.4\n",
      "StudyDesc: 40.7\n",
      "PostPractice: 13.9\n",
      "Instructions: 12.7\n",
      "\n",
      "7g8xw8\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:general:a curious orange and black cat with yellow eyes is crouched on a tan sisal rug and is partly obstructed by a half full glass of red wine \n",
      "final-0-1:general:a tan towel is hanging from a chrome handle on a textured glass shower door\n",
      "final-0-2:general:in a drab yellow bathroom is a very clinical white sink with an unadorned mirror above and adjacent white toilet with a roll of toilet paper on top\n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a woman in a bridal gown stands next to a man in a tuxedo in front of a weding cake while a photographer explains how to position her hand for a photi\n",
      "final-1-1:norecs:a man in a red shirt with two children are on a beach holding a multi-colored kite while other people fly kites in the background\n",
      "final-1-2:norecs:an old train is stopped on the train tracks in front of a lovely cape cod cottage with bright blue trim and adjacent matching cottages\n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a red double decker bus is traveling down a busy european street lined with historic buildings and people on the sidewalks. \n",
      "final-2-1:specific:a tennis player is swinging his racket on a green tennis court with writing on the grass. \n",
      "final-2-2:specific:a blonde surfer in a black and white wetsuit is riding a large wave in the water. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-0-other: Was a good experience \n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: This was absolutely horrible \n",
      "postTask-2-techDiff: No\n",
      "postTask-2-other: Way better than the last one \n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 39\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "postExp-other: Everything was great. First and third were pretty equal. Second was awful.\n",
      "\n",
      "Total time: 33.7m\n",
      "ExperimentScreen: 1206.6\n",
      "Welcome: 417.2\n",
      "PostTaskSurvey: 158.6\n",
      "PostExpSurvey: 137.5\n",
      "TaskDescription: 52.0\n",
      "StudyDesc: 20.5\n",
      "IntroSurvey: 15.9\n",
      "PostPractice: 7.3\n",
      "Instructions: 4.5\n",
      "\n",
      "533r6c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a  brownish-orange cat with yellow eyes is look to his left past a glass of red wine  \n",
      "final-0-1:general:a person is taking a shower in a shower with very opaque sliding doors  \n",
      "final-0-2:general:a bathroom with one white sink and a white toilet with a toilet paper roll on the back lid sits next to the sink which has a mirror above it which shows the exact same toilet across the room \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a obvious dressed bride and groom at a wedding reception are cutting into their wedding cake with the help of the photographer whose hand is guiding theirs\n",
      "final-1-1:norecs:a man and his two children are flying multicolored kites on a sandy beach \n",
      "final-1-2:norecs:a brown colored train is parked at an outdoor train station with three blue and white buildings\n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a city view of a busy london street filled with a black car and a red double decker bus driving on the street. many people fill the sidewalk mostly the right side\n",
      "final-2-1:specific:a male tennis player is on a tennis court with the letters toronto on the mat. the man is swinging his red racket at a yellow tennis ball\n",
      "final-2-2:specific:a male surfer in a white shirt black sleeves and black pants is surfing waves on a white surfboard \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 28\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-other: Being able to not have to backspace to redo typing\n",
      "\n",
      "Total time: 67.0m\n",
      "ExperimentScreen: 1647.5\n",
      "Welcome: 855.5\n",
      "TaskDescription: 583.0\n",
      "PostTaskSurvey: 320.5\n",
      "PostExpSurvey: 241.0\n",
      "IntroSurvey: 175.9\n",
      "StudyDesc: 173.7\n",
      "PostPractice: 14.2\n",
      "Instructions: 9.2\n",
      "\n",
      "74v545\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a glass of wine in front of a cat on a mat on a table\n",
      "final-0-1:norecs:a bathroom towel hanging on a shower door with a toilet in view\n",
      "final-0-2:norecs:a restroom containing a porcelain toilet and sink. a mirror sits above the sunk on the wall. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a black and white photo of a wedding. the groom and a camerawoman are helping the bride cut the wedding cake on the table filled with glasses and chocloates. \n",
      "final-1-1:general:a family is flying several kites on a beach on a clear day. the kites are very colorful. \n",
      "final-1-2:general:the image shows a railroad track with a train on it further out in te distance. multiple white building hug the side if the track, with some woods behind them. \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:the photo shows a downtown scene of a city. there are old buildings everywhere, and a red bus is prominent in the middle of the road. many people walk down the sidewalks. \n",
      "final-2-1:specific:a tennis olayer is ready to hit the ball back to the opponent who is off screen. they are on a professional sponsored court. \n",
      "final-2-2:specific:a blonde surfer wearing a wetsuit rides an ocean wave. the water looks clear. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No difficulties here\n",
      "postTask-1-techDiff: Nope\n",
      "postTask-2-techDiff: No\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 26\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "\n",
      "Total time: 13.8m\n",
      "ExperimentScreen: 654.9\n",
      "PostTaskSurvey: 86.5\n",
      "PostExpSurvey: 52.7\n",
      "IntroSurvey: 9.6\n",
      "Instructions: 6.3\n",
      "PostPractice: 6.1\n",
      "Welcome: 5.0\n",
      "TaskDescription: 2.9\n",
      "StudyDesc: 1.3\n",
      "\n",
      "vxjcf7\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:an orange and brown cat looks at a glass of red wine\n",
      "final-0-1:general:a beige towel hangs up on the outside of an enclosed shower containing toiletries \n",
      "final-0-2:general:a toilet paper roll sits on a toilet next to a mirror and a white porcelain sink\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a bride and a groom are seen cutting a cake with a photographer in black and white \n",
      "final-1-1:specific:several multicolored kites with streamers are seen soaring above the heads of people\n",
      "final-1-2:specific:a brown train is seen at a station near some colorful buildings and trees \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:dozens of people line the gray sidewalks adjacent to tall buildings as a two deck bus and vehicle progress on the street\n",
      "final-2-1:norecs:a male tennis player wearing khacki shorts swings towards the yellow tennis ball on the green and blue court\n",
      "final-2-2:norecs:a surfer wearing black and white decends from a small wave in the blue ocean\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 34\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-other: Had to scroll to see the entire image, seems like it slowed down the task a bit. Other than that, task was fluid, progressed at a good pace.\n",
      "\n",
      "Total time: 37.8m\n",
      "ExperimentScreen: 936.1\n",
      "PostExpSurvey: 389.5\n",
      "IntroSurvey: 301.8\n",
      "Welcome: 208.4\n",
      "PostTaskSurvey: 207.4\n",
      "TaskDescription: 104.9\n",
      "StudyDesc: 72.5\n",
      "PostPractice: 39.4\n",
      "Instructions: 10.7\n",
      "\n",
      "9f5xwx\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:a cat behind a glass vase \n",
      "final-0-1:specific:a shower door \n",
      "final-0-2:specific:a bathroom with a sink and a toilet \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:an old timey wedding\n",
      "final-1-1:norecs:kites in the sky\n",
      "final-1-2:norecs:train on tracks next to homes\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:old european architecture \n",
      "final-2-1:general:man playing tennis \n",
      "final-2-2:general:man surfing \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 21\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "\n",
      "Total time: 122.4m\n",
      "ExperimentScreen: 7187.1\n",
      "PostTaskSurvey: 75.4\n",
      "PostExpSurvey: 36.7\n",
      "IntroSurvey: 11.7\n",
      "TaskDescription: 11.2\n",
      "StudyDesc: 10.6\n",
      "Welcome: 7.3\n",
      "Instructions: 3.3\n",
      "PostPractice: 2.7\n",
      "\n",
      "3267ww\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:specific:a cat is sitting behind a glass of wine\n",
      "\n",
      "final-0-1:specific:a toilet and a shower door hanging with a towel \n",
      "final-0-2:specific:a toilet with a roll of toilet paper and a sink \n",
      "practice-1:norecs:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:norecs:a bride and a groom are cutting a cake with the help of a woman\n",
      "final-1-1:norecs:one adult and two kids are playing with kites\n",
      "final-1-2:norecs:a train is coming on a rail road\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red double-decker bus driving on the road, many people walking on the sidewalk\n",
      "\n",
      "final-2-1:general:an adult is holding a tennis racket trying to hit a ball \n",
      "final-2-2:general:a man is standing on water with skis \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 1\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 2\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 28\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Fluent\n",
      "\n",
      "Total time: 11.7m\n",
      "ExperimentScreen: 502.9\n",
      "PostTaskSurvey: 100.7\n",
      "PostExpSurvey: 50.7\n",
      "IntroSurvey: 18.6\n",
      "Welcome: 11.4\n",
      "Instructions: 6.0\n",
      "TaskDescription: 5.6\n",
      "PostPractice: 5.3\n",
      "StudyDesc: 2.0\n",
      "\n",
      "wf4c3m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a wine glass with red wine less than half full and an orange striped tabby cat in the background behind the glass\n",
      "final-0-1:general:sliding glass, frosted, shower doors with a tan towel hanging on the handle and a white toilet with a blue floor rug\n",
      "final-0-2:general:a bathroom sink and mirror and toilet with a silver handle attached to the wall behind it\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven\n",
      "final-1-0:specific:a groom and bride slicing a white wedding cake on the banquet food table \n",
      "final-1-1:specific:some people on a sandy beach flying kites with a clear blue sky \n",
      "final-1-2:specific:some train tracks with a train on it traveling beside some white and blue buildings with green trees in the background and a clear blue sky \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a downtown city street and buildings with a vehicle and a bus and some people standing and walking on the sidewalk\n",
      "final-2-1:norecs:a professional tennis court with a professional tennis player hitting at a tennis ball\n",
      "final-2-2:norecs:a surfer in the ocean surfing on a wave\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No. Except what was already explained about the keyboard having to use backspace if I need to correct a word. It won't let me tsp the curser on the exact place I need to correct. But I'm assuming that's part of the keyboard experiment so I wouldn't classify that as technical difficulty. \n",
      "postTask-0-other: Pleasant and interesting experiment. \n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: N/a\n",
      "postTask-2-techDiff: I noticed the keyboard didn't offer word suggestions to choose from. \n",
      "postTask-2-other: N/a\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: Yes\n",
      "postExp-age: 46\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No. \n",
      "postExp-other: The experiment was pleasant. The keyboards one and two were very similar. I'm not sure I noticed a big difference between them. Definitely the option to pinpoint correct would be a good option as  is auto correct. But that's it that I can think of.\n",
      "\n",
      "Total time: 67.0m\n",
      "ExperimentScreen: 1730.7\n",
      "PostTaskSurvey: 712.7\n",
      "IntroSurvey: 439.3\n",
      "Welcome: 415.7\n",
      "PostExpSurvey: 394.0\n",
      "TaskDescription: 194.4\n",
      "StudyDesc: 73.7\n",
      "Instructions: 46.9\n",
      "PostPractice: 10.8\n",
      "\n",
      "7jcm37\n",
      "practice-0:general:a black cat napping on a sunny unpainted wood bench in front of a red wall \n",
      "final-0-0:general:a half full glass of red wine on a table in front of a calico cat\n",
      "\n",
      "final-0-1:general:a beige towel hanging on a translucent glass shower door\n",
      "final-0-2:general:a white toilet and a white sink with a mirror above the sink \n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a photographer holding the hand of a bride and groom as they cut their wedding cake \n",
      "final-1-1:specific:a msn helping two kids try to fly a kite on the beach \n",
      "final-1-2:specific:a train leaving a train station that has a blue and white building \n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:a double decker bus driving down a street with old architecture buildings\n",
      "final-2-1:norecs:a tennis player returning a shot on a court in the rogers centre in toronto\n",
      "final-2-2:norecs:a man with blonde hair and a white and black wetsuit surfing a wave. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-0-other: No\n",
      "postTask-1-techDiff: No\n",
      "postTask-1-other: No\n",
      "postTask-2-techDiff: No\n",
      "postTask-2-other: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 3\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 46\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No\n",
      "postExp-other: It went smooth no issues \n",
      "\n",
      "Total time: 19.5m\n",
      "ExperimentScreen: 726.8\n",
      "PostTaskSurvey: 126.8\n",
      "PostExpSurvey: 87.7\n",
      "Welcome: 79.8\n",
      "TaskDescription: 74.6\n",
      "IntroSurvey: 36.2\n",
      "StudyDesc: 19.7\n",
      "PostPractice: 9.0\n",
      "Instructions: 8.5\n",
      "\n",
      "cf9p8m\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a brown and tan cat lays behind a glass of red wine\n",
      "final-0-1:norecs:a beige towel sits on a glass shower door\n",
      "final-0-2:norecs:an unopened roll of toilet tissue rests upon a white toilet\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a woman in black helps a bride and groom cut into their wedding cake\n",
      "final-1-1:specific:families stand around by the water flying kites on a sunny day\n",
      "final-1-2:specific:a train sits on a set of tracks inbetween two platforms resting next to three blue and white buildings\n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a red double-decker bus driving down a street next to tall buildings and a cloudy sky in london.\n",
      "final-2-1:general:a man is standing in a field with a tennins racket swinging at a ball\n",
      "final-2-2:general:a blonde haired man surfs on a surfboard in the ocean \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: None\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 30\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Fluent\n",
      "postExp-other: Everything went smoothly. Thank you\n",
      "\n",
      "Total time: 32.3m\n",
      "Welcome: 1182.9\n",
      "ExperimentScreen: 462.9\n",
      "PostTaskSurvey: 162.5\n",
      "PostExpSurvey: 44.9\n",
      "TaskDescription: 43.2\n",
      "IntroSurvey: 18.3\n",
      "StudyDesc: 16.2\n",
      "Instructions: 3.1\n",
      "PostPractice: 2.6\n",
      "\n",
      "phqcw9\n",
      "practice-0:specific:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:specific:a curious cat sits perched upon a table, next to a glass of wine\n",
      "final-0-1:specific:a closed wavy glass door in the bathroom peers intk the walk in shower \n",
      "final-0-2:specific:a toilet paper sits on top of a toilet next to the sink, in a plain bathroom \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a black-and-white picture of a young couple cuttinf the wedding cake with the help of a young photographer at the wedding event\n",
      "final-1-1:general:two children with an adult flying kites on the beach around others doing the same in the afternoon \n",
      "final-1-2:general:a landscape of a train stop with an old-looking brownish train and a few brightly colored buildings to one side\n",
      "practice-2:norecs:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:norecs:looking down a london street on a crowded evening with a london double bus in clear focus and old-style buildings next to each other on both sides\n",
      "final-2-1:norecs:roger federer moves towards the tennis ball, intently ready to smack it and win\n",
      "final-2-2:norecs:a young blond man in a water suit catching a small wave on his surfboard\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: I did not\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 039\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "\n",
      "Total time: 14.5m\n",
      "ExperimentScreen: 629.0\n",
      "PostTaskSurvey: 77.6\n",
      "TaskDescription: 73.5\n",
      "PostExpSurvey: 50.3\n",
      "StudyDesc: 14.6\n",
      "IntroSurvey: 11.6\n",
      "Instructions: 4.7\n",
      "Welcome: 4.6\n",
      "PostPractice: 4.4\n",
      "\n",
      "5jj59g\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a cat sitting on a placemat on a table behind a wineglass\n",
      "final-0-1:norecs:a closed shower with a pattern on the door making it hard to see inside\n",
      "final-0-2:norecs:a sink, mirror and toilet, all in white with a roll of toilet paper on the toilet\n",
      "practice-1:specific:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:specific:a bride and groom cutting a cake with the photographer showing them how to cut the four tier cake\n",
      "final-1-1:specific:a man and two children about to fly kites with people in the background flying kites above the beach \n",
      "final-1-2:specific:an old train about to arrive at a station stop with no people present \n",
      "practice-2:general:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:general:a large street with people on the sidewalk while a red double decker bus approaches a pedestrian crossing. \n",
      "final-2-1:general:a tennis player on the court about to swing and hit a ball appproaching him\n",
      "final-2-2:general:a surfer on a a surfboard riding wave in the ocean\n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No issues\n",
      "postTask-1-techDiff: No issues\n",
      "postTask-2-techDiff: No issues\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 2\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 2\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 2\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 37\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-techDiff: No issues\n",
      "\n",
      "Total time: 12.8m\n",
      "ExperimentScreen: 473.5\n",
      "PostTaskSurvey: 145.6\n",
      "PostExpSurvey: 52.1\n",
      "TaskDescription: 48.5\n",
      "StudyDesc: 22.3\n",
      "IntroSurvey: 11.9\n",
      "Welcome: 7.5\n",
      "Instructions: 3.9\n",
      "PostPractice: 3.6\n",
      "\n",
      "gw3w72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a tabby cat is sitting in front of a wine glass\n",
      "final-0-1:norecs:the doors to the shower are closed and made of glass you can partially see through. \n",
      "final-0-2:norecs:the mirror shows there are more than one toliets in this bathroom. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a woman is standing next to a couple in front of a cake with a knife in it and holding the other womans hands\n",
      "final-1-1:general:people are standing on the beach flying colorful kites \n",
      "final-1-2:general:there is a train stopped at a train station platform \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:there are people walking down the street with a red double decker bus in the middle of the street \n",
      "final-2-1:specific:the tennis player is swinging his racket at a tennis ball in front of him. \n",
      "final-2-2:specific:a man riding a wave on top of a surfboard in the middle of the ocean with his surfboard \n",
      "\n",
      "intro-use_predictive: No\n",
      "postTask-0-techDiff: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 41\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "postExp-other: There were no problems in taking this study\n",
      "\n",
      "Total time: 18.1m\n",
      "ExperimentScreen: 665.1\n",
      "PostTaskSurvey: 148.7\n",
      "PostExpSurvey: 109.0\n",
      "TaskDescription: 86.5\n",
      "StudyDesc: 25.5\n",
      "Welcome: 21.0\n",
      "IntroSurvey: 19.3\n",
      "PostPractice: 8.1\n",
      "Instructions: 4.5\n",
      "\n",
      "559x69\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a cat sits on a table behind a barely filled wine glass. \n",
      "final-0-1:norecs:a loofah and other items are blurry looking through an opaque shower door. \n",
      "final-0-2:norecs:a toilet has a roll of toilet paper on it, and there is a sink that matches it to the right. \n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:the photographer helps the bride and groom cut the wedding cake. \n",
      "final-1-1:general:there is one kite flying over four other kites on a blue sky. \n",
      "final-1-2:general:a train is arriving at a quaint beach side looking station. \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a double-decker bus drives through a busy city street in london. \n",
      "final-2-1:specific:a tennis player lunges across the court towards the ball with his tennis racquet. \n",
      "final-2-2:specific:a surfer wearing a wetsuit is catching a wave. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 32\n",
      "postExp-gender: Female\n",
      "postExp-english_proficiency: Native or bilingual\n",
      "\n",
      "Total time: 22.9m\n",
      "ExperimentScreen: 878.9\n",
      "PostTaskSurvey: 152.8\n",
      "TaskDescription: 143.2\n",
      "IntroSurvey: 73.1\n",
      "Instructions: 40.2\n",
      "PostExpSurvey: 35.9\n",
      "StudyDesc: 22.6\n",
      "Welcome: 14.1\n",
      "PostPractice: 10.3\n",
      "\n",
      "gvwqp6\n",
      "practice-0:norecs:a black cat napping on a sunny unpainted wood bench in front of a red wall\n",
      "final-0-0:norecs:a chubby faced brown and yellow tabby cat looks beyond a glass of red wine\n",
      "final-0-1:norecs:a towel folded over a rack on sliding shower doors\n",
      "final-0-2:norecs:a bathroom with a white sink and white toilet. a roll of unwrapped toilet paper sits on the bowl\n",
      "practice-1:general:a man with black hair and glasses placing a large turkey into an upper oven \n",
      "final-1-0:general:a bride and groom cut a wedding cake together \n",
      "final-1-1:general:a family flies their kites together at a beach in the sun \n",
      "final-1-2:general:a train is traveling down the tracks near a rail road station \n",
      "practice-2:specific:a black and red vehicle with bikes on top and people standing nearby with umbrellas. \n",
      "final-2-0:specific:a double decker bus traveling down the middle of the street in the city streets. \n",
      "final-2-1:specific:a male tennis player hits the ball with his racket on the tennis court. \n",
      "final-2-2:specific:a surfer rides the crest of the waves in the ocean. \n",
      "\n",
      "intro-use_predictive: Yes\n",
      "postTask-0-techDiff: No\n",
      "postTask-1-techDiff: No\n",
      "postTask-2-techDiff: No\n",
      "postExp-helpfulRank-specific-most: Keyboard Design 3\n",
      "postExp-helpfulRank-specific-least: Keyboard Design 1\n",
      "postExp-helpfulRank-accurate-most: Keyboard Design 3\n",
      "postExp-helpfulRank-accurate-least: Keyboard Design 1\n",
      "postExp-helpfulRank-quick-most: Keyboard Design 3\n",
      "postExp-helpfulRank-quick-least: Keyboard Design 1\n",
      "postExp-verbalized_during: No\n",
      "postExp-age: 41\n",
      "postExp-gender: Male\n",
      "postExp-english_proficiency: Fluent\n",
      "postExp-techDiff: No\n",
      "postExp-other: I really enjoyed this experiment. Well done!! Thank you for considering my data.\n",
      "\n",
      "Total time: 19.7m\n",
      "ExperimentScreen: 677.1\n",
      "PostTaskSurvey: 155.5\n",
      "TaskDescription: 127.2\n",
      "PostExpSurvey: 114.4\n",
      "IntroSurvey: 52.6\n",
      "StudyDesc: 20.6\n",
      "Welcome: 18.4\n",
      "PostPractice: 10.7\n",
      "Instructions: 6.3\n"
     ]
    }
   ],
   "source": [
    "# summarize('2018-04-27')\n",
    "summarize('2018-05-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = get_trial_data(participants['2018-05-02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in trial_data:\n",
    "    trial['text'] = trial['text'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had the wrong URL for one image when one person ran it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_data = [trial for trial in trial_data if not (trial['stimulus'] == 431140 and trial['participant'] == 'h52x67')]\n",
    "trial_data = [trial for trial in trial_data if not trial['participant'] == 'h52x67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(toolz.pluck('text', trial_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(toolz.pluck('participant', trial_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "norecs,general,specific    6\n",
       "general,norecs,specific    4\n",
       "norecs,specific,general    4\n",
       "general,specific,norecs    4\n",
       "specific,general,norecs    3\n",
       "specific,norecs,general    3\n",
       "Name: conditions, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(k, ','.join(list(toolz.pluck('condition', v))[::4])) for k,v in toolz.groupby('participant', trial_data).items()],\n",
    "             columns='participant conditions'.split()).conditions.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(trial_data).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in trial_data:\n",
    "    exclude = False\n",
    "    if trial['condition'] == 'norecs':\n",
    "        assert trial['num_tapSugg_any'] == 0\n",
    "    else:\n",
    "        if trial['num_tapSugg_any'] == 0:\n",
    "            exclude = True\n",
    "    trial['exclude'] = exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046296296296296294"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(trial_data)['exclude']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trial_data).to_csv('data/trial_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_level, experiment_level = get_survey_data(participants['2018-05-02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_level_pivot = experiment_level.pivot(index='participant', columns='name', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>accurate-least-condition</th>\n",
       "      <th>accurate-most-condition</th>\n",
       "      <th>quick-least-condition</th>\n",
       "      <th>quick-most-condition</th>\n",
       "      <th>specific-least-condition</th>\n",
       "      <th>specific-most-condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norecs</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specific</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name      accurate-least-condition  accurate-most-condition  \\\n",
       "general                          2                        4   \n",
       "norecs                          19                        2   \n",
       "specific                         4                       19   \n",
       "\n",
       "name      quick-least-condition  quick-most-condition  \\\n",
       "general                       1                     5   \n",
       "norecs                       22                     2   \n",
       "specific                      2                    18   \n",
       "\n",
       "name      specific-least-condition  specific-most-condition  \n",
       "general                          2                        6  \n",
       "norecs                          20                        2  \n",
       "specific                         3                       17  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpful_ranks = experiment_level_pivot[[col for col in experiment_level_pivot.columns if col.startswith('helpfulRank')]]\n",
    "helpful_ranks = helpful_ranks.rename(columns={col: col[len('helpfulRank-'):] for col in helpful_ranks.columns})\n",
    "helpful_ranks[[col for col in helpful_ranks.columns if col.endswith('condition')]].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>accurate-least-idx</th>\n",
       "      <th>accurate-most-idx</th>\n",
       "      <th>quick-least-idx</th>\n",
       "      <th>quick-most-idx</th>\n",
       "      <th>specific-least-idx</th>\n",
       "      <th>specific-most-idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name  accurate-least-idx  accurate-most-idx  quick-least-idx  quick-most-idx  \\\n",
       "0                     10                  6               11               7   \n",
       "1                      8                  8                7               6   \n",
       "2                      7                 11                7              12   \n",
       "\n",
       "name  specific-least-idx  specific-most-idx  \n",
       "0                      9                  7  \n",
       "1                      7                  8  \n",
       "2                      9                 10  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpful_ranks[[col for col in helpful_ranks.columns if col.endswith('idx')]].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>block</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>sys-specific</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>sys-accurate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>sys-fast</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>mental</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>physical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>temporal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>performance</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>effort</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>frustration</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>techDiff</td>\n",
       "      <td>There was no image in he third task.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>The keyboard seemed to have the words I wanted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>sys-specific</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>sys-accurate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>sys-fast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>mental</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>physical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>temporal</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>performance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>effort</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>frustration</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>techDiff</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>It was a little more challenging this time, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>2</td>\n",
       "      <td>sys-specific</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>2</td>\n",
       "      <td>sys-accurate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>2</td>\n",
       "      <td>sys-fast</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>2</td>\n",
       "      <td>mental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>2</td>\n",
       "      <td>physical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>2</td>\n",
       "      <td>temporal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>2</td>\n",
       "      <td>performance</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>h52x67</td>\n",
       "      <td>2</td>\n",
       "      <td>effort</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>sys-specific</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>sys-accurate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>sys-fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>mental</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>physical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>temporal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>performance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>effort</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>frustration</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>0</td>\n",
       "      <td>techDiff</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>sys-specific</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>sys-accurate</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>sys-fast</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>mental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>physical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>temporal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>performance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>effort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>frustration</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>1</td>\n",
       "      <td>techDiff</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>sys-specific</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>sys-accurate</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>sys-fast</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>mental</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>physical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>temporal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>performance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>effort</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>frustration</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>2</td>\n",
       "      <td>techDiff</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant  block          name  \\\n",
       "0        h52x67      0  sys-specific   \n",
       "1        h52x67      0  sys-accurate   \n",
       "2        h52x67      0      sys-fast   \n",
       "3        h52x67      0        mental   \n",
       "4        h52x67      0      physical   \n",
       "5        h52x67      0      temporal   \n",
       "6        h52x67      0   performance   \n",
       "7        h52x67      0        effort   \n",
       "8        h52x67      0   frustration   \n",
       "9        h52x67      0      techDiff   \n",
       "10       h52x67      0         other   \n",
       "11       h52x67      1  sys-specific   \n",
       "12       h52x67      1  sys-accurate   \n",
       "13       h52x67      1      sys-fast   \n",
       "14       h52x67      1        mental   \n",
       "15       h52x67      1      physical   \n",
       "16       h52x67      1      temporal   \n",
       "17       h52x67      1   performance   \n",
       "18       h52x67      1        effort   \n",
       "19       h52x67      1   frustration   \n",
       "20       h52x67      1      techDiff   \n",
       "21       h52x67      1         other   \n",
       "22       h52x67      2  sys-specific   \n",
       "23       h52x67      2  sys-accurate   \n",
       "24       h52x67      2      sys-fast   \n",
       "25       h52x67      2        mental   \n",
       "26       h52x67      2      physical   \n",
       "27       h52x67      2      temporal   \n",
       "28       h52x67      2   performance   \n",
       "29       h52x67      2        effort   \n",
       "..          ...    ...           ...   \n",
       "721      gvwqp6      0  sys-specific   \n",
       "722      gvwqp6      0  sys-accurate   \n",
       "723      gvwqp6      0      sys-fast   \n",
       "724      gvwqp6      0        mental   \n",
       "725      gvwqp6      0      physical   \n",
       "726      gvwqp6      0      temporal   \n",
       "727      gvwqp6      0   performance   \n",
       "728      gvwqp6      0        effort   \n",
       "729      gvwqp6      0   frustration   \n",
       "730      gvwqp6      0      techDiff   \n",
       "731      gvwqp6      1  sys-specific   \n",
       "732      gvwqp6      1  sys-accurate   \n",
       "733      gvwqp6      1      sys-fast   \n",
       "734      gvwqp6      1        mental   \n",
       "735      gvwqp6      1      physical   \n",
       "736      gvwqp6      1      temporal   \n",
       "737      gvwqp6      1   performance   \n",
       "738      gvwqp6      1        effort   \n",
       "739      gvwqp6      1   frustration   \n",
       "740      gvwqp6      1      techDiff   \n",
       "741      gvwqp6      2  sys-specific   \n",
       "742      gvwqp6      2  sys-accurate   \n",
       "743      gvwqp6      2      sys-fast   \n",
       "744      gvwqp6      2        mental   \n",
       "745      gvwqp6      2      physical   \n",
       "746      gvwqp6      2      temporal   \n",
       "747      gvwqp6      2   performance   \n",
       "748      gvwqp6      2        effort   \n",
       "749      gvwqp6      2   frustration   \n",
       "750      gvwqp6      2      techDiff   \n",
       "\n",
       "                                                 value  \n",
       "0                                                    6  \n",
       "1                                                    5  \n",
       "2                                                    6  \n",
       "3                                                    3  \n",
       "4                                                    0  \n",
       "5                                                    3  \n",
       "6                                                    3  \n",
       "7                                                    5  \n",
       "8                                                    5  \n",
       "9                 There was no image in he third task.  \n",
       "10   The keyboard seemed to have the words I wanted...  \n",
       "11                                                   0  \n",
       "12                                                   3  \n",
       "13                                                   1  \n",
       "14                                                   4  \n",
       "15                                                   1  \n",
       "16                                                   4  \n",
       "17                                                   2  \n",
       "18                                                   2  \n",
       "19                                                   1  \n",
       "20                                               None.  \n",
       "21   It was a little more challenging this time, be...  \n",
       "22                                                   4  \n",
       "23                                                   5  \n",
       "24                                                   6  \n",
       "25                                                   1  \n",
       "26                                                   0  \n",
       "27                                                   3  \n",
       "28                                                   3  \n",
       "29                                                   4  \n",
       "..                                                 ...  \n",
       "721                                                  1  \n",
       "722                                                  0  \n",
       "723                                                  0  \n",
       "724                                                  2  \n",
       "725                                                  0  \n",
       "726                                                  0  \n",
       "727                                                  2  \n",
       "728                                                  2  \n",
       "729                                                  0  \n",
       "730                                                 No  \n",
       "731                                                  6  \n",
       "732                                                  6  \n",
       "733                                                  6  \n",
       "734                                                  1  \n",
       "735                                                  1  \n",
       "736                                                  0  \n",
       "737                                                  2  \n",
       "738                                                  1  \n",
       "739                                                  0  \n",
       "740                                                 No  \n",
       "741                                                  6  \n",
       "742                                                  6  \n",
       "743                                                  6  \n",
       "744                                                  0  \n",
       "745                                                  0  \n",
       "746                                                  0  \n",
       "747                                                  1  \n",
       "748                                                  0  \n",
       "749                                                  1  \n",
       "750                                                 No  \n",
       "\n",
       "[751 rows x 4 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Mone\n",
      "\n",
      "No\n",
      "\n",
      "No\n",
      "\n",
      "No issues\n",
      "\n",
      "No \n",
      "\n",
      "No\n",
      "\n",
      "No\n",
      "\n",
      "No\n",
      "\n",
      "Nope\n",
      "\n",
      "None.\n",
      "\n",
      "No\n",
      "\n",
      "Just the fact that the third photo in keyboard 1 never loaded.\n",
      "\n",
      "None\n",
      "\n",
      "No. \n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n'.join(x for x in experiment_level_pivot['techDiff'] if x is not None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, I really enjoyed this task ☺️\n",
      "\n",
      "None\n",
      "\n",
      "It went well but my initial survey responses might not be in complete alignment with my final responses on this page.  That's because seeing my captions on this page gave me a better perspective with the benefit of hindsight.  Thanks for the HIT!  I did my best and hope the data is useful!\n",
      "\n",
      "Being able to not have to backspace to redo typing\n",
      "\n",
      "This was very annoying\n",
      "\n",
      "Everything was great. First and third were pretty equal. Second was awful.\n",
      "\n",
      "It went smooth no issues \n",
      "\n",
      "Everything went smoothly. Thank you\n",
      "\n",
      "Can I type this one on the computer? One: I love the fact that after going to this page straight from the HIT on my computer, the page stayed synced when I went to it from my phone. There are some HITs I've done that could really benefit from that little nicety. Two: I feel like the suggestions really tend toward making me lazy, to some small extent. Having to type it all, you have to think about what to say, whereas faced with suggested options, you might say to yourself \"Yeah, that'll do.\" Three: I didn't notice much of a difference between the first two keyboards, honestly. \n",
      "\n",
      "No problems, hit was fine. Really liked the third board, it was the best one by far.\n",
      "\n",
      "I really enjoyed this experiment. Well done!! Thank you for considering my data.\n",
      "\n",
      "There were no problems in taking this study\n",
      "\n",
      "It was fun! Just feel a little unsure that I will be penalized for not writing a caption for the third photo on keyboard 1. I hope that was OK. Thank you!\n",
      "\n",
      "Use  my data\n",
      "\n",
      "Had to scroll to see the entire image, seems like it slowed down the task a bit. Other than that, task was fluid, progressed at a good pace.\n",
      "\n",
      "The experiment was pleasant. The keyboards one and two were very similar. I'm not sure I noticed a big difference between them. Definitely the option to pinpoint correct would be a good option as  is auto correct. But that's it that I can think of.\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n'.join(x for x in experiment_level_pivot['other'] if x is not None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate nAFC task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each stimulus image, choose a foil set. It should be about equally difficult for each condition. Simplest approach: find the nearest caption to the concatenation of all captions we got for that image.\n",
    "\n",
    "TODO: should we be computing similarities of individual captions, rather than complete images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vectorizer, caption_vecs = util.get_vectorized_captions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123287, 9952)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://images.cocodataset.org/train2017/000000570528.jpg'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2url[570528]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([275449, 396295, 431140, 227326, 200451, 223777, 247576, 71815, 240275])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_captions = {stimulus: '\\n'.join(toolz.pluck('text', trials))\n",
    "                   for stimulus, trials in toolz.groupby('stimulus', trial_data).items()}\n",
    "concat_captions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a small bath with a shower with a blue mat on the floor\n",
      "someome is using a shower but it's hard to see due to the opaque glass\n",
      "i see a standing shower with two hazy sliding glass doors and a towel hanging off of one.\n",
      "a tan towel hangs in front of a glass shower\n",
      "brown towel is hanging on a sliding shower door\n",
      "a beige towel hangs over the rightmost shower door both of which are wet with water\n",
      "a closed shower door with crackled glass encases some hanging colored toiletries\n",
      "a rusty and dirty shower in the bathroom has a tan towel over its handle\n",
      "a sliding glass shower door with a bath mat hanging on it\n",
      "a shower with a towel hanging on the handle of the door\n",
      "a tan towel is hanging from a chrome handle on a textured glass shower door\n",
      "a person is taking a shower in a shower with very opaque sliding doors\n",
      "a bathroom towel hanging on a shower door with a toilet in view\n",
      "a beige towel hangs up on the outside of an enclosed shower containing toiletries\n",
      "a shower door\n",
      "a toilet and a shower door hanging with a towel\n",
      "sliding glass, frosted, shower doors with a tan towel hanging on the handle and a white toilet with a blue floor rug\n",
      "a beige towel hanging on a translucent glass shower door\n",
      "a beige towel sits on a glass shower door\n",
      "a closed wavy glass door in the bathroom peers intk the walk in shower\n",
      "a closed shower with a pattern on the door making it hard to see inside\n",
      "the doors to the shower are closed and made of glass you can partially see through.\n",
      "a loofah and other items are blurry looking through an opaque shower door.\n",
      "a towel folded over a rack on sliding shower doors\n"
     ]
    }
   ],
   "source": [
    "# print(concat_captions[71815])\n",
    "# print(concat_captions[275449])\n",
    "print(concat_captions[396295])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 275449, the foil images are fixated on the 'wine'. But unsurprising, since all but one caption mentions it, and it's probably less common than \"cat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_similar_images(caption, n=10):\n",
    "    query_vec = cap_vectorizer.transform([caption])\n",
    "    similarity = caption_vecs.dot(query_vec.T).A.ravel()\n",
    "    return [images[idx]['cocoid'] for idx in np.argsort(similarity)[-n:][::-1]]\n",
    "query_caption = concat_captions[396295].replace('wine', '') #trial_data[0]['text']\n",
    "# query_caption = \"a rusty and dirty shower in the bathroom has a tan towel over its handle\"\n",
    "# query_caption = \"a sliding glass shower door with a bath mat hanging on it\"\n",
    "query_caption = \"a closed shower door with crackled glass encases some hanging colored toiletries\"\n",
    "# print(query_caption)\n",
    "# HTML(show_images(get_similar_images(query_caption)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[490872, 233737, 372775, 396295, 409842, 262284, 503200, 510852, 98257, 212082]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_foil_set(*, stimulus, caption, rs):\n",
    "    similar_images = get_similar_images(caption, n=10)\n",
    "    if stimulus not in similar_images:\n",
    "        print(\"Inserting\", stimulus, 'into foil set')\n",
    "        similar_images[-1] = stimulus\n",
    "    rs.shuffle(similar_images)\n",
    "    return similar_images\n",
    "stimulus = trial_data[1]['stimulus']\n",
    "get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=np.random.RandomState(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 200451 into foil set\n",
      "Inserting 240275 into foil set\n",
      "Inserting 431140 into foil set\n"
     ]
    }
   ],
   "source": [
    "rs = np.random.RandomState(1234)\n",
    "foil_sets = {\n",
    "    stimulus: get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=rs)\n",
    "    for stimulus in sorted(concat_captions.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group tasks so that (1) each annotator never gets the same target image twice and (2) each annotator never sees two captions from the same person. The latter criterion cannot always be met, though, since the number of annotators may not evenly divide the number of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffled(lst):\n",
    "    lst = lst[:]\n",
    "    random.shuffle(lst)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    trials_by_img = toolz.groupby('stimulus', shuffled(trial_data))\n",
    "    annotators = []\n",
    "    while not any(len(trials) == 0 for trials in trials_by_img.values()):\n",
    "        trials_for_annotator = []\n",
    "        participants_seen_by_annotator = set()\n",
    "        for stimulus, trials in trials_by_img.items():\n",
    "            for i in range(len(trials)):\n",
    "                participant = trials[i]['participant']\n",
    "                if participant not in participants_seen_by_annotator:\n",
    "                    trials_for_annotator.append(trials.pop(i))\n",
    "                    participants_seen_by_annotator.add(participant)\n",
    "                    break\n",
    "            else:\n",
    "#                 print(\"Have to use the same participant again\")\n",
    "                trials_for_annotator.append(trials.pop(0))\n",
    "\n",
    "        annotators.append(shuffled(trials_for_annotator))\n",
    "    if all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators):\n",
    "        break\n",
    "    assert all(len(trials) == 0 for trials in trials_by_img.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = annotators[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{71815: [],\n",
       " 227326: [],\n",
       " 247576: [],\n",
       " 223777: [],\n",
       " 240275: [],\n",
       " 275449: [],\n",
       " 431140: [],\n",
       " 200451: [],\n",
       " 396295: []}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_by_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never gets the same target image twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('stimulus', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never sees two captions from the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(trials) for trials in annotators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_task(stimulus, text):\n",
    "    foil_set = foil_sets[stimulus]\n",
    "    return dict(\n",
    "        description=text,\n",
    "        correct_idx=foil_set.index(stimulus),\n",
    "        images=[id2url[idx] for idx in foil_set]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'dozens of people line the gray sidewalks adjacent to tall buildings as a two deck bus and vehicle progress on the street',\n",
       " 'correct_idx': 2,\n",
       " 'images': ['http://images.cocodataset.org/train2017/000000200447.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000578233.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000247576.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000050752.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000024600.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000551983.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000318107.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000282343.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000059611.jpg',\n",
       "  'http://images.cocodataset.org/train2017/000000360528.jpg']}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = annotators[0][0]\n",
    "make_task(trial['stimulus'], trial['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_task = pd.DataFrame([\n",
    "    json.dumps([make_task(trial['stimulus'], trial['text']) for trial in annotator_trials])\n",
    "    for annotator_trials in annotators], columns=['task'])\n",
    "guesses_task.iloc[:1].to_csv(str(paths.data / 'anno-tasks' / 'guesses_test.csv'), index=False)\n",
    "guesses_task.iloc[1:].to_csv(str(paths.data / 'anno-tasks' / 'guesses_remain.csv'), index=False)\n",
    "guesses_task.to_csv(str(paths.data / 'anno-tasks' / 'guesses.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MTurk results so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = list((paths.data / 'mturk').glob('*-guesses.csv'))\n",
    "batched_guesses_results = (\n",
    "    pd.concat([pd.read_csv(str(f)) for f in result_files], axis=0, ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1be407b38>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bcb352b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(batched_guesses_results['WorkTimeInSeconds']/60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    141.000000\n",
       "mean       3.541477\n",
       "std        1.978311\n",
       "min        1.289233\n",
       "25%        2.376467\n",
       "50%        3.031583\n",
       "75%        4.121867\n",
       "max       15.050567\n",
       "Name: Answer.results, dtype: float64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19bfe1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_active_dur(results):\n",
    "    pages = json.loads(results)\n",
    "    try:\n",
    "        first_guess = pages[0]['guesses'][0]['timestamp']\n",
    "        last_guess = pages[-1]['guesses'][-1]['timestamp']\n",
    "        return (last_guess - first_guess) / 1000 / 60\n",
    "    except IndexError:\n",
    "        # Something failed in the UI probably...\n",
    "        return None\n",
    "batched_guesses_results['Answer.results'].apply(get_active_dur).hist()\n",
    "batched_guesses_results['Answer.results'].apply(get_active_dur).describe()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>92</th>\n",
       "      <th>102</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AcceptTime</th>\n",
       "      <td>Tue May 22 14:49:42 PDT 2018</td>\n",
       "      <td>Tue May 22 14:50:27 PDT 2018</td>\n",
       "      <td>Tue May 22 14:53:55 PDT 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Answer.doNotRedirect</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Answer.feedback</th>\n",
       "      <td>not very long, but it was a little confusing.</td>\n",
       "      <td>NO COMMENTS</td>\n",
       "      <td>NOTHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Answer.results</th>\n",
       "      <td>[{\"pageIdx\":0,\"description\":\"looking down a lo...</td>\n",
       "      <td>[{\"pageIdx\":0,\"description\":\"a tennis player a...</td>\n",
       "      <td>[{\"pageIdx\":0,\"description\":\"a towel folded ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApprovalTime</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Approve</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AssignmentDurationInSeconds</th>\n",
       "      <td>3600</td>\n",
       "      <td>3600</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AssignmentId</th>\n",
       "      <td>3YHH42UU5BFCFW5Q64TTZGBH8MG0L1</td>\n",
       "      <td>31Z0PCVWUKFEGKDF0CGT0MVLAD7T7W</td>\n",
       "      <td>3IOEN3P9S7JU30N1FJRRO2CUNJX612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AssignmentStatus</th>\n",
       "      <td>Submitted</td>\n",
       "      <td>Submitted</td>\n",
       "      <td>Submitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutoApprovalDelayInSeconds</th>\n",
       "      <td>259200</td>\n",
       "      <td>259200</td>\n",
       "      <td>259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutoApprovalTime</th>\n",
       "      <td>Fri May 25 14:50:26 PDT 2018</td>\n",
       "      <td>Fri May 25 14:53:59 PDT 2018</td>\n",
       "      <td>Fri May 25 15:37:13 PDT 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreationTime</th>\n",
       "      <td>Tue May 22 14:48:47 PDT 2018</td>\n",
       "      <td>Tue May 22 14:48:48 PDT 2018</td>\n",
       "      <td>Tue May 22 14:48:48 PDT 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <td>Can you pick the correct image in the fewest n...</td>\n",
       "      <td>Can you pick the correct image in the fewest n...</td>\n",
       "      <td>Can you pick the correct image in the fewest n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expiration</th>\n",
       "      <td>Tue May 29 14:48:47 PDT 2018</td>\n",
       "      <td>Tue May 29 14:48:48 PDT 2018</td>\n",
       "      <td>Tue May 29 14:48:48 PDT 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HITId</th>\n",
       "      <td>3TKXBROM5TAF5H0DH71K0L2XW8OJIZ</td>\n",
       "      <td>3TY2U1TEB7AB0SKJZPMKCMHX9NDJJB</td>\n",
       "      <td>3ZTE0JGGCES2TP5A5AX3XELOIXEOCL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HITTypeId</th>\n",
       "      <td>3ZT4KTA7QOEJZ9T4JBUMIE7H12L23C</td>\n",
       "      <td>3ZT4KTA7QOEJZ9T4JBUMIE7H12L23C</td>\n",
       "      <td>3ZT4KTA7QOEJZ9T4JBUMIE7H12L23C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input.task</th>\n",
       "      <td>[{\"description\": \"looking down a london street...</td>\n",
       "      <td>[{\"description\": \"a tennis player about to hit...</td>\n",
       "      <td>[{\"description\": \"a towel folded over a rack o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Keywords</th>\n",
       "      <td>image, comparison, choose, guess</td>\n",
       "      <td>image, comparison, choose, guess</td>\n",
       "      <td>image, comparison, choose, guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last30DaysApprovalRate</th>\n",
       "      <td>0% (0/0)</td>\n",
       "      <td>0% (0/0)</td>\n",
       "      <td>0% (0/0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last7DaysApprovalRate</th>\n",
       "      <td>0% (0/0)</td>\n",
       "      <td>0% (0/0)</td>\n",
       "      <td>0% (0/0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LifetimeApprovalRate</th>\n",
       "      <td>0% (0/0)</td>\n",
       "      <td>0% (0/0)</td>\n",
       "      <td>100% (1/1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LifetimeInSeconds</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxAssignments</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfSimilarHITs</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reject</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RejectionTime</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RequesterAnnotation</th>\n",
       "      <td>BatchId:3243155;OriginalHitTemplateId:920937336;</td>\n",
       "      <td>BatchId:3243155;OriginalHitTemplateId:920937336;</td>\n",
       "      <td>BatchId:3243155;OriginalHitTemplateId:920937336;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RequesterFeedback</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reward</th>\n",
       "      <td>$0.75</td>\n",
       "      <td>$0.75</td>\n",
       "      <td>$0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubmitTime</th>\n",
       "      <td>Tue May 22 14:50:26 PDT 2018</td>\n",
       "      <td>Tue May 22 14:53:59 PDT 2018</td>\n",
       "      <td>Tue May 22 15:37:13 PDT 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>Which image fits a given description?</td>\n",
       "      <td>Which image fits a given description?</td>\n",
       "      <td>Which image fits a given description?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WorkTimeInSeconds</th>\n",
       "      <td>44</td>\n",
       "      <td>212</td>\n",
       "      <td>2598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WorkerId</th>\n",
       "      <td>A27TKWMGFUCDMY</td>\n",
       "      <td>A3343ON7H5UO3L</td>\n",
       "      <td>A111ZFNLXK1TCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           92   \\\n",
       "AcceptTime                                        Tue May 22 14:49:42 PDT 2018   \n",
       "Answer.doNotRedirect                                                       NaN   \n",
       "Answer.feedback                  not very long, but it was a little confusing.   \n",
       "Answer.results               [{\"pageIdx\":0,\"description\":\"looking down a lo...   \n",
       "ApprovalTime                                                               NaN   \n",
       "Approve                                                                    NaN   \n",
       "AssignmentDurationInSeconds                                               3600   \n",
       "AssignmentId                                    3YHH42UU5BFCFW5Q64TTZGBH8MG0L1   \n",
       "AssignmentStatus                                                     Submitted   \n",
       "AutoApprovalDelayInSeconds                                              259200   \n",
       "AutoApprovalTime                                  Fri May 25 14:50:26 PDT 2018   \n",
       "CreationTime                                      Tue May 22 14:48:47 PDT 2018   \n",
       "Description                  Can you pick the correct image in the fewest n...   \n",
       "Expiration                                        Tue May 29 14:48:47 PDT 2018   \n",
       "HITId                                           3TKXBROM5TAF5H0DH71K0L2XW8OJIZ   \n",
       "HITTypeId                                       3ZT4KTA7QOEJZ9T4JBUMIE7H12L23C   \n",
       "Input.task                   [{\"description\": \"looking down a london street...   \n",
       "Keywords                                      image, comparison, choose, guess   \n",
       "Last30DaysApprovalRate                                                0% (0/0)   \n",
       "Last7DaysApprovalRate                                                 0% (0/0)   \n",
       "LifetimeApprovalRate                                                  0% (0/0)   \n",
       "LifetimeInSeconds                                                          NaN   \n",
       "MaxAssignments                                                               3   \n",
       "NumberOfSimilarHITs                                                        NaN   \n",
       "Reject                                                                     NaN   \n",
       "RejectionTime                                                              NaN   \n",
       "RequesterAnnotation           BatchId:3243155;OriginalHitTemplateId:920937336;   \n",
       "RequesterFeedback                                                          NaN   \n",
       "Reward                                                                   $0.75   \n",
       "SubmitTime                                        Tue May 22 14:50:26 PDT 2018   \n",
       "Title                                    Which image fits a given description?   \n",
       "WorkTimeInSeconds                                                           44   \n",
       "WorkerId                                                        A27TKWMGFUCDMY   \n",
       "\n",
       "                                                                           102  \\\n",
       "AcceptTime                                        Tue May 22 14:50:27 PDT 2018   \n",
       "Answer.doNotRedirect                                                       NaN   \n",
       "Answer.feedback                                                    NO COMMENTS   \n",
       "Answer.results               [{\"pageIdx\":0,\"description\":\"a tennis player a...   \n",
       "ApprovalTime                                                               NaN   \n",
       "Approve                                                                    NaN   \n",
       "AssignmentDurationInSeconds                                               3600   \n",
       "AssignmentId                                    31Z0PCVWUKFEGKDF0CGT0MVLAD7T7W   \n",
       "AssignmentStatus                                                     Submitted   \n",
       "AutoApprovalDelayInSeconds                                              259200   \n",
       "AutoApprovalTime                                  Fri May 25 14:53:59 PDT 2018   \n",
       "CreationTime                                      Tue May 22 14:48:48 PDT 2018   \n",
       "Description                  Can you pick the correct image in the fewest n...   \n",
       "Expiration                                        Tue May 29 14:48:48 PDT 2018   \n",
       "HITId                                           3TY2U1TEB7AB0SKJZPMKCMHX9NDJJB   \n",
       "HITTypeId                                       3ZT4KTA7QOEJZ9T4JBUMIE7H12L23C   \n",
       "Input.task                   [{\"description\": \"a tennis player about to hit...   \n",
       "Keywords                                      image, comparison, choose, guess   \n",
       "Last30DaysApprovalRate                                                0% (0/0)   \n",
       "Last7DaysApprovalRate                                                 0% (0/0)   \n",
       "LifetimeApprovalRate                                                  0% (0/0)   \n",
       "LifetimeInSeconds                                                          NaN   \n",
       "MaxAssignments                                                               3   \n",
       "NumberOfSimilarHITs                                                        NaN   \n",
       "Reject                                                                     NaN   \n",
       "RejectionTime                                                              NaN   \n",
       "RequesterAnnotation           BatchId:3243155;OriginalHitTemplateId:920937336;   \n",
       "RequesterFeedback                                                          NaN   \n",
       "Reward                                                                   $0.75   \n",
       "SubmitTime                                        Tue May 22 14:53:59 PDT 2018   \n",
       "Title                                    Which image fits a given description?   \n",
       "WorkTimeInSeconds                                                          212   \n",
       "WorkerId                                                        A3343ON7H5UO3L   \n",
       "\n",
       "                                                                           127  \n",
       "AcceptTime                                        Tue May 22 14:53:55 PDT 2018  \n",
       "Answer.doNotRedirect                                                       NaN  \n",
       "Answer.feedback                                                        NOTHING  \n",
       "Answer.results               [{\"pageIdx\":0,\"description\":\"a towel folded ov...  \n",
       "ApprovalTime                                                               NaN  \n",
       "Approve                                                                    NaN  \n",
       "AssignmentDurationInSeconds                                               3600  \n",
       "AssignmentId                                    3IOEN3P9S7JU30N1FJRRO2CUNJX612  \n",
       "AssignmentStatus                                                     Submitted  \n",
       "AutoApprovalDelayInSeconds                                              259200  \n",
       "AutoApprovalTime                                  Fri May 25 15:37:13 PDT 2018  \n",
       "CreationTime                                      Tue May 22 14:48:48 PDT 2018  \n",
       "Description                  Can you pick the correct image in the fewest n...  \n",
       "Expiration                                        Tue May 29 14:48:48 PDT 2018  \n",
       "HITId                                           3ZTE0JGGCES2TP5A5AX3XELOIXEOCL  \n",
       "HITTypeId                                       3ZT4KTA7QOEJZ9T4JBUMIE7H12L23C  \n",
       "Input.task                   [{\"description\": \"a towel folded over a rack o...  \n",
       "Keywords                                      image, comparison, choose, guess  \n",
       "Last30DaysApprovalRate                                                0% (0/0)  \n",
       "Last7DaysApprovalRate                                                 0% (0/0)  \n",
       "LifetimeApprovalRate                                                100% (1/1)  \n",
       "LifetimeInSeconds                                                          NaN  \n",
       "MaxAssignments                                                               3  \n",
       "NumberOfSimilarHITs                                                        NaN  \n",
       "Reject                                                                     NaN  \n",
       "RejectionTime                                                              NaN  \n",
       "RequesterAnnotation           BatchId:3243155;OriginalHitTemplateId:920937336;  \n",
       "RequesterFeedback                                                          NaN  \n",
       "Reward                                                                   $0.75  \n",
       "SubmitTime                                        Tue May 22 15:37:13 PDT 2018  \n",
       "Title                                    Which image fits a given description?  \n",
       "WorkTimeInSeconds                                                         2598  \n",
       "WorkerId                                                        A111ZFNLXK1TCO  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_guesses_results[batched_guesses_results['Answer.results'].apply(lambda x: '\"guesses\":[]' in x)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-266-7084eaa7ce6a>\u001b[0m(3)\u001b[0;36mget_active_dur\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mget_active_dur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m    \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m    \u001b[0mfirst_guess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'guesses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mlast_guess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'guesses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlast_guess\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfirst_guess\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p results\n",
      "'[{\"pageIdx\":0,\"description\":\"looking down a london street on a crowded evening with a london double bus in clear focus and old-style buildings next to each other on both sides\",\"guesses\":[],\"images\":[{\"idx\":7,\"url\":\"http://images.cocodataset.org/train2017/000000282343.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":0,\"url\":\"http://images.cocodataset.org/train2017/000000200447.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":6,\"url\":\"http://images.cocodataset.org/train2017/000000318107.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":4,\"url\":\"http://images.cocodataset.org/train2017/000000024600.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":2,\"url\":\"http://images.cocodataset.org/train2017/000000247576.jpg\",\"isCorrect\":true,\"alreadyGuessed\":false},{\"idx\":9,\"url\":\"http://images.cocodataset.org/train2017/000000360528.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":1,\"url\":\"http://images.cocodataset.org/train2017/000000578233.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":5,\"url\":\"http://images.cocodataset.org/train2017/000000551983.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":3,\"url\":\"http://images.cocodataset.org/train2017/000000050752.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":8,\"url\":\"http://images.cocodataset.org/train2017/000000059611.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false}]},{\"pageIdx\":1,\"description\":\"a black and white picture of a bride and groom cutting their wedding cake with a photographer helping them pose\",\"guesses\":[],\"images\":[{\"idx\":9,\"url\":\"http://images.cocodataset.org/train2017/000000312289.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":8,\"url\":\"http://images.cocodataset.org/train2017/000000119065.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":4,\"url\":\"http://images.cocodataset.org/train2017/000000564058.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":0,\"url\":\"http://images.cocodataset.org/train2017/000000352892.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":1,\"url\":\"http://images.cocodataset.org/train2017/000000466456.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":7,\"url\":\"http://images.cocodataset.org/train2017/000000227326.jpg\",\"isCorrect\":true,\"alreadyGuessed\":false},{\"idx\":5,\"url\":\"http://images.cocodataset.org/train2017/000000561454.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":6,\"url\":\"http://images.cocodataset.org/train2017/000000086147.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":2,\"url\":\"http://images.cocodataset.org/val2017/000000263969.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":3,\"url\":\"http://images.cocodataset.org/train2017/000000082990.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false}]},{\"pageIdx\":2,\"description\":\"two children and one adult stand on the beach holding kites and flying them into the sky\",\"guesses\":[],\"images\":[{\"idx\":1,\"url\":\"http://images.cocodataset.org/train2017/000000293789.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":3,\"url\":\"http://images.cocodataset.org/train2017/000000291140.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":5,\"url\":\"http://images.cocodataset.org/train2017/000000538916.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":6,\"url\":\"http://images.cocodataset.org/train2017/000000445668.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":7,\"url\":\"http://images.cocodataset.org/train2017/000000421184.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":0,\"url\":\"http://images.cocodataset.org/train2017/000000248884.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":8,\"url\":\"http://images.cocodataset.org/train2017/000000535307.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":4,\"url\":\"http://images.cocodataset.org/train2017/000000563053.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":2,\"url\":\"http://images.cocodataset.org/train2017/000000570075.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":9,\"url\":\"http://images.cocodataset.org/train2017/000000200451.jpg\",\"isCorrect\":true,\"alreadyGuessed\":false}]},{\"pageIdx\":3,\"description\":\"a tan towel is hanging from a chrome handle on a textured glass shower door\",\"guesses\":[],\"images\":[{\"idx\":5,\"url\":\"http://images.cocodataset.org/train2017/000000212082.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":6,\"url\":\"http://images.cocodataset.org/train2017/000000233737.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":3,\"url\":\"http://images.cocodataset.org/train2017/000000372775.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":2,\"url\":\"http://images.cocodataset.org/train2017/000000490872.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":1,\"url\":\"http://images.cocodataset.org/train2017/000000409842.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":4,\"url\":\"http://images.cocodataset.org/train2017/000000396295.jpg\",\"isCorrect\":true,\"alreadyGuessed\":false},{\"idx\":7,\"url\":\"http://images.cocodataset.org/train2017/000000503200.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":8,\"url\":\"http://images.cocodataset.org/train2017/000000098257.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":9,\"url\":\"http://images.cocodataset.org/train2017/000000262284.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":0,\"url\":\"http://images.cocodataset.org/train2017/000000510852.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false}]},{\"pageIdx\":4,\"description\":\"a cat sitting on top of the table next to a wine glass\",\"guesses\":[],\"images\":[{\"idx\":0,\"url\":\"http://images.cocodataset.org/train2017/000000055285.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":6,\"url\":\"http://images.cocodataset.org/train2017/000000275449.jpg\",\"isCorrect\":true,\"alreadyGuessed\":false},{\"idx\":7,\"url\":\"http://images.cocodataset.org/train2017/000000033901.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":1,\"url\":\"http://images.cocodataset.org/train2017/000000148839.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":9,\"url\":\"http://images.cocodataset.org/train2017/000000567627.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":3,\"url\":\"http://images.cocodataset.org/train2017/000000107868.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":2,\"url\":\"http://images.cocodataset.org/train2017/000000016072.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":8,\"url\":\"http://images.cocodataset.org/train2017/000000062446.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":5,\"url\":\"http://images.cocodataset.org/train2017/000000349130.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":4,\"url\":\"http://images.cocodataset.org/train2017/000000384260.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false}]},{\"pageIdx\":5,\"description\":\"a surfer is riding a wave the water looks so refreshing its a beautiful day\",\"guesses\":[],\"images\":[{\"idx\":5,\"url\":\"http://images.cocodataset.org/train2017/000000121263.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":0,\"url\":\"http://images.cocodataset.org/train2017/000000482172.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":1,\"url\":\"http://images.cocodataset.org/train2017/000000464694.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":7,\"url\":\"http://images.cocodataset.org/train2017/000000507211.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":9,\"url\":\"http://images.cocodataset.org/train2017/000000467872.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":4,\"url\":\"http://images.cocodataset.org/train2017/000000098619.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":8,\"url\":\"http://images.cocodataset.org/train2017/000000538693.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":2,\"url\":\"http://images.cocodataset.org/train2017/000000471028.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":6,\"url\":\"http://images.cocodataset.org/train2017/000000240275.jpg\",\"isCorrect\":true,\"alreadyGuessed\":false},{\"idx\":3,\"url\":\"http://images.cocodataset.org/train2017/000000413289.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false}]},{\"pageIdx\":6,\"description\":\"a train is pulling into the train station.\",\"guesses\":[],\"images\":[{\"idx\":6,\"url\":\"http://images.cocodataset.org/train2017/000000319266.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":2,\"url\":\"http://images.cocodataset.org/val2017/000000184321.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":8,\"url\":\"http://images.cocodataset.org/train2017/000000032773.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":4,\"url\":\"http://images.cocodataset.org/train2017/000000080203.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":3,\"url\":\"http://images.cocodataset.org/train2017/000000200369.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":9,\"url\":\"http://images.cocodataset.org/train2017/000000117275.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":7,\"url\":\"http://images.cocodataset.org/train2017/000000074110.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":1,\"url\":\"http://images.cocodataset.org/train2017/000000311112.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":0,\"url\":\"http://images.cocodataset.org/train2017/000000223777.jpg\",\"isCorrect\":true,\"alreadyGuessed\":false},{\"idx\":5,\"url\":\"http://images.cocodataset.org/train2017/000000109896.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false}]},{\"pageIdx\":7,\"description\":\"a clean bathroom with a white sink near a white toilet\",\"guesses\":[],\"images\":[{\"idx\":3,\"url\":\"http://images.cocodataset.org/train2017/000000139492.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":7,\"url\":\"http://images.cocodataset.org/train2017/000000382542.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":8,\"url\":\"http://images.cocodataset.org/train2017/000000386560.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":6,\"url\":\"http://images.cocodataset.org/train2017/000000345401.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":4,\"url\":\"http://images.cocodataset.org/train2017/000000567179.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":2,\"url\":\"http://images.cocodataset.org/val2017/000000431140.jpg\",\"isCorrect\":true,\"alreadyGuessed\":false},{\"idx\":1,\"url\":\"http://images.cocodataset.org/train2017/000000070107.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":9,\"url\":\"http://images.cocodataset.org/train2017/000000341011.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":0,\"url\":\"http://images.cocodataset.org/train2017/000000204826.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":5,\"url\":\"http://images.cocodataset.org/train2017/000000262386.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false}]},{\"pageIdx\":8,\"description\":\"man playing tennis\",\"guesses\":[],\"images\":[{\"idx\":8,\"url\":\"http://images.cocodataset.org/train2017/000000217465.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":9,\"url\":\"http://images.cocodataset.org/train2017/000000227269.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":1,\"url\":\"http://images.cocodataset.org/train2017/000000562778.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":5,\"url\":\"http://images.cocodataset.org/train2017/000000306186.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":2,\"url\":\"http://images.cocodataset.org/train2017/000000451651.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":3,\"url\":\"http://images.cocodataset.org/train2017/000000071815.jpg\",\"isCorrect\":true,\"alreadyGuessed\":false},{\"idx\":7,\"url\":\"http://images.cocodataset.org/train2017/000000260802.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":6,\"url\":\"http://images.cocodataset.org/train2017/000000419076.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":4,\"url\":\"http://images.cocodataset.org/train2017/000000033305.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false},{\"idx\":0,\"url\":\"http://images.cocodataset.org/train2017/000000247224.jpg\",\"isCorrect\":false,\"alreadyGuessed\":false}]}]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UI fail A27TKWMGFUCDMY\n",
      "UI fail A27TKWMGFUCDMY\n",
      "UI fail A27TKWMGFUCDMY\n",
      "UI fail A27TKWMGFUCDMY\n",
      "UI fail A27TKWMGFUCDMY\n",
      "UI fail A27TKWMGFUCDMY\n",
      "UI fail A27TKWMGFUCDMY\n",
      "UI fail A27TKWMGFUCDMY\n",
      "UI fail A27TKWMGFUCDMY\n",
      "UI fail A3343ON7H5UO3L\n",
      "UI fail A3343ON7H5UO3L\n",
      "UI fail A3343ON7H5UO3L\n",
      "UI fail A3343ON7H5UO3L\n",
      "UI fail A3343ON7H5UO3L\n",
      "UI fail A3343ON7H5UO3L\n",
      "UI fail A3343ON7H5UO3L\n",
      "UI fail A3343ON7H5UO3L\n",
      "UI fail A111ZFNLXK1TCO\n",
      "UI fail A111ZFNLXK1TCO\n",
      "UI fail A111ZFNLXK1TCO\n",
      "UI fail A111ZFNLXK1TCO\n",
      "UI fail A111ZFNLXK1TCO\n",
      "UI fail A111ZFNLXK1TCO\n",
      "UI fail A111ZFNLXK1TCO\n",
      "UI fail A111ZFNLXK1TCO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>guesser</th>\n",
       "      <th>num_guesses</th>\n",
       "      <th>stimulus_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dozens of people line the gray sidewalks adjac...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a man with blonde hair and a white and black w...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people are standing on the beach flying colorf...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a train is coming on a rail road</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>6</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a tricolor cat is sitting in front of a partia...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a closed shower door with crackled glass encas...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a tennis player in a white shirt and tan short...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a bathroom with a toilet and sink and with a r...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dozens of people line the gray sidewalks adjac...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a man with blonde hair and a white and black w...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>people are standing on the beach flying colorf...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a train is coming on a rail road</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>7</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a tricolor cat is sitting in front of a partia...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a closed shower door with crackled glass encas...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a tennis player in a white shirt and tan short...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a bathroom with a toilet and sink and with a r...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dozens of people line the gray sidewalks adjac...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a man with blonde hair and a white and black w...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>people are standing on the beach flying colorf...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a train is coming on a rail road</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>10</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a tricolor cat is sitting in front of a partia...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>a closed shower door with crackled glass encas...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a tennis player in a white shirt and tan short...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>a bathroom with a toilet and sink and with a r...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>a gorgeous european city with tall gothic buil...</td>\n",
       "      <td>A23437BMZ5T1FH</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>a restroom containing a porcelain toilet and s...</td>\n",
       "      <td>A23437BMZ5T1FH</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A23437BMZ5T1FH</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>a brown trai  pulls into the tracka next to so...</td>\n",
       "      <td>A1NLW5ZS2WQR35</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>a young blond man in a water suit catching a s...</td>\n",
       "      <td>A1NLW5ZS2WQR35</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>a gray and beige cat looks upward as a half fu...</td>\n",
       "      <td>A1NLW5ZS2WQR35</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>a man and his two children are flying multicol...</td>\n",
       "      <td>A35SC4D5YNJGOW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>a man and woman getting assistance cutting the...</td>\n",
       "      <td>A35SC4D5YNJGOW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>a wine glass with red wine less than half full...</td>\n",
       "      <td>A35SC4D5YNJGOW</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>a surfer leans forward to ride a wave</td>\n",
       "      <td>A35SC4D5YNJGOW</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>roger federer about to back hand a tennis ball...</td>\n",
       "      <td>A35SC4D5YNJGOW</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>a large street with people on the sidewalk whi...</td>\n",
       "      <td>A35SC4D5YNJGOW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>a train is approaching the station and passing...</td>\n",
       "      <td>A35SC4D5YNJGOW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>a white bathroom sink and toilet with a mirror...</td>\n",
       "      <td>A35SC4D5YNJGOW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>a sliding glass shower door with a bath mat ha...</td>\n",
       "      <td>A35SC4D5YNJGOW</td>\n",
       "      <td>6</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>a man and his two children are flying multicol...</td>\n",
       "      <td>A2EKR2ZFO10VMV</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>a man and woman getting assistance cutting the...</td>\n",
       "      <td>A2EKR2ZFO10VMV</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>a wine glass with red wine less than half full...</td>\n",
       "      <td>A2EKR2ZFO10VMV</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>a surfer leans forward to ride a wave</td>\n",
       "      <td>A2EKR2ZFO10VMV</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>roger federer about to back hand a tennis ball...</td>\n",
       "      <td>A2EKR2ZFO10VMV</td>\n",
       "      <td>7</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>a large street with people on the sidewalk whi...</td>\n",
       "      <td>A2EKR2ZFO10VMV</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>a train is approaching the station and passing...</td>\n",
       "      <td>A2EKR2ZFO10VMV</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>a white bathroom sink and toilet with a mirror...</td>\n",
       "      <td>A2EKR2ZFO10VMV</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>a sliding glass shower door with a bath mat ha...</td>\n",
       "      <td>A2EKR2ZFO10VMV</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>a man and his two children are flying multicol...</td>\n",
       "      <td>A3RBA581BHJDR8</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>a man and woman getting assistance cutting the...</td>\n",
       "      <td>A3RBA581BHJDR8</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>a wine glass with red wine less than half full...</td>\n",
       "      <td>A3RBA581BHJDR8</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>a surfer leans forward to ride a wave</td>\n",
       "      <td>A3RBA581BHJDR8</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>roger federer about to back hand a tennis ball...</td>\n",
       "      <td>A3RBA581BHJDR8</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>a large street with people on the sidewalk whi...</td>\n",
       "      <td>A3RBA581BHJDR8</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>a train is approaching the station and passing...</td>\n",
       "      <td>A3RBA581BHJDR8</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>a white bathroom sink and toilet with a mirror...</td>\n",
       "      <td>A3RBA581BHJDR8</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>a sliding glass shower door with a bath mat ha...</td>\n",
       "      <td>A3RBA581BHJDR8</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1271 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description         guesser  \\\n",
       "0     dozens of people line the gray sidewalks adjac...   A89R5XGMHOTJE   \n",
       "1     a newly wedded couple cutting there wedding ca...   A89R5XGMHOTJE   \n",
       "2     a man with blonde hair and a white and black w...   A89R5XGMHOTJE   \n",
       "3     people are standing on the beach flying colorf...   A89R5XGMHOTJE   \n",
       "4                      a train is coming on a rail road   A89R5XGMHOTJE   \n",
       "5     a tricolor cat is sitting in front of a partia...   A89R5XGMHOTJE   \n",
       "6     a closed shower door with crackled glass encas...   A89R5XGMHOTJE   \n",
       "7     a tennis player in a white shirt and tan short...   A89R5XGMHOTJE   \n",
       "8     a bathroom with a toilet and sink and with a r...   A89R5XGMHOTJE   \n",
       "9     dozens of people line the gray sidewalks adjac...  A1DKVUTOBPQH11   \n",
       "10    a newly wedded couple cutting there wedding ca...  A1DKVUTOBPQH11   \n",
       "11    a man with blonde hair and a white and black w...  A1DKVUTOBPQH11   \n",
       "12    people are standing on the beach flying colorf...  A1DKVUTOBPQH11   \n",
       "13                     a train is coming on a rail road  A1DKVUTOBPQH11   \n",
       "14    a tricolor cat is sitting in front of a partia...  A1DKVUTOBPQH11   \n",
       "15    a closed shower door with crackled glass encas...  A1DKVUTOBPQH11   \n",
       "16    a tennis player in a white shirt and tan short...  A1DKVUTOBPQH11   \n",
       "17    a bathroom with a toilet and sink and with a r...  A1DKVUTOBPQH11   \n",
       "18    dozens of people line the gray sidewalks adjac...  A1T9KDKDFO114S   \n",
       "19    a newly wedded couple cutting there wedding ca...  A1T9KDKDFO114S   \n",
       "20    a man with blonde hair and a white and black w...  A1T9KDKDFO114S   \n",
       "21    people are standing on the beach flying colorf...  A1T9KDKDFO114S   \n",
       "22                     a train is coming on a rail road  A1T9KDKDFO114S   \n",
       "23    a tricolor cat is sitting in front of a partia...  A1T9KDKDFO114S   \n",
       "24    a closed shower door with crackled glass encas...  A1T9KDKDFO114S   \n",
       "25    a tennis player in a white shirt and tan short...  A1T9KDKDFO114S   \n",
       "26    a bathroom with a toilet and sink and with a r...  A1T9KDKDFO114S   \n",
       "27    a gorgeous european city with tall gothic buil...  A23437BMZ5T1FH   \n",
       "28    a restroom containing a porcelain toilet and s...  A23437BMZ5T1FH   \n",
       "29    a family flies their kites together at a beach...  A23437BMZ5T1FH   \n",
       "...                                                 ...             ...   \n",
       "1241  a brown trai  pulls into the tracka next to so...  A1NLW5ZS2WQR35   \n",
       "1242  a young blond man in a water suit catching a s...  A1NLW5ZS2WQR35   \n",
       "1243  a gray and beige cat looks upward as a half fu...  A1NLW5ZS2WQR35   \n",
       "1244  a man and his two children are flying multicol...  A35SC4D5YNJGOW   \n",
       "1245  a man and woman getting assistance cutting the...  A35SC4D5YNJGOW   \n",
       "1246  a wine glass with red wine less than half full...  A35SC4D5YNJGOW   \n",
       "1247              a surfer leans forward to ride a wave  A35SC4D5YNJGOW   \n",
       "1248  roger federer about to back hand a tennis ball...  A35SC4D5YNJGOW   \n",
       "1249  a large street with people on the sidewalk whi...  A35SC4D5YNJGOW   \n",
       "1250  a train is approaching the station and passing...  A35SC4D5YNJGOW   \n",
       "1251  a white bathroom sink and toilet with a mirror...  A35SC4D5YNJGOW   \n",
       "1252  a sliding glass shower door with a bath mat ha...  A35SC4D5YNJGOW   \n",
       "1253  a man and his two children are flying multicol...  A2EKR2ZFO10VMV   \n",
       "1254  a man and woman getting assistance cutting the...  A2EKR2ZFO10VMV   \n",
       "1255  a wine glass with red wine less than half full...  A2EKR2ZFO10VMV   \n",
       "1256              a surfer leans forward to ride a wave  A2EKR2ZFO10VMV   \n",
       "1257  roger federer about to back hand a tennis ball...  A2EKR2ZFO10VMV   \n",
       "1258  a large street with people on the sidewalk whi...  A2EKR2ZFO10VMV   \n",
       "1259  a train is approaching the station and passing...  A2EKR2ZFO10VMV   \n",
       "1260  a white bathroom sink and toilet with a mirror...  A2EKR2ZFO10VMV   \n",
       "1261  a sliding glass shower door with a bath mat ha...  A2EKR2ZFO10VMV   \n",
       "1262  a man and his two children are flying multicol...  A3RBA581BHJDR8   \n",
       "1263  a man and woman getting assistance cutting the...  A3RBA581BHJDR8   \n",
       "1264  a wine glass with red wine less than half full...  A3RBA581BHJDR8   \n",
       "1265              a surfer leans forward to ride a wave  A3RBA581BHJDR8   \n",
       "1266  roger federer about to back hand a tennis ball...  A3RBA581BHJDR8   \n",
       "1267  a large street with people on the sidewalk whi...  A3RBA581BHJDR8   \n",
       "1268  a train is approaching the station and passing...  A3RBA581BHJDR8   \n",
       "1269  a white bathroom sink and toilet with a mirror...  A3RBA581BHJDR8   \n",
       "1270  a sliding glass shower door with a bath mat ha...  A3RBA581BHJDR8   \n",
       "\n",
       "      num_guesses                                       stimulus_url  \n",
       "0               1  http://images.cocodataset.org/train2017/000000...  \n",
       "1               1  http://images.cocodataset.org/train2017/000000...  \n",
       "2               1  http://images.cocodataset.org/train2017/000000...  \n",
       "3               4  http://images.cocodataset.org/train2017/000000...  \n",
       "4               6  http://images.cocodataset.org/train2017/000000...  \n",
       "5               3  http://images.cocodataset.org/train2017/000000...  \n",
       "6               1  http://images.cocodataset.org/train2017/000000...  \n",
       "7               1  http://images.cocodataset.org/train2017/000000...  \n",
       "8               1  http://images.cocodataset.org/val2017/00000043...  \n",
       "9               2  http://images.cocodataset.org/train2017/000000...  \n",
       "10              1  http://images.cocodataset.org/train2017/000000...  \n",
       "11              1  http://images.cocodataset.org/train2017/000000...  \n",
       "12              3  http://images.cocodataset.org/train2017/000000...  \n",
       "13              7  http://images.cocodataset.org/train2017/000000...  \n",
       "14              2  http://images.cocodataset.org/train2017/000000...  \n",
       "15              1  http://images.cocodataset.org/train2017/000000...  \n",
       "16              1  http://images.cocodataset.org/train2017/000000...  \n",
       "17              1  http://images.cocodataset.org/val2017/00000043...  \n",
       "18              2  http://images.cocodataset.org/train2017/000000...  \n",
       "19              1  http://images.cocodataset.org/train2017/000000...  \n",
       "20              1  http://images.cocodataset.org/train2017/000000...  \n",
       "21              2  http://images.cocodataset.org/train2017/000000...  \n",
       "22             10  http://images.cocodataset.org/train2017/000000...  \n",
       "23              1  http://images.cocodataset.org/train2017/000000...  \n",
       "24              2  http://images.cocodataset.org/train2017/000000...  \n",
       "25              2  http://images.cocodataset.org/train2017/000000...  \n",
       "26              1  http://images.cocodataset.org/val2017/00000043...  \n",
       "27              1  http://images.cocodataset.org/train2017/000000...  \n",
       "28              5  http://images.cocodataset.org/val2017/00000043...  \n",
       "29              1  http://images.cocodataset.org/train2017/000000...  \n",
       "...           ...                                                ...  \n",
       "1241            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1242            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1243            3  http://images.cocodataset.org/train2017/000000...  \n",
       "1244            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1245            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1246            2  http://images.cocodataset.org/train2017/000000...  \n",
       "1247            3  http://images.cocodataset.org/train2017/000000...  \n",
       "1248            2  http://images.cocodataset.org/train2017/000000...  \n",
       "1249            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1250            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1251            1  http://images.cocodataset.org/val2017/00000043...  \n",
       "1252            6  http://images.cocodataset.org/train2017/000000...  \n",
       "1253            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1254            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1255            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1256            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1257            7  http://images.cocodataset.org/train2017/000000...  \n",
       "1258            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1259            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1260            1  http://images.cocodataset.org/val2017/00000043...  \n",
       "1261            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1262            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1263            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1264            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1265            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1266            3  http://images.cocodataset.org/train2017/000000...  \n",
       "1267            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1268            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1269            1  http://images.cocodataset.org/val2017/00000043...  \n",
       "1270            4  http://images.cocodataset.org/train2017/000000...  \n",
       "\n",
       "[1271 rows x 4 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses_results = []\n",
    "for i, row in batched_guesses_results.iterrows():\n",
    "    for page in json.loads(row['Answer.results']):\n",
    "#         print(page)\n",
    "        guess_indices = [guess['idx'] for guess in page['guesses']]\n",
    "        if len(guess_indices) == 0:\n",
    "            print(\"UI fail\", row['WorkerId'])\n",
    "            continue\n",
    "#         guessed_right_sometime = [row.correctIdx in row.guess_indices for row in mturk_nafc_results.itertuples()]\n",
    "        stimulus_url = [img for img in page['images'] if img['isCorrect']][0]['url']\n",
    "        guesses_results.append(dict(\n",
    "            guesser=row['WorkerId'],\n",
    "            description=page['description'],\n",
    "            num_guesses=len(guess_indices),\n",
    "            stimulus_url=stimulus_url))\n",
    "pd.DataFrame(guesses_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_responses_by_caption = mturk_nafc_results.groupby('Answer.description').size().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tasks remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials_todo = [trial for trial in trial_data if num_responses_by_caption.get(trial['text'], 0) < 3]\n",
    "# len(trial_data), len(trials_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# while True:\n",
    "#     out_fn = paths.data / 'anno-tasks' / f'{datetime.date.today().isoformat()}-{i}-nAFC.csv'\n",
    "#     if not out_fn.exists():\n",
    "#         break\n",
    "#     i += 1\n",
    "# out_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = np.random.RandomState(1234)\n",
    "# pd.DataFrame([make_task(trial, rs) for trial in trials_todo]).to_csv(out_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the actual HIT text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "html = Template(open(paths.top_level / 'HITs' / '2018-05-04-image-description-match.jinja.html').read()).render(dict(\n",
    "    description='${description}',\n",
    "    images=['${image_%d_url}' % i for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html2 = html\n",
    "trial = trial_data[18+7*9]\n",
    "for k, v in make_task(trial['stimulus'], trial['text']).items():\n",
    "    html2 = html2.replace('${' + k + '}', str(v))\n",
    "HTML('<div style=\"height: 1000px; position: relative;\">'+html2+'</div>')\n",
    "# print(html2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.Popen('pbcopy', stdin=subprocess.PIPE).communicate(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MTurk results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results.groupby('Answer.description').num_guesses.mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mturk_nafc_results['WorkTimeInSeconds'][mturk_nafc_results['WorkTimeInSeconds'] < 5*60] / 60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(mturk_nafc_results['WorkTimeInSeconds'] / 60) * 9/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    15 # participants\n",
    "    * 3 # conditions per participant\n",
    "    * 3 # captions per condition\n",
    "    - 1 # image not shown\n",
    ") * 3 # annotators per description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    * .24 # reward per annotator\n",
    ") * 1.2 # MTurk 20% fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the same worker see the same target image multiple times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data.iterrows())[1]['Input.image_0_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['target_image_url'] = [row['Input.image_'+str(row['correctIdx'])+\"_url\"] for _, row in mturk_nafc_results.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_worker_image_pairs = set()\n",
    "for worker_id, data in mturk_nafc_results.groupby('WorkerId'):\n",
    "    target_images = [row['target_image_url'] for _, row in data.iterrows()]\n",
    "    if len(target_images) != len(set(target_images)):\n",
    "#         print(worker_id)\n",
    "        value_counts = pd.Series(target_images).value_counts()\n",
    "        value_counts = value_counts[value_counts > 1]\n",
    "#         print(value_counts)\n",
    "        for img in value_counts.index:\n",
    "            bad_worker_image_pairs.add((worker_id, img))\n",
    "bad_worker_image_pairs\n",
    "\n",
    "annotation_row_is_bad = [\n",
    "    (row['WorkerId'], row['target_image_url']) in bad_worker_image_pairs\n",
    "    for _, row in mturk_nafc_results.iterrows()\n",
    "]\n",
    "mturk_nafc_results['row_is_bad'] = annotation_row_is_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['row_is_bad'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_results = mturk_nafc_results[~mturk_nafc_results['row_is_bad']].rename(columns={'Answer.description': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mturk_nafc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(guess_results), len(trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'guess_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-32d8d7787f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m annotator_level_data = pd.merge(\n\u001b[1;32m      2\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'participant'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'writer'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mguess_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'WorkerId'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'guesser'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HITId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HITTypeId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Description'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Keywords'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RequesterAnnotation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'guesses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     on='text', validate='1:m', how='right')\n\u001b[1;32m      5\u001b[0m \u001b[0mannotator_level_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'guess_results' is not defined"
     ]
    }
   ],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    guess_results.rename(columns={'WorkerId': 'guesser'}).drop(['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'RequesterAnnotation', 'guesses'], axis=1),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guesser': 'A89R5XGMHOTJE',\n",
       " 'description': 'dozens of people line the gray sidewalks adjacent to tall buildings as a two deck bus and vehicle progress on the street',\n",
       " 'num_guesses': 1,\n",
       " 'stimulus_url': 'http://images.cocodataset.org/train2017/000000247576.jpg'}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>condition</th>\n",
       "      <th>exclude</th>\n",
       "      <th>idx</th>\n",
       "      <th>idx_in_block</th>\n",
       "      <th>num_resized</th>\n",
       "      <th>num_tapBackspace</th>\n",
       "      <th>num_tapKey</th>\n",
       "      <th>num_tapSugg_any</th>\n",
       "      <th>num_tapSugg_bos</th>\n",
       "      <th>num_tapSugg_full</th>\n",
       "      <th>num_tapSugg_part</th>\n",
       "      <th>num_tapText</th>\n",
       "      <th>writer</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>text</th>\n",
       "      <th>guesser</th>\n",
       "      <th>num_guesses</th>\n",
       "      <th>stimulus_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>275449</td>\n",
       "      <td>a yellow cat with strips is setting on a place...</td>\n",
       "      <td>A1TARNH07A75CG</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>275449</td>\n",
       "      <td>a yellow cat with strips is setting on a place...</td>\n",
       "      <td>A3GEL5PWFIK05S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>275449</td>\n",
       "      <td>a yellow cat with strips is setting on a place...</td>\n",
       "      <td>A185P3B2MC2K83</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>275449</td>\n",
       "      <td>a yellow cat with strips is setting on a place...</td>\n",
       "      <td>A3774HPOUKYTX7</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>275449</td>\n",
       "      <td>a yellow cat with strips is setting on a place...</td>\n",
       "      <td>A1PDBRYBFMMFNY</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>275449</td>\n",
       "      <td>a yellow cat with strips is setting on a place...</td>\n",
       "      <td>AZJKB1D4AFMQY</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>396295</td>\n",
       "      <td>a small bath with a shower with a blue mat on ...</td>\n",
       "      <td>A3VENK02U0X16N</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>396295</td>\n",
       "      <td>a small bath with a shower with a blue mat on ...</td>\n",
       "      <td>AJRY9ALX8069Y</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>396295</td>\n",
       "      <td>a small bath with a shower with a blue mat on ...</td>\n",
       "      <td>A3L2FPKRD46FRW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>396295</td>\n",
       "      <td>a small bath with a shower with a blue mat on ...</td>\n",
       "      <td>A2VAL2BRKVSUB5</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>396295</td>\n",
       "      <td>a small bath with a shower with a blue mat on ...</td>\n",
       "      <td>A21UA6O7ZFAIQJ</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>396295</td>\n",
       "      <td>a small bath with a shower with a blue mat on ...</td>\n",
       "      <td>A2XJH3WC02RMXQ</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bath room with a white toilet and a white wa...</td>\n",
       "      <td>A2ECXGDFC0NJEL</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bath room with a white toilet and a white wa...</td>\n",
       "      <td>A3FCZNB9E8K3CX</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bath room with a white toilet and a white wa...</td>\n",
       "      <td>AIZTLQM7HHQN6</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bath room with a white toilet and a white wa...</td>\n",
       "      <td>A230GPTWWF3SE7</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bath room with a white toilet and a white wa...</td>\n",
       "      <td>A11FRLH5KWRLBV</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>431140</td>\n",
       "      <td>a bath room with a white toilet and a white wa...</td>\n",
       "      <td>A1NLW5ZS2WQR35</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>227326</td>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A89R5XGMHOTJE</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>227326</td>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A1DKVUTOBPQH11</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>227326</td>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A1T9KDKDFO114S</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>227326</td>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A2WWYVKGZZXBOB</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>227326</td>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A1NOINYD1FZ55T</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>227326</td>\n",
       "      <td>a newly wedded couple cutting there wedding ca...</td>\n",
       "      <td>A2CF2BD4Q0ZDJN</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>200451</td>\n",
       "      <td>a group of people flying kites on a beach and ...</td>\n",
       "      <td>A2P76QVLSGJR45</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>200451</td>\n",
       "      <td>a group of people flying kites on a beach and ...</td>\n",
       "      <td>A2ZNOMZ35LKY8Q</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>200451</td>\n",
       "      <td>a group of people flying kites on a beach and ...</td>\n",
       "      <td>A1USR9JCAMDGM3</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>200451</td>\n",
       "      <td>a group of people flying kites on a beach and ...</td>\n",
       "      <td>A198QA1OQBUJV1</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>200451</td>\n",
       "      <td>a group of people flying kites on a beach and ...</td>\n",
       "      <td>ATSZCAVI441RM</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>norecs</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>jvccx2</td>\n",
       "      <td>200451</td>\n",
       "      <td>a group of people flying kites on a beach and ...</td>\n",
       "      <td>A9ZCY6FLUCIU1</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>200451</td>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A23437BMZ5T1FH</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>200451</td>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A2YGAEODJ5SSF6</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>200451</td>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A1T208Y507O4RS</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>200451</td>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A3FAH5S2RGZ5AK</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>200451</td>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>AU95AAGU3WSFY</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>200451</td>\n",
       "      <td>a family flies their kites together at a beach...</td>\n",
       "      <td>A2EZNZ6X58RTNR</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train is traveling down the tracks near a ra...</td>\n",
       "      <td>A26M997VYVK0E6</td>\n",
       "      <td>7</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train is traveling down the tracks near a ra...</td>\n",
       "      <td>A3JT2I4GGKDYPE</td>\n",
       "      <td>10</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train is traveling down the tracks near a ra...</td>\n",
       "      <td>A2MGH3MBXMKD96</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train is traveling down the tracks near a ra...</td>\n",
       "      <td>A2TDGWWPX6IMIZ</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train is traveling down the tracks near a ra...</td>\n",
       "      <td>AJG4Y1OT9N50T</td>\n",
       "      <td>6</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>223777</td>\n",
       "      <td>a train is traveling down the tracks near a ra...</td>\n",
       "      <td>A3P74FP62XNVYI</td>\n",
       "      <td>3</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>247576</td>\n",
       "      <td>a double decker bus traveling down the middle ...</td>\n",
       "      <td>A3VENK02U0X16N</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>247576</td>\n",
       "      <td>a double decker bus traveling down the middle ...</td>\n",
       "      <td>AJRY9ALX8069Y</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>247576</td>\n",
       "      <td>a double decker bus traveling down the middle ...</td>\n",
       "      <td>A3L2FPKRD46FRW</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>247576</td>\n",
       "      <td>a double decker bus traveling down the middle ...</td>\n",
       "      <td>A2VAL2BRKVSUB5</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>247576</td>\n",
       "      <td>a double decker bus traveling down the middle ...</td>\n",
       "      <td>A21UA6O7ZFAIQJ</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>247576</td>\n",
       "      <td>a double decker bus traveling down the middle ...</td>\n",
       "      <td>A2XJH3WC02RMXQ</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>71815</td>\n",
       "      <td>a male tennis player hits the ball with his ra...</td>\n",
       "      <td>A1NSHNH3MNFRGW</td>\n",
       "      <td>8</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>71815</td>\n",
       "      <td>a male tennis player hits the ball with his ra...</td>\n",
       "      <td>A1ZN6V0PU8VVAH</td>\n",
       "      <td>6</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>71815</td>\n",
       "      <td>a male tennis player hits the ball with his ra...</td>\n",
       "      <td>A125KW9P18V5Z1</td>\n",
       "      <td>5</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>71815</td>\n",
       "      <td>a male tennis player hits the ball with his ra...</td>\n",
       "      <td>A20FYCXV508HM9</td>\n",
       "      <td>1</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>71815</td>\n",
       "      <td>a male tennis player hits the ball with his ra...</td>\n",
       "      <td>A610SH5RY1NG1</td>\n",
       "      <td>8</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>71815</td>\n",
       "      <td>a male tennis player hits the ball with his ra...</td>\n",
       "      <td>AKZ8SFOAI4RZN</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer rides the crest of the waves in the o...</td>\n",
       "      <td>AZ9BU8QI4YKF3</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer rides the crest of the waves in the o...</td>\n",
       "      <td>AR1IWBDA7MC86</td>\n",
       "      <td>10</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer rides the crest of the waves in the o...</td>\n",
       "      <td>A2WC2NO555XU3J</td>\n",
       "      <td>6</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer rides the crest of the waves in the o...</td>\n",
       "      <td>A3RCX3IQ8L6HHW</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer rides the crest of the waves in the o...</td>\n",
       "      <td>A1LOD3LNX7FUPJ</td>\n",
       "      <td>2</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>2</td>\n",
       "      <td>specific</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gvwqp6</td>\n",
       "      <td>240275</td>\n",
       "      <td>a surfer rides the crest of the waves in the o...</td>\n",
       "      <td>A27F76XB3KS0W2</td>\n",
       "      <td>4</td>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1271 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      block condition  exclude  idx  idx_in_block  num_resized  \\\n",
       "0         0   general    False    0             0          NaN   \n",
       "1         0   general    False    0             0          NaN   \n",
       "2         0   general    False    0             0          NaN   \n",
       "3         0   general    False    0             0          NaN   \n",
       "4         0   general    False    0             0          NaN   \n",
       "5         0   general    False    0             0          NaN   \n",
       "6         0   general    False    1             1          2.0   \n",
       "7         0   general    False    1             1          2.0   \n",
       "8         0   general    False    1             1          2.0   \n",
       "9         0   general    False    1             1          2.0   \n",
       "10        0   general    False    1             1          2.0   \n",
       "11        0   general    False    1             1          2.0   \n",
       "12        0   general    False    2             2          NaN   \n",
       "13        0   general    False    2             2          NaN   \n",
       "14        0   general    False    2             2          NaN   \n",
       "15        0   general    False    2             2          NaN   \n",
       "16        0   general    False    2             2          NaN   \n",
       "17        0   general    False    2             2          NaN   \n",
       "18        1    norecs    False    3             0          NaN   \n",
       "19        1    norecs    False    3             0          NaN   \n",
       "20        1    norecs    False    3             0          NaN   \n",
       "21        1    norecs    False    3             0          NaN   \n",
       "22        1    norecs    False    3             0          NaN   \n",
       "23        1    norecs    False    3             0          NaN   \n",
       "24        1    norecs    False    4             1          NaN   \n",
       "25        1    norecs    False    4             1          NaN   \n",
       "26        1    norecs    False    4             1          NaN   \n",
       "27        1    norecs    False    4             1          NaN   \n",
       "28        1    norecs    False    4             1          NaN   \n",
       "29        1    norecs    False    4             1          NaN   \n",
       "...     ...       ...      ...  ...           ...          ...   \n",
       "1241      1   general    False    4             1          NaN   \n",
       "1242      1   general    False    4             1          NaN   \n",
       "1243      1   general    False    4             1          NaN   \n",
       "1244      1   general    False    4             1          NaN   \n",
       "1245      1   general    False    4             1          NaN   \n",
       "1246      1   general    False    4             1          NaN   \n",
       "1247      1   general    False    5             2          NaN   \n",
       "1248      1   general    False    5             2          NaN   \n",
       "1249      1   general    False    5             2          NaN   \n",
       "1250      1   general    False    5             2          NaN   \n",
       "1251      1   general    False    5             2          NaN   \n",
       "1252      1   general    False    5             2          NaN   \n",
       "1253      2  specific    False    6             0          NaN   \n",
       "1254      2  specific    False    6             0          NaN   \n",
       "1255      2  specific    False    6             0          NaN   \n",
       "1256      2  specific    False    6             0          NaN   \n",
       "1257      2  specific    False    6             0          NaN   \n",
       "1258      2  specific    False    6             0          NaN   \n",
       "1259      2  specific    False    7             1          NaN   \n",
       "1260      2  specific    False    7             1          NaN   \n",
       "1261      2  specific    False    7             1          NaN   \n",
       "1262      2  specific    False    7             1          NaN   \n",
       "1263      2  specific    False    7             1          NaN   \n",
       "1264      2  specific    False    7             1          NaN   \n",
       "1265      2  specific    False    8             2          NaN   \n",
       "1266      2  specific    False    8             2          NaN   \n",
       "1267      2  specific    False    8             2          NaN   \n",
       "1268      2  specific    False    8             2          NaN   \n",
       "1269      2  specific    False    8             2          NaN   \n",
       "1270      2  specific    False    8             2          NaN   \n",
       "\n",
       "      num_tapBackspace  num_tapKey  num_tapSugg_any  num_tapSugg_bos  \\\n",
       "0                  6.0        86.0                6              NaN   \n",
       "1                  6.0        86.0                6              NaN   \n",
       "2                  6.0        86.0                6              NaN   \n",
       "3                  6.0        86.0                6              NaN   \n",
       "4                  6.0        86.0                6              NaN   \n",
       "5                  6.0        86.0                6              NaN   \n",
       "6                  2.0        46.0                4              1.0   \n",
       "7                  2.0        46.0                4              1.0   \n",
       "8                  2.0        46.0                4              1.0   \n",
       "9                  2.0        46.0                4              1.0   \n",
       "10                 2.0        46.0                4              1.0   \n",
       "11                 2.0        46.0                4              1.0   \n",
       "12                 8.0        46.0                4              1.0   \n",
       "13                 8.0        46.0                4              1.0   \n",
       "14                 8.0        46.0                4              1.0   \n",
       "15                 8.0        46.0                4              1.0   \n",
       "16                 8.0        46.0                4              1.0   \n",
       "17                 8.0        46.0                4              1.0   \n",
       "18                25.0       116.0                0              NaN   \n",
       "19                25.0       116.0                0              NaN   \n",
       "20                25.0       116.0                0              NaN   \n",
       "21                25.0       116.0                0              NaN   \n",
       "22                25.0       116.0                0              NaN   \n",
       "23                25.0       116.0                0              NaN   \n",
       "24                70.0       135.0                0              NaN   \n",
       "25                70.0       135.0                0              NaN   \n",
       "26                70.0       135.0                0              NaN   \n",
       "27                70.0       135.0                0              NaN   \n",
       "28                70.0       135.0                0              NaN   \n",
       "29                70.0       135.0                0              NaN   \n",
       "...                ...         ...              ...              ...   \n",
       "1241               8.0         5.0               13              NaN   \n",
       "1242               8.0         5.0               13              NaN   \n",
       "1243               8.0         5.0               13              NaN   \n",
       "1244               8.0         5.0               13              NaN   \n",
       "1245               8.0         5.0               13              NaN   \n",
       "1246               8.0         5.0               13              NaN   \n",
       "1247               NaN         9.0               10              NaN   \n",
       "1248               NaN         9.0               10              NaN   \n",
       "1249               NaN         9.0               10              NaN   \n",
       "1250               NaN         9.0               10              NaN   \n",
       "1251               NaN         9.0               10              NaN   \n",
       "1252               NaN         9.0               10              NaN   \n",
       "1253               1.0         4.0               14              NaN   \n",
       "1254               1.0         4.0               14              NaN   \n",
       "1255               1.0         4.0               14              NaN   \n",
       "1256               1.0         4.0               14              NaN   \n",
       "1257               1.0         4.0               14              NaN   \n",
       "1258               1.0         4.0               14              NaN   \n",
       "1259               9.0         5.0               15              1.0   \n",
       "1260               9.0         5.0               15              1.0   \n",
       "1261               9.0         5.0               15              1.0   \n",
       "1262               9.0         5.0               15              1.0   \n",
       "1263               9.0         5.0               15              1.0   \n",
       "1264               9.0         5.0               15              1.0   \n",
       "1265               NaN         3.0               11              1.0   \n",
       "1266               NaN         3.0               11              1.0   \n",
       "1267               NaN         3.0               11              1.0   \n",
       "1268               NaN         3.0               11              1.0   \n",
       "1269               NaN         3.0               11              1.0   \n",
       "1270               NaN         3.0               11              1.0   \n",
       "\n",
       "      num_tapSugg_full  num_tapSugg_part  num_tapText  writer  stimulus  \\\n",
       "0                  NaN               6.0          1.0  jvccx2    275449   \n",
       "1                  NaN               6.0          1.0  jvccx2    275449   \n",
       "2                  NaN               6.0          1.0  jvccx2    275449   \n",
       "3                  NaN               6.0          1.0  jvccx2    275449   \n",
       "4                  NaN               6.0          1.0  jvccx2    275449   \n",
       "5                  NaN               6.0          1.0  jvccx2    275449   \n",
       "6                  NaN               3.0          NaN  jvccx2    396295   \n",
       "7                  NaN               3.0          NaN  jvccx2    396295   \n",
       "8                  NaN               3.0          NaN  jvccx2    396295   \n",
       "9                  NaN               3.0          NaN  jvccx2    396295   \n",
       "10                 NaN               3.0          NaN  jvccx2    396295   \n",
       "11                 NaN               3.0          NaN  jvccx2    396295   \n",
       "12                 NaN               3.0          NaN  jvccx2    431140   \n",
       "13                 NaN               3.0          NaN  jvccx2    431140   \n",
       "14                 NaN               3.0          NaN  jvccx2    431140   \n",
       "15                 NaN               3.0          NaN  jvccx2    431140   \n",
       "16                 NaN               3.0          NaN  jvccx2    431140   \n",
       "17                 NaN               3.0          NaN  jvccx2    431140   \n",
       "18                 NaN               NaN          1.0  jvccx2    227326   \n",
       "19                 NaN               NaN          1.0  jvccx2    227326   \n",
       "20                 NaN               NaN          1.0  jvccx2    227326   \n",
       "21                 NaN               NaN          1.0  jvccx2    227326   \n",
       "22                 NaN               NaN          1.0  jvccx2    227326   \n",
       "23                 NaN               NaN          1.0  jvccx2    227326   \n",
       "24                 NaN               NaN          7.0  jvccx2    200451   \n",
       "25                 NaN               NaN          7.0  jvccx2    200451   \n",
       "26                 NaN               NaN          7.0  jvccx2    200451   \n",
       "27                 NaN               NaN          7.0  jvccx2    200451   \n",
       "28                 NaN               NaN          7.0  jvccx2    200451   \n",
       "29                 NaN               NaN          7.0  jvccx2    200451   \n",
       "...                ...               ...          ...     ...       ...   \n",
       "1241              11.0               2.0          1.0  gvwqp6    200451   \n",
       "1242              11.0               2.0          1.0  gvwqp6    200451   \n",
       "1243              11.0               2.0          1.0  gvwqp6    200451   \n",
       "1244              11.0               2.0          1.0  gvwqp6    200451   \n",
       "1245              11.0               2.0          1.0  gvwqp6    200451   \n",
       "1246              11.0               2.0          1.0  gvwqp6    200451   \n",
       "1247               7.0               3.0          1.0  gvwqp6    223777   \n",
       "1248               7.0               3.0          1.0  gvwqp6    223777   \n",
       "1249               7.0               3.0          1.0  gvwqp6    223777   \n",
       "1250               7.0               3.0          1.0  gvwqp6    223777   \n",
       "1251               7.0               3.0          1.0  gvwqp6    223777   \n",
       "1252               7.0               3.0          1.0  gvwqp6    223777   \n",
       "1253              14.0               NaN          NaN  gvwqp6    247576   \n",
       "1254              14.0               NaN          NaN  gvwqp6    247576   \n",
       "1255              14.0               NaN          NaN  gvwqp6    247576   \n",
       "1256              14.0               NaN          NaN  gvwqp6    247576   \n",
       "1257              14.0               NaN          NaN  gvwqp6    247576   \n",
       "1258              14.0               NaN          NaN  gvwqp6    247576   \n",
       "1259              12.0               2.0          NaN  gvwqp6     71815   \n",
       "1260              12.0               2.0          NaN  gvwqp6     71815   \n",
       "1261              12.0               2.0          NaN  gvwqp6     71815   \n",
       "1262              12.0               2.0          NaN  gvwqp6     71815   \n",
       "1263              12.0               2.0          NaN  gvwqp6     71815   \n",
       "1264              12.0               2.0          NaN  gvwqp6     71815   \n",
       "1265               8.0               2.0          NaN  gvwqp6    240275   \n",
       "1266               8.0               2.0          NaN  gvwqp6    240275   \n",
       "1267               8.0               2.0          NaN  gvwqp6    240275   \n",
       "1268               8.0               2.0          NaN  gvwqp6    240275   \n",
       "1269               8.0               2.0          NaN  gvwqp6    240275   \n",
       "1270               8.0               2.0          NaN  gvwqp6    240275   \n",
       "\n",
       "                                                   text         guesser  \\\n",
       "0     a yellow cat with strips is setting on a place...  A1TARNH07A75CG   \n",
       "1     a yellow cat with strips is setting on a place...  A3GEL5PWFIK05S   \n",
       "2     a yellow cat with strips is setting on a place...  A185P3B2MC2K83   \n",
       "3     a yellow cat with strips is setting on a place...  A3774HPOUKYTX7   \n",
       "4     a yellow cat with strips is setting on a place...  A1PDBRYBFMMFNY   \n",
       "5     a yellow cat with strips is setting on a place...   AZJKB1D4AFMQY   \n",
       "6     a small bath with a shower with a blue mat on ...  A3VENK02U0X16N   \n",
       "7     a small bath with a shower with a blue mat on ...   AJRY9ALX8069Y   \n",
       "8     a small bath with a shower with a blue mat on ...  A3L2FPKRD46FRW   \n",
       "9     a small bath with a shower with a blue mat on ...  A2VAL2BRKVSUB5   \n",
       "10    a small bath with a shower with a blue mat on ...  A21UA6O7ZFAIQJ   \n",
       "11    a small bath with a shower with a blue mat on ...  A2XJH3WC02RMXQ   \n",
       "12    a bath room with a white toilet and a white wa...  A2ECXGDFC0NJEL   \n",
       "13    a bath room with a white toilet and a white wa...  A3FCZNB9E8K3CX   \n",
       "14    a bath room with a white toilet and a white wa...   AIZTLQM7HHQN6   \n",
       "15    a bath room with a white toilet and a white wa...  A230GPTWWF3SE7   \n",
       "16    a bath room with a white toilet and a white wa...  A11FRLH5KWRLBV   \n",
       "17    a bath room with a white toilet and a white wa...  A1NLW5ZS2WQR35   \n",
       "18    a newly wedded couple cutting there wedding ca...   A89R5XGMHOTJE   \n",
       "19    a newly wedded couple cutting there wedding ca...  A1DKVUTOBPQH11   \n",
       "20    a newly wedded couple cutting there wedding ca...  A1T9KDKDFO114S   \n",
       "21    a newly wedded couple cutting there wedding ca...  A2WWYVKGZZXBOB   \n",
       "22    a newly wedded couple cutting there wedding ca...  A1NOINYD1FZ55T   \n",
       "23    a newly wedded couple cutting there wedding ca...  A2CF2BD4Q0ZDJN   \n",
       "24    a group of people flying kites on a beach and ...  A2P76QVLSGJR45   \n",
       "25    a group of people flying kites on a beach and ...  A2ZNOMZ35LKY8Q   \n",
       "26    a group of people flying kites on a beach and ...  A1USR9JCAMDGM3   \n",
       "27    a group of people flying kites on a beach and ...  A198QA1OQBUJV1   \n",
       "28    a group of people flying kites on a beach and ...   ATSZCAVI441RM   \n",
       "29    a group of people flying kites on a beach and ...   A9ZCY6FLUCIU1   \n",
       "...                                                 ...             ...   \n",
       "1241  a family flies their kites together at a beach...  A23437BMZ5T1FH   \n",
       "1242  a family flies their kites together at a beach...  A2YGAEODJ5SSF6   \n",
       "1243  a family flies their kites together at a beach...  A1T208Y507O4RS   \n",
       "1244  a family flies their kites together at a beach...  A3FAH5S2RGZ5AK   \n",
       "1245  a family flies their kites together at a beach...   AU95AAGU3WSFY   \n",
       "1246  a family flies their kites together at a beach...  A2EZNZ6X58RTNR   \n",
       "1247  a train is traveling down the tracks near a ra...  A26M997VYVK0E6   \n",
       "1248  a train is traveling down the tracks near a ra...  A3JT2I4GGKDYPE   \n",
       "1249  a train is traveling down the tracks near a ra...  A2MGH3MBXMKD96   \n",
       "1250  a train is traveling down the tracks near a ra...  A2TDGWWPX6IMIZ   \n",
       "1251  a train is traveling down the tracks near a ra...   AJG4Y1OT9N50T   \n",
       "1252  a train is traveling down the tracks near a ra...  A3P74FP62XNVYI   \n",
       "1253  a double decker bus traveling down the middle ...  A3VENK02U0X16N   \n",
       "1254  a double decker bus traveling down the middle ...   AJRY9ALX8069Y   \n",
       "1255  a double decker bus traveling down the middle ...  A3L2FPKRD46FRW   \n",
       "1256  a double decker bus traveling down the middle ...  A2VAL2BRKVSUB5   \n",
       "1257  a double decker bus traveling down the middle ...  A21UA6O7ZFAIQJ   \n",
       "1258  a double decker bus traveling down the middle ...  A2XJH3WC02RMXQ   \n",
       "1259  a male tennis player hits the ball with his ra...  A1NSHNH3MNFRGW   \n",
       "1260  a male tennis player hits the ball with his ra...  A1ZN6V0PU8VVAH   \n",
       "1261  a male tennis player hits the ball with his ra...  A125KW9P18V5Z1   \n",
       "1262  a male tennis player hits the ball with his ra...  A20FYCXV508HM9   \n",
       "1263  a male tennis player hits the ball with his ra...   A610SH5RY1NG1   \n",
       "1264  a male tennis player hits the ball with his ra...   AKZ8SFOAI4RZN   \n",
       "1265  a surfer rides the crest of the waves in the o...   AZ9BU8QI4YKF3   \n",
       "1266  a surfer rides the crest of the waves in the o...   AR1IWBDA7MC86   \n",
       "1267  a surfer rides the crest of the waves in the o...  A2WC2NO555XU3J   \n",
       "1268  a surfer rides the crest of the waves in the o...  A3RCX3IQ8L6HHW   \n",
       "1269  a surfer rides the crest of the waves in the o...  A1LOD3LNX7FUPJ   \n",
       "1270  a surfer rides the crest of the waves in the o...  A27F76XB3KS0W2   \n",
       "\n",
       "      num_guesses                                       stimulus_url  \n",
       "0               1  http://images.cocodataset.org/train2017/000000...  \n",
       "1               1  http://images.cocodataset.org/train2017/000000...  \n",
       "2               1  http://images.cocodataset.org/train2017/000000...  \n",
       "3               1  http://images.cocodataset.org/train2017/000000...  \n",
       "4               1  http://images.cocodataset.org/train2017/000000...  \n",
       "5               1  http://images.cocodataset.org/train2017/000000...  \n",
       "6               1  http://images.cocodataset.org/train2017/000000...  \n",
       "7               1  http://images.cocodataset.org/train2017/000000...  \n",
       "8               1  http://images.cocodataset.org/train2017/000000...  \n",
       "9               1  http://images.cocodataset.org/train2017/000000...  \n",
       "10              1  http://images.cocodataset.org/train2017/000000...  \n",
       "11              1  http://images.cocodataset.org/train2017/000000...  \n",
       "12              2  http://images.cocodataset.org/val2017/00000043...  \n",
       "13              2  http://images.cocodataset.org/val2017/00000043...  \n",
       "14              2  http://images.cocodataset.org/val2017/00000043...  \n",
       "15              2  http://images.cocodataset.org/val2017/00000043...  \n",
       "16              4  http://images.cocodataset.org/val2017/00000043...  \n",
       "17              2  http://images.cocodataset.org/val2017/00000043...  \n",
       "18              1  http://images.cocodataset.org/train2017/000000...  \n",
       "19              1  http://images.cocodataset.org/train2017/000000...  \n",
       "20              1  http://images.cocodataset.org/train2017/000000...  \n",
       "21              1  http://images.cocodataset.org/train2017/000000...  \n",
       "22              3  http://images.cocodataset.org/train2017/000000...  \n",
       "23              1  http://images.cocodataset.org/train2017/000000...  \n",
       "24              4  http://images.cocodataset.org/train2017/000000...  \n",
       "25              1  http://images.cocodataset.org/train2017/000000...  \n",
       "26              2  http://images.cocodataset.org/train2017/000000...  \n",
       "27              5  http://images.cocodataset.org/train2017/000000...  \n",
       "28              1  http://images.cocodataset.org/train2017/000000...  \n",
       "29              2  http://images.cocodataset.org/train2017/000000...  \n",
       "...           ...                                                ...  \n",
       "1241            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1242            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1243            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1244            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1245            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1246            2  http://images.cocodataset.org/train2017/000000...  \n",
       "1247            7  http://images.cocodataset.org/train2017/000000...  \n",
       "1248           10  http://images.cocodataset.org/train2017/000000...  \n",
       "1249            3  http://images.cocodataset.org/train2017/000000...  \n",
       "1250            2  http://images.cocodataset.org/train2017/000000...  \n",
       "1251            6  http://images.cocodataset.org/train2017/000000...  \n",
       "1252            3  http://images.cocodataset.org/train2017/000000...  \n",
       "1253            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1254            5  http://images.cocodataset.org/train2017/000000...  \n",
       "1255            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1256            5  http://images.cocodataset.org/train2017/000000...  \n",
       "1257            2  http://images.cocodataset.org/train2017/000000...  \n",
       "1258            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1259            8  http://images.cocodataset.org/train2017/000000...  \n",
       "1260            6  http://images.cocodataset.org/train2017/000000...  \n",
       "1261            5  http://images.cocodataset.org/train2017/000000...  \n",
       "1262            1  http://images.cocodataset.org/train2017/000000...  \n",
       "1263            8  http://images.cocodataset.org/train2017/000000...  \n",
       "1264            4  http://images.cocodataset.org/train2017/000000...  \n",
       "1265            2  http://images.cocodataset.org/train2017/000000...  \n",
       "1266           10  http://images.cocodataset.org/train2017/000000...  \n",
       "1267            6  http://images.cocodataset.org/train2017/000000...  \n",
       "1268            2  http://images.cocodataset.org/train2017/000000...  \n",
       "1269            2  http://images.cocodataset.org/train2017/000000...  \n",
       "1270            4  http://images.cocodataset.org/train2017/000000...  \n",
       "\n",
       "[1271 rows x 19 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    pd.DataFrame(guesses_results).rename(columns={'description': 'text'}),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['block', 'condition', 'exclude', 'idx', 'idx_in_block', 'num_resized',\n",
       "       'num_tapBackspace', 'num_tapKey', 'num_tapSugg_any', 'num_tapSugg_bos',\n",
       "       'num_tapSugg_full', 'num_tapSugg_part', 'num_tapText', 'writer',\n",
       "       'stimulus', 'text', 'guesser', 'num_guesses', 'stimulus_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator_level_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data.to_csv('annotator_level_data_2018-05-22v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5381589299763966"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(annotator_level_data['num_guesses'] == 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kcarnold/code/textrec'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by REML ['lmerMod']\n",
       "Formula: num_guesses ~ condition + (1 | writer) + (1 | guesser) + (1 |  \n",
       "    stimulus)\n",
       "   Data: annotator_level_data\n",
       "REML criterion at convergence: 5530.827\n",
       "Random effects:\n",
       " Groups   Name        Std.Dev.\n",
       " guesser  (Intercept) 0.5323  \n",
       " writer   (Intercept) 0.5333  \n",
       " stimulus (Intercept) 0.5996  \n",
       " Residual             2.0263  \n",
       "Number of obs: 1271, groups:  guesser, 143; writer, 24; stimulus, 9\n",
       "Fixed Effects:\n",
       "      (Intercept)    conditionnorecs  conditionspecific  \n",
       "          2.54278           -0.20093           -0.06277  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i annotator_level_data\n",
    "(model = lmer(num_guesses ~ condition + (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by REML ['lmerMod']\n",
       "Formula: num_guesses ~ (1 | writer) + (1 | guesser) + (1 | stimulus)\n",
       "   Data: annotator_level_data\n",
       "REML criterion at convergence: 5528.521\n",
       "Random effects:\n",
       " Groups   Name        Std.Dev.\n",
       " guesser  (Intercept) 0.5365  \n",
       " writer   (Intercept) 0.5320  \n",
       " stimulus (Intercept) 0.6032  \n",
       " Residual             2.0256  \n",
       "Number of obs: 1271, groups:  guesser, 143; writer, 24; stimulus, 9\n",
       "Fixed Effects:\n",
       "(Intercept)  \n",
       "      2.455  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i annotator_level_data\n",
    "(null_model = lmer(num_guesses ~ (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(pbkrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F-test with Kenward-Roger approximation; computing time: 3.05 sec.\n",
       "large : num_guesses ~ condition + (1 | writer) + (1 | guesser) + (1 | \n",
       "    stimulus)\n",
       "small : num_guesses ~ (1 | writer) + (1 | guesser) + (1 | stimulus)\n",
       "           stat       ndf       ddf F.scaling p.value\n",
       "Ftest    1.0214    2.0000 1234.8701   0.99999  0.3604\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "(kr <- KRmodcomp(model, null_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(glm.full = glmer(num_guesses ~ condition + (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data, family=poisson()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "(glm.null = glmer(num_guesses ~ (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data, family=poisson()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#confint(glm.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "anova(glm.full, glm.null, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(nb_model = glmer.nb(num_guesses ~ condition + (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(nb_model.null = glmer.nb(num_guesses ~ (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "anova(nb_model, nb_model.null, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([dict(trial, specificity=specificity_lookup[trial['text'].strip()]) for trial in trial_data])\n",
    "for col in ['condition', 'participant']:\n",
    "    results[col] = results[col].astype('category')\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('condition').specificity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trial_data).sample(frac=1.0).sort_values('stimulus').to_csv('trial_data_by_stimulus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many images does this caption apply to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/kcarnold/Downloads/Submitted Captions - Sheet1.csv\").iloc[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna().copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_unique'] = (data.iloc[:,5] == '1')\n",
    "data.is_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['block', 'idx_in_block', 'condition']).is_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['participant'] = data['participant'].astype('category')\n",
    "data['condition'] = data['condition'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('condition').is_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i data\n",
    "transformed <- art(is_unique ~ condition + (1|participant), data=data)\n",
    "summary(transformed)\n",
    "anova(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = trial_data[-1]['text']\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concepts: traffic light. COCO doesn't have \"pedestian crossing sign\". There are 4330 images with traffic lights in them in COCO. That's way too much. Looking at Visual Genome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Genome synsets are potentially best, but they're sometimes inaccurate. e.g., \"18 wheeler\" is \"cyclist.n.01\". So let's consider an object a match if matches either the synset or object name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_base = pathlib.Path('/Data/VisualGenome')\n",
    "image_objects = json.load(open(vg_base / 'objects.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_by_id = {img['image_id']: img for img in image_objects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_synsets = json.load(open(vg_base / 'object_synsets.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_attributes = json.load(open(vg_base / 'attributes.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(obj_attributes), len(image_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_attributes[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_by_img = {att['image_id']: att['attributes'] for att in obj_attributes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_by_img[61514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def has_object(obj_name):\n",
    "#     return {\n",
    "#         img['image_id'] for img in image_objects\n",
    "#         if any(obj_name in '\\n'.join(obj['names']) for obj in img['objects'])\n",
    "#            }\n",
    "def has_object(imgid, obj_name):\n",
    "    return any(obj_name in '\\n'.join(obj['names']) for obj in attributes_by_img[imgid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def has_synset(obj_synset):\n",
    "#     return {\n",
    "#         img['image_id'] for img in image_objects\n",
    "#         if any(obj_synset in obj['synsets'] for obj in img['objects'])}\n",
    "def has_synset(imgid, obj_synset):\n",
    "    return any(obj_synset in obj['synsets'] for obj in attributes_by_img[imgid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_obj_with_attr(imgid, obj_name, attr):\n",
    "    return any(\n",
    "        (obj_name in '\\n'.join(obj['names'])) and (attr in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])\n",
    "\n",
    "def has_synset_with_attr(imgid, obj_synset, attr):\n",
    "    return any(\n",
    "        (obj_synset in obj['synsets']) and (attr in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])\n",
    "\n",
    "def has_obj_without_attr(imgid, obj_name, attr):\n",
    "    return any(\n",
    "        (obj_name in '\\n'.join(obj['names'])) and (attr not in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])\n",
    "\n",
    "def has_synset_without_attr(imgid, obj_synset, attr):\n",
    "    return any(\n",
    "        (obj_synset in obj['synsets']) and (attr not in obj.get('attributes', []))\n",
    "        for obj in attributes_by_img[imgid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_synsets['pedestrian sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates = (\n",
    "#     (has_object('pedestrian sign') | has_object('pedestrian crossing sign') | has_object('crossing sign') | has_object('sign')) &\n",
    "#     (has_object('traffic light') | has_synset('traffic_light.n.01'))\n",
    "# )\n",
    "candidates = {\n",
    "    imgid for imgid in attributes_by_img.keys()\n",
    "    if (\n",
    "        (\n",
    "            has_object(imgid, 'pedestrian sign') |\n",
    "            has_object(imgid, 'pedestrian crossing sign') |\n",
    "            has_object(imgid, 'crossing sign') |\n",
    "            has_obj_with_attr(imgid, 'sign', 'yellow')\n",
    "        ) & (\n",
    "            has_obj_without_attr(imgid, 'traffic light', 'red') |\n",
    "            has_synset_without_attr(imgid, 'traffic_light.n.01', 'red')\n",
    "        ))}\n",
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_images(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[img['image_id'] for img in image_objects if '61514' in img.get('image_url', '')]\n",
    "#Image(img_by_id[61514]['image_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_by_id[61514]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use paired comparisons to analyze specificity and accuracy. For a target image $x$ and a fixed set of imposter images $Y$, the **specific accuracy** of a caption is the fraction of comparisons that chose $x$. \n",
    "\n",
    "We start with our dataset of paired comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [\n",
    "    \"exactly how are both the dog and the person going to fit on that skateboard?\",\n",
    "    \"the dark haired dog is trying to ride on the skateboard.\",\n",
    "    \"a person in shorts and a black dog both have one foot on a skateboard.\",\n",
    "    \"a dog with a black head and black legs and ears standing up has one black paw on a black skateboard with white wheels and a guy with black and white shoes and white socks has one foot on the skateboard also and there are bikes and other people in the background\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternatives = 'dog-and-guy-on-skateboard just-dog-on-skateboard guy-on-skateboard-holding-dog dog-and-guy-next-to-skateboard'.split()\n",
    "target = alternatives[0]\n",
    "imposters = alternatives[1:]\n",
    "applies_to = [\n",
    "    'dog-and-guy-on-skateboard dog-and-guy-next-to-skateboard'.split(),\n",
    "    'just-dog-on-skateboard'.split(),\n",
    "    'dog-and-guy-on-skateboard'.split(),\n",
    "    'dog-and-guy-on-skateboard just-dog-on-skateboard guy-on-skateboard-holding-dog dog-and-guy-next-to-skateboard'.split()\n",
    "]\n",
    "applies_to = {cap: tgts for cap, tgts in zip(captions, applies_to)}\n",
    "applies_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "pairs = [[target, imposter] for imposter in imposters]\n",
    "for pair in pairs:\n",
    "    random.shuffle(pair)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_answer_pairs_for_caption(applies, pairs):\n",
    "    outcomes = []\n",
    "    for a, b in pairs:\n",
    "        choices = []\n",
    "        if a in applies:\n",
    "            choices.append(0)\n",
    "        if b in applies:\n",
    "            choices.append(1)\n",
    "        if len(choices) == 0:\n",
    "            choices = [0, 1]\n",
    "        outcomes.append(random.choice(choices))\n",
    "    return outcomes\n",
    "fake_answer_pairs_for_caption(applies_to[captions[0]], pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_comparisons_data = []\n",
    "for caption in captions:\n",
    "    for annotator in range(5):\n",
    "        for pair, outcome in zip(pairs, fake_answer_pairs_for_caption(applies_to[caption], pairs)):\n",
    "            picked = pair[outcome]\n",
    "            fake_comparisons_data.append(dict(\n",
    "                caption=caption,\n",
    "                annotator=annotator,\n",
    "                pair=pair,\n",
    "                picked=picked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(fake_comparisons_data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['picked_correct'] = data['picked'] == 'dog-and-guy-on-skateboard'\n",
    "data.groupby('caption').picked_correct.mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a main effect of writing condition on outcome specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "    dict(participant_id=participant_id, condition=condition)\n",
    "    for participant_id in 'abc def ghi'.split() for condition in 'general specific norecs'.split()\n",
    "])\n",
    "results['participant_id'] = results['participant_id'].astype('category')\n",
    "results['condition'] = results['condition'].astype('category')\n",
    "results['specificity'] = np.random.randn(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#install.packages(\"ARTool\")\n",
    "library(ARTool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i results\n",
    "summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i results\n",
    "transformed <- art(specificity ~ condition + (1|participant), data=results)\n",
    "summary(transformed)\n",
    "anova(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

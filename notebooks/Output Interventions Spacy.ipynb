{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/code/textrec\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/textrec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import toolz\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading COCO captions\n",
      "Loading COCO id2url\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcarnold/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ONMT models...\n",
      "coco_lm_adam_acc_46.00_ppl_16.32_e10_nooptim.pt\n",
      "Loading model parameters.\n",
      "coco_cap_adam_acc_48.73_ppl_12.56_e10_nooptim.pt\n",
      "Loading model parameters.\n",
      "Ready.\n",
      "Loading SpaCy...done\n",
      "Loading COCO captions\n",
      "Loading COCO id2url\n",
      "Done\n",
      "Loading SpaCy...done\n"
     ]
    }
   ],
   "source": [
    "from textrec.paths import paths\n",
    "from textrec import analysis_util, util, notebook_util, automated_analyses\n",
    "reload(analysis_util), reload(util), reload(notebook_util), reload(automated_analyses)\n",
    "from textrec.notebook_util import images, id2img, id2url, show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results of writing experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites: Run `textrec.logs_to_csv {batch_name}` and `textrec.gruntwork {batch_name}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 'spec1'\n",
    "experiment_level_data = pd.read_csv(paths.analyzed / f'experiment_{batch}.csv')\n",
    "block_level_data = pd.read_csv(paths.analyzed / f'block_{batch}.csv')\n",
    "trial_level_data = pd.read_csv(paths.analyzed / f'trial_withmanual_{batch}.csv')\n",
    "helpful_ranks_by_condition = pd.read_csv(paths.analyzed / f'helpful_ranks_by_condition_{batch}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_captions = {img['cocoid']: util.join_captions(img) for img in notebook_util.images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vectorizer, caption_vecs = util.get_vectorized_captions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123287, 9952)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_captions = {stimulus: '\\n'.join(toolz.pluck('text', trials))\n",
    "                   for stimulus, trials in toolz.groupby('stimulus', trial_data).items()}\n",
    "concat_captions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>train/352082</div><img src=\"http://images.cocodataset.org/train2017/000000352082.jpg\" style=\"max-width: 200px\"><div>A train traveling down railroad tracks next to a train station.</div>\n",
       "<div>People standing next to a train as it pulls down the tracks.</div>\n",
       "<div>A train sitting on some train tracks with people taking pictures</div>\n",
       "<div>A black train is stopped on the tracks.</div>\n",
       "<div>A black train engine on tracks next to buildings.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/548597</div><img src=\"http://images.cocodataset.org/train2017/000000548597.jpg\" style=\"max-width: 200px\"><div>A train in front of several colorful houses.</div>\n",
       "<div>A train driving down tracks near a building.</div>\n",
       "<div>a train sitting on the tracks next to a metal pole</div>\n",
       "<div>The train is parked on the railroad tracks.</div>\n",
       "<div>A train parked on an old track beside colorful buildings.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>restval/150091</div><img src=\"http://images.cocodataset.org/train2017/000000150091.jpg\" style=\"max-width: 200px\"><div>there is a old train that is coming up the tracks</div>\n",
       "<div>A yellow and red train traveling down train tracks.</div>\n",
       "<div>A train sits on train tracks in front of some buildings.</div>\n",
       "<div>Train going down a track next to big buildings.</div>\n",
       "<div>A train sitting on the tracks next to a platform.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/477646</div><img src=\"http://images.cocodataset.org/train2017/000000477646.jpg\" style=\"max-width: 200px\"><div>a blue train is on a set of tracks</div>\n",
       "<div>A narrow train pulls into the station in the rain.</div>\n",
       "<div>A blue train near a platform while it is snowing.</div>\n",
       "<div>A blue train pulls into a station in the snow.</div>\n",
       "<div>a black and blue train a sign and tracks</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/322049</div><img src=\"http://images.cocodataset.org/train2017/000000322049.jpg\" style=\"max-width: 200px\"><div>a train on a train track with buildings in the background</div>\n",
       "<div>A train pulls up to a platform by the rails.</div>\n",
       "<div>A train that is riding on the tracks near the street.</div>\n",
       "<div>A train sitting next to a loading platform near tall buildings.</div>\n",
       "<div>A train on tracks near buildings and a boarding platform.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>val/338986</div><img src=\"http://images.cocodataset.org/val2017/000000338986.jpg\" style=\"max-width: 200px\"><div>A train pulls up along some buildings. </div>\n",
       "<div>A blue train is coming down the tracks</div>\n",
       "<div>A photo of a train station with the train pulling in.</div>\n",
       "<div>a blue and yellow train a building and some cars</div>\n",
       "<div>a group of cars next to a train</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/132878</div><img src=\"http://images.cocodataset.org/train2017/000000132878.jpg\" style=\"max-width: 200px\"><div>A blue and yellow train traveling down train tracks.</div>\n",
       "<div>A blue, red and yellow train traveling through a wide set of tracks.</div>\n",
       "<div>Red yellow and blue train rides along train tracks</div>\n",
       "<div>A colorful train pulls into a multi track station.</div>\n",
       "<div>A train getting ready to go down the train tracks. </div></div>\n",
       "<div style=\"display: inline-block;\"><div>val/138196</div><img src=\"http://images.cocodataset.org/train2017/000000138196.jpg\" style=\"max-width: 200px\"><div>A train is driving down the tracks in front of a building.</div>\n",
       "<div>a train that is parked on some train tracks</div>\n",
       "<div>A train that is pulling into a train station. </div>\n",
       "<div>A yellow and red train engine pulling into a station.</div>\n",
       "<div>a train pulls up to a platform for people to board.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/537139</div><img src=\"http://images.cocodataset.org/train2017/000000537139.jpg\" style=\"max-width: 200px\"><div>There is a train, buildings, and cars in the mountains.</div>\n",
       "<div>A train pulling into a train station surrounded by buildings.</div>\n",
       "<div>A train on the tracks by a building outside.</div>\n",
       "<div>A cargo train is moving traveling through the city.</div>\n",
       "<div>A train runs on tracks behind some buildings and a parking lot.</div></div>\n",
       "<div style=\"display: inline-block;\"><div>train/372234</div><img src=\"http://images.cocodataset.org/train2017/000000372234.jpg\" style=\"max-width: 200px\"><div>A train pulls into the train station in a metropolis.</div>\n",
       "<div>The commuter train is traveling below the tunnel.</div>\n",
       "<div>A train on the railroad tracks has a yellow door on the front.</div>\n",
       "<div>There is a train that is on the tracks</div>\n",
       "<div>A commuter train is seen with city buildings in the background.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similar_images(caption, n=10):\n",
    "    query_vec = cap_vectorizer.transform([caption])\n",
    "    similarity = caption_vecs.dot(query_vec.T).A.ravel()\n",
    "    return [images[idx]['cocoid'] for idx in np.argsort(similarity)[-n:][::-1]]\n",
    "#query_caption = concat_captions[396295].replace('wine', '') #trial_data[0]['text']\n",
    "# query_caption = \"a rusty and dirty shower in the bathroom has a tan towel over its handle\"\n",
    "# query_caption = \"a sliding glass shower door with a bath mat hanging on it\"\n",
    "# query_caption = \"a closed shower door with crackled glass encases some hanging colored toiletries\"\n",
    "query_caption = \"a brown train pulls into the tracks next to some colorful buildings\"\n",
    "# print(query_caption)\n",
    "HTML(show_images(get_similar_images(query_caption)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_caption = \"a brown train pulls into the tracks next to some colorful buildings\"\n",
    "query_vec = cap_vectorizer.transform([query_caption])\n",
    "similarity = caption_vecs.dot(query_vec.T).A.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How similar should we count as similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_argsort = np.argsort(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: inline-block;\"><div>restval/168811</div><img src=\"http://images.cocodataset.org/train2017/000000168811.jpg\" style=\"max-width: 200px\"><div>There is a crowd of people waiting for the train. </div>\n",
       "<div>A crowd of people take pictures of a departing train.</div>\n",
       "<div>A group of people on a train platform taking pictures of a departing train</div>\n",
       "<div>Several people taking photos with their cell phones at a train depot.</div>\n",
       "<div>There are many people standing on the platform awaiting a train</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(show_images([images[similarity_argsort[int(.976*len(similarity_argsort))]]['cocoid']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14745.,     0.,     0.,     0.,     0.,  4229., 31110., 52124.,\n",
       "        17650.,  3429.]),\n",
       " array([-13.81551056, -12.48829988, -11.16108921,  -9.83387853,\n",
       "         -8.50666785,  -7.17945718,  -5.8522465 ,  -4.52503583,\n",
       "         -3.19782515,  -1.87061448,  -0.5434038 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1602e6240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(similarity+1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return [images[idx]['cocoid'] for idx in np.argsort(similarity)[-n:][::-1]]\n",
    "#query_caption = concat_captions[396295].replace('wine', '') #trial_data[0]['text']\n",
    "# query_caption = \"a rusty and dirty shower in the bathroom has a tan towel over its handle\"\n",
    "# query_caption = \"a sliding glass shower door with a bath mat hanging on it\"\n",
    "# query_caption = \"a closed shower door with crackled glass encases some hanging colored toiletries\"\n",
    "# print(query_caption)\n",
    "HTML(show_images(get_similar_images(query_caption)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_foil_set(*, stimulus, caption, rs):\n",
    "    similar_images = get_similar_images(caption, n=10)\n",
    "    if stimulus not in similar_images:\n",
    "        print(\"Inserting\", stimulus, 'into foil set')\n",
    "        similar_images[-1] = stimulus\n",
    "    rs.shuffle(similar_images)\n",
    "    return similar_images\n",
    "stimulus = trial_data[1]['stimulus']\n",
    "get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=np.random.RandomState(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(1234)\n",
    "foil_sets = {\n",
    "    stimulus: get_foil_set(stimulus=stimulus, caption=concat_captions[stimulus], rs=rs)\n",
    "    for stimulus in sorted(concat_captions.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group tasks so that (1) each annotator never gets the same target image twice and (2) each annotator never sees two captions from the same person. The latter criterion cannot always be met, though, since the number of annotators may not evenly divide the number of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffled(lst):\n",
    "    lst = lst[:]\n",
    "    random.shuffle(lst)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    trials_by_img = toolz.groupby('stimulus', shuffled(trial_data))\n",
    "    annotators = []\n",
    "    while not any(len(trials) == 0 for trials in trials_by_img.values()):\n",
    "        trials_for_annotator = []\n",
    "        participants_seen_by_annotator = set()\n",
    "        for stimulus, trials in trials_by_img.items():\n",
    "            for i in range(len(trials)):\n",
    "                participant = trials[i]['participant']\n",
    "                if participant not in participants_seen_by_annotator:\n",
    "                    trials_for_annotator.append(trials.pop(i))\n",
    "                    participants_seen_by_annotator.add(participant)\n",
    "                    break\n",
    "            else:\n",
    "#                 print(\"Have to use the same participant again\")\n",
    "                trials_for_annotator.append(trials.pop(0))\n",
    "\n",
    "        annotators.append(shuffled(trials_for_annotator))\n",
    "    if all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators):\n",
    "        break\n",
    "    assert all(len(trials) == 0 for trials in trials_by_img.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = annotators[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_by_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never gets the same target image twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('stimulus', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each annotator never sees two captions from the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(set(toolz.pluck('participant', trials))) == len(trials) for trials in annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(trials) for trials in annotators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_task(stimulus, text):\n",
    "    foil_set = foil_sets[stimulus]\n",
    "    return dict(\n",
    "        description=text,\n",
    "        correct_idx=foil_set.index(stimulus),\n",
    "        images=[id2url[idx] for idx in foil_set]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = annotators[0][0]\n",
    "make_task(trial['stimulus'], trial['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_task = pd.DataFrame([\n",
    "    json.dumps([make_task(trial['stimulus'], trial['text']) for trial in annotator_trials])\n",
    "    for annotator_trials in annotators], columns=['task'])\n",
    "guesses_task.iloc[:1].to_csv(str(paths.data / 'anno-tasks' / 'guesses_test.csv'), index=False)\n",
    "guesses_task.iloc[1:].to_csv(str(paths.data / 'anno-tasks' / 'guesses_remain.csv'), index=False)\n",
    "guesses_task.to_csv(str(paths.data / 'anno-tasks' / 'guesses.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MTurk results so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = list((paths.data / 'mturk').glob('*-guesses.csv'))\n",
    "batched_guesses_results = (\n",
    "    pd.concat([pd.read_csv(str(f)) for f in result_files], axis=0, ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(batched_guesses_results['WorkTimeInSeconds']/60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_dur(results):\n",
    "    pages = json.loads(results)\n",
    "    try:\n",
    "        first_guess = pages[0]['guesses'][0]['timestamp']\n",
    "        last_guess = pages[-1]['guesses'][-1]['timestamp']\n",
    "        return (last_guess - first_guess) / 1000 / 60\n",
    "    except IndexError:\n",
    "        # Something failed in the UI probably...\n",
    "        return None\n",
    "batched_guesses_results['Answer.results'].apply(get_active_dur).hist()\n",
    "batched_guesses_results['Answer.results'].apply(get_active_dur).describe()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_guesses_results[batched_guesses_results['Answer.results'].apply(lambda x: '\"guesses\":[]' in x)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_results = []\n",
    "for i, row in batched_guesses_results.iterrows():\n",
    "    for page in json.loads(row['Answer.results']):\n",
    "#         print(page)\n",
    "        guess_indices = [guess['idx'] for guess in page['guesses']]\n",
    "        if len(guess_indices) == 0:\n",
    "            print(\"UI fail\", row['WorkerId'])\n",
    "            continue\n",
    "#         guessed_right_sometime = [row.correctIdx in row.guess_indices for row in mturk_nafc_results.itertuples()]\n",
    "        stimulus_url = [img for img in page['images'] if img['isCorrect']][0]['url']\n",
    "        guesses_results.append(dict(\n",
    "            guesser=row['WorkerId'],\n",
    "            description=page['description'],\n",
    "            num_guesses=len(guess_indices),\n",
    "            stimulus_url=stimulus_url))\n",
    "pd.DataFrame(guesses_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_responses_by_caption = mturk_nafc_results.groupby('Answer.description').size().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tasks remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials_todo = [trial for trial in trial_data if num_responses_by_caption.get(trial['text'], 0) < 3]\n",
    "# len(trial_data), len(trials_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# while True:\n",
    "#     out_fn = paths.data / 'anno-tasks' / f'{datetime.date.today().isoformat()}-{i}-nAFC.csv'\n",
    "#     if not out_fn.exists():\n",
    "#         break\n",
    "#     i += 1\n",
    "# out_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = np.random.RandomState(1234)\n",
    "# pd.DataFrame([make_task(trial, rs) for trial in trials_todo]).to_csv(out_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the actual HIT text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "html = Template(open(paths.top_level / 'HITs' / '2018-05-04-image-description-match.jinja.html').read()).render(dict(\n",
    "    description='${description}',\n",
    "    images=['${image_%d_url}' % i for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html2 = html\n",
    "trial = trial_data[18+7*9]\n",
    "for k, v in make_task(trial['stimulus'], trial['text']).items():\n",
    "    html2 = html2.replace('${' + k + '}', str(v))\n",
    "HTML('<div style=\"height: 1000px; position: relative;\">'+html2+'</div>')\n",
    "# print(html2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.Popen('pbcopy', stdin=subprocess.PIPE).communicate(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MTurk results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results.groupby('Answer.description').num_guesses.mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mturk_nafc_results['WorkTimeInSeconds'][mturk_nafc_results['WorkTimeInSeconds'] < 5*60] / 60).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(mturk_nafc_results['WorkTimeInSeconds'] / 60) * 9/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    15 # participants\n",
    "    * 3 # conditions per participant\n",
    "    * 3 # captions per condition\n",
    "    - 1 # image not shown\n",
    ") * 3 # annotators per description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    * .24 # reward per annotator\n",
    ") * 1.2 # MTurk 20% fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the same worker see the same target image multiple times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data.iterrows())[1]['Input.image_0_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['target_image_url'] = [row['Input.image_'+str(row['correctIdx'])+\"_url\"] for _, row in mturk_nafc_results.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_worker_image_pairs = set()\n",
    "for worker_id, data in mturk_nafc_results.groupby('WorkerId'):\n",
    "    target_images = [row['target_image_url'] for _, row in data.iterrows()]\n",
    "    if len(target_images) != len(set(target_images)):\n",
    "#         print(worker_id)\n",
    "        value_counts = pd.Series(target_images).value_counts()\n",
    "        value_counts = value_counts[value_counts > 1]\n",
    "#         print(value_counts)\n",
    "        for img in value_counts.index:\n",
    "            bad_worker_image_pairs.add((worker_id, img))\n",
    "bad_worker_image_pairs\n",
    "\n",
    "annotation_row_is_bad = [\n",
    "    (row['WorkerId'], row['target_image_url']) in bad_worker_image_pairs\n",
    "    for _, row in mturk_nafc_results.iterrows()\n",
    "]\n",
    "mturk_nafc_results['row_is_bad'] = annotation_row_is_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_nafc_results['row_is_bad'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_results = mturk_nafc_results[~mturk_nafc_results['row_is_bad']].rename(columns={'Answer.description': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mturk_nafc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(guess_results), len(trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    guess_results.rename(columns={'WorkerId': 'guesser'}).drop(['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'RequesterAnnotation', 'guesses'], axis=1),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data = pd.merge(\n",
    "    pd.DataFrame(trial_data).rename(columns={'participant': 'writer'}),\n",
    "    pd.DataFrame(guesses_results).rename(columns={'description': 'text'}),\n",
    "    on='text', validate='1:m', how='right')\n",
    "annotator_level_data\n",
    "    #.groupby().num_guesses.mean().to_frame('mean_num_guesses'),\n",
    "#     left_on='text', right_index=True).groupby('condition').mean_num_guesses.aggregate(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_level_data.to_csv('annotator_level_data_2018-05-22v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(annotator_level_data['num_guesses'] == 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(model = lmer(num_guesses ~ condition + (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(null_model = lmer(num_guesses ~ (1|writer) + (1|guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(pbkrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "(kr <- KRmodcomp(model, null_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(glm.full = glmer(num_guesses ~ condition + (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data, family=poisson()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "(glm.null = glmer(num_guesses ~ (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data, family=poisson()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#confint(glm.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "anova(glm.full, glm.null, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(nb_model = glmer.nb(num_guesses ~ condition + (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i annotator_level_data\n",
    "(nb_model.null = glmer.nb(num_guesses ~ (1|writer) + (1+guesser) + (1|stimulus), annotator_level_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "anova(nb_model, nb_model.null, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([dict(trial, specificity=specificity_lookup[trial['text'].strip()]) for trial in trial_data])\n",
    "for col in ['condition', 'participant']:\n",
    "    results[col] = results[col].astype('category')\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('condition').specificity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trial_data).sample(frac=1.0).sort_values('stimulus').to_csv('trial_data_by_stimulus.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
